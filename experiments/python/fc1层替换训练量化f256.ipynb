{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matmul as mm\n",
    "import math_util as mu\n",
    "import scipy.io as io\n",
    "from amm_methods import *\n",
    "import socket # Obtain the current host name, which can be used to select different data directories and result saving directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method = METHOD_MITHRAL\n",
    "# method = METHOD_PQ\n",
    "# method = METHOD_EXACT\n",
    "method = METHOD_SCALAR_QUANTIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "feedback_bits = 256\n",
    "ncodebooks=64\n",
    "ncentroids=256\n",
    "train_sam_num = 3000 # 训练集样本数\n",
    "qbits = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "host_name = socket.gethostname()\n",
    "if host_name == 'DESKTOP-PLRL7TK':\n",
    "    dir_train = 'E:\\\\hdr\\\\研一\\\\华为-深度学习\\\\intermediate\\\\intermediate8dbfc1'\n",
    "    dir_result = ''\n",
    "elif host_name == 'DESKTOP-6FOH47P':\n",
    "    dir_train = 'F:\\\\Projects\\\\python\\\\PQ\\\\intermediate8dbfc1'\n",
    "    dir_result = 'F:\\\\Projects\\\\python\\\\PQ\\\\res'\n",
    "    data_to_fcpath_train= 'data_to_fc_e39_7999.npy'\n",
    "    featurepath_train= 'feature_e39_7999.npy'\n",
    "    data_to_fcpath_test = 'data_to_fc_e39_7999.npy'\n",
    "    featurepath_test = 'feature_e39_7999.npy'\n",
    "elif host_name == 'jm-System-Product-Name':\n",
    "    dir_train = '/data/hdr/transformer_data/joined'\n",
    "    dir_result = '/data/hdr/pq/res'\n",
    "    data_to_fcpath_train= 'data_to_fc_train_f%i_sam%i.npy' % (feedback_bits, train_sam_num)\n",
    "    y_train = 'y_train_f%i_sam%i.npy' % (feedback_bits, train_sam_num)\n",
    "    featurepath_train= 'feature_train_f%i_sam%i.npy' % (feedback_bits, train_sam_num)\n",
    "    data_to_fcpath_test = 'data_to_fc_test.npy'\n",
    "    featurepath_test = 'feature_test.npy'\n",
    "    y_test = 'y_test.npy'\n",
    "else:\n",
    "    raise NameError(\"You are running the script in a new computer, please define dir_train\")\n",
    "\n",
    "\n",
    "weightpath = 'encoder_fcw.npy'\n",
    "biaspath = 'encoder_fcb.npy'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _scalar_quantize(A, axis=0, signed=False, nbits=8):\n",
    "    unsigned_maxval = float(1 << int(nbits)) - 1\n",
    "\n",
    "    # # TODO rm\n",
    "    # # return np.zeros((A.shape[0], 1)), np.ones((A.shape[0], 1)), A\n",
    "    # # offsets = np.zeros((A.shape[0], 1))\n",
    "    # offsets = A.min(axis=1, keepdims=True)\n",
    "    # # scales = maxval / np.ones((A.shape[0], 1))\n",
    "    # scales = maxval / A.max(axis=1, keepdims=True)\n",
    "    # Aq = (A - offsets) * scales\n",
    "    # return offsets, scales, Aq\n",
    "\n",
    "    # maxval = float(1 << int(nbits)) - 1\n",
    "    mins = A.min(axis=axis, keepdims=True)\n",
    "    # A_offset = A - offsets\n",
    "    ranges = (A - mins).max(axis=axis, keepdims=True) + 1e-20\n",
    "    print(\"ranges:\")\n",
    "    print(ranges)\n",
    "    scales = unsigned_maxval / ranges\n",
    "    # Aq = (A_offset * (maxval / scales)).astype(np.int)\n",
    "    # Aq = (A_offset * scales).astype(np.int)\n",
    "\n",
    "    if signed:\n",
    "        # sign_offset = 1 << (nbits - 1)  # 8 bits -> 128\n",
    "        # A_offset -= sign_offset\n",
    "        offsets = mins + (ranges * (128. / 255))\n",
    "        minval = -(1 << (nbits - 1))\n",
    "        maxval = -minval - 1\n",
    "    else:\n",
    "        offsets = mins\n",
    "        minval = 0\n",
    "        maxval = (1 << nbits) - 1\n",
    "\n",
    "    Aq = (A - offsets) * scales\n",
    "    # print(\"min, max A:\", Aq.min(), Aq.max())  # looks good\n",
    "    Aq = np.clip(Aq, minval, maxval).astype(int)\n",
    "\n",
    "    return offsets, scales, Aq, minval, maxval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_quantize(A, B, offsets, scales, minval, maxval, axis=0, signed=False, nbits=8):\n",
    "    Aq = (A - offsets) * scales\n",
    "    Aq = np.clip(Aq, minval, maxval).astype(int) # 量化后的值（整数\n",
    "    Aqreal = Aq / scales + offsets # 量化后对应的实际值\n",
    "    print(\"A:\")\n",
    "    print(A)\n",
    "    print(\"Aq:\")\n",
    "    print(Aq)\n",
    "    print(\"Aqreal\")\n",
    "    print(Aqreal)\n",
    "    C = np.matmul(Aqreal, B)\n",
    "\n",
    "    return C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 9.  6.  3.  5.  2.]\n",
      " [ 1.  8.  1.  1.  2.]\n",
      " [ 8.  1.  9.  1.  6.]\n",
      " [ 5.  0.  2.  1. 10.]\n",
      " [ 7.  7.  4.  3.  5.]]\n"
     ]
    }
   ],
   "source": [
    "ran_mat = np.rint(10*np.random.random(size=(5,5)))\n",
    "print(ran_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ranges:\n",
      "[[8. 8. 8. 4. 8.]]\n"
     ]
    }
   ],
   "source": [
    "offsets, scales, Aq, minval, maxval = _scalar_quantize(ran_mat, axis=0, signed=False, nbits=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 1. 1. 2.]]\n",
      "[[31.875 31.875 31.875 63.75  31.875]]\n",
      "[[255 191  63 255   0]\n",
      " [  0 255   0   0   0]\n",
      " [223  31 255   0 127]\n",
      " [127   0  31   0 255]\n",
      " [191 223  95 127  95]]\n",
      "0\n",
      "255\n"
     ]
    }
   ],
   "source": [
    "print(offsets)\n",
    "print(scales)\n",
    "print(Aq)\n",
    "print(minval)\n",
    "print(maxval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(96000, 2048)\n",
      "(2048, 256)\n",
      "(32000, 2048)\n"
     ]
    }
   ],
   "source": [
    "data_to_fc_train = np.load(os.path.join(dir_train, data_to_fcpath_train))\n",
    "print(data_to_fc_train.shape)\n",
    "weight = np.load(os.path.join(dir_train, weightpath))\n",
    "print(weight.shape)\n",
    "data_to_fc_test = np.load(os.path.join(dir_train, data_to_fcpath_test))\n",
    "print(data_to_fc_test.shape)\n",
    "bias = np.load(dir_train+'/'+biaspath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ranges:\n",
      "[[0.01557301 0.00956542 0.01400521 ... 0.17773968 0.14837046 0.15120666]]\n"
     ]
    }
   ],
   "source": [
    "train_offsets, train_scales, train_Aq, train_minval, train_maxval = _scalar_quantize(data_to_fc_train, axis=0, signed=False, nbits=qbits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A:\n",
      "[[ 0.001161   -0.0003292   0.00079327 ...  0.02352978  0.02011615\n",
      "   0.01869451]\n",
      " [-0.00108941 -0.0003551  -0.00034218 ...  0.01012411  0.00046477\n",
      "   0.00978941]\n",
      " [ 0.00097858  0.00035693  0.00280184 ... -0.01709364  0.01152093\n",
      "   0.00830318]\n",
      " ...\n",
      " [ 0.0044448  -0.00065186  0.00043888 ... -0.0145436  -0.00225845\n",
      "   0.00354694]\n",
      " [ 0.00094269 -0.0011471   0.00078288 ...  0.00279342  0.00330969\n",
      "  -0.01324401]\n",
      " [ 0.00324066  0.00071579  0.00377456 ... -0.0036882   0.00070076\n",
      "  -0.00470257]]\n",
      "Aq:\n",
      "[[136 128 136 ... 147 158 169]\n",
      " [ 99 127 116 ... 128 124 154]\n",
      " [133 146 173 ...  89 143 151]\n",
      " ...\n",
      " [190 119 130 ...  93 119 143]\n",
      " [133 106 136 ... 118 129 115]\n",
      " [170 155 191 ... 108 124 129]]\n",
      "Aqreal\n",
      "[[ 0.00111608 -0.00033059  0.00074773 ...  0.0228645   0.02008874\n",
      "   0.01843729]\n",
      " [-0.00114353 -0.00036811 -0.00035071 ...  0.00962115  0.00030602\n",
      "   0.00954278]\n",
      " [ 0.00093287  0.00034461  0.00277986 ... -0.01756257  0.01136107\n",
      "   0.00776388]\n",
      " ...\n",
      " [ 0.0044139  -0.0006682   0.0004182  ... -0.01477449 -0.00260321\n",
      "   0.00302014]\n",
      " [ 0.00093287 -0.00115585  0.00074773 ...  0.00265097  0.00321524\n",
      "  -0.01358295]\n",
      " [ 0.00319248  0.00068221  0.00376847 ... -0.00431922  0.00030602\n",
      "  -0.0052814 ]]\n"
     ]
    }
   ],
   "source": [
    "y_out_matmul = test_quantize(data_to_fc_test, weight, train_offsets, train_scales, train_minval, train_maxval)\n",
    "y_out_last = y_out_matmul + bias.T # MADDNESS替换后当前层输出，即+bias并不需要激活函数后的结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.08795245  0.01847343 -0.54548272 ... -0.07523059  0.07883646\n",
      "   0.00561524]\n",
      " [-0.23517419 -0.12676349 -0.29348168 ... -0.38049333  0.00978337\n",
      "  -0.07713263]\n",
      " [ 0.3898445  -0.05268517 -0.24185705 ... -0.50888443  0.18536493\n",
      "   0.11724634]\n",
      " ...\n",
      " [ 0.3498211   0.14093997 -0.52193499 ... -0.1764249  -0.20703671\n",
      "   0.00418148]\n",
      " [ 0.24449094  0.01195635 -0.24397657 ...  0.05938521 -0.00413316\n",
      "   0.05226247]\n",
      " [-0.31105483  0.10657356 -0.42814031 ... -0.34607515 -0.14545673\n",
      "   0.17339793]]\n",
      "float64\n",
      "(32000, 256)\n"
     ]
    }
   ],
   "source": [
    "print(y_out_last)\n",
    "print(y_out_last.dtype)\n",
    "print(y_out_last.shape)\n",
    "np.save(dir_result+'/'+'UserQuantize'+'fc1_fb%i_qb%i.npy' % (feedback_bits, qbits), y_out_last.astype(np.float32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2048)\n",
      "(1, 2048)\n",
      "(96000, 2048)\n"
     ]
    }
   ],
   "source": [
    "print(train_offsets.shape)\n",
    "print(train_scales.shape)\n",
    "print(train_Aq.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.00718952 -0.00513206 -0.00672171 ... -0.0795972  -0.07184276\n",
      "  -0.08177418]]\n"
     ]
    }
   ],
   "source": [
    "print(train_offsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('pqhdr')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ec04f7dc2b3ae4a422de9aaf96e8c62fe190a2869a08d14112cb2d7713497448"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
