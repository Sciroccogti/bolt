{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matmul as mm\n",
    "import math_util as mu\n",
    "import scipy.io as io\n",
    "from amm_methods import *\n",
    "import socket # Obtain the current host name, which can be used to select different data directories and result saving directories\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method = METHOD_MITHRAL\n",
    "# method = METHOD_PQ\n",
    "# method = METHOD_EXACT\n",
    "method = METHOD_SCALAR_QUANTIZE\n",
    "user_method = \"METHOD_USER_SCALAR_QUANTIZE\"\n",
    "# user_method = \"METHOD_USER_QUANTIZE\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "feedback_bits = 256\n",
    "ncodebooks=64\n",
    "ncentroids=256\n",
    "train_sam_num = 3000 # 训练集样本数\n",
    "qbits = 8\n",
    "prop_A = 0\n",
    "prop_B = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "host_name = socket.gethostname()\n",
    "if host_name == 'DESKTOP-PLRL7TK':\n",
    "    dir_train = 'E:\\\\hdr\\\\研一\\\\华为-深度学习\\\\intermediate\\\\intermediate8dbfc1'\n",
    "    dir_result = ''\n",
    "elif host_name == 'DESKTOP-6FOH47P':\n",
    "    dir_train = 'F:\\\\Projects\\\\python\\\\PQ\\\\intermediate8dbfc1'\n",
    "    dir_result = 'F:\\\\Projects\\\\python\\\\PQ\\\\res'\n",
    "    data_to_fcpath_train= 'data_to_fc_e39_7999.npy'\n",
    "    featurepath_train= 'feature_e39_7999.npy'\n",
    "    data_to_fcpath_test = 'data_to_fc_e39_7999.npy'\n",
    "    featurepath_test = 'feature_e39_7999.npy'\n",
    "elif host_name == 'jm-System-Product-Name':\n",
    "    dir_train = '/data/hdr/transformer_data/joined'\n",
    "    dir_result = '/data/hdr/pq/res'\n",
    "    data_to_fcpath_train= 'data_to_fc_train_f%i_sam%i.npy' % (feedback_bits, train_sam_num)\n",
    "    y_train = 'y_train_f%i_sam%i.npy' % (feedback_bits, train_sam_num)\n",
    "    featurepath_train= 'feature_train_f%i_sam%i.npy' % (feedback_bits, train_sam_num)\n",
    "    data_to_fcpath_test = 'data_to_fc_test.npy'\n",
    "    featurepath_test = 'feature_test.npy'\n",
    "    y_test = 'y_test.npy'\n",
    "else:\n",
    "    raise NameError(\"You are running the script in a new computer, please define dir_train\")\n",
    "\n",
    "\n",
    "weightpath = 'encoder_fcw.npy'\n",
    "biaspath = 'encoder_fcb.npy'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from turtle import right\n",
    "\n",
    "\n",
    "def saturation_sort(A, proportion = 0.3, axis = 0): #饱和排序：proportion:饱和比例（一般为30%）\n",
    "    axis_quantity = A.shape[axis] # axis = 0返回行数，1返回列数\n",
    "    \n",
    "    mins_ori = A.min(axis=axis, keepdims=True)\n",
    "    # A_offset = A - offsets\n",
    "    ranges_ori = (A - mins_ori).max(axis=axis, keepdims=True) + 1e-20\n",
    "    if proportion == 0:\n",
    "        return mins_ori, ranges_ori\n",
    "    elif proportion > 0 and proportion <= 1:\n",
    "        ix_threshold = math.floor(proportion*axis_quantity) # 前proportion%的最后一位\n",
    "        Ato0 = A - ranges_ori/2. - mins_ori # 使A的axis维的最大最小值关于0对称\n",
    "        Ato0abs = np.absolute(Ato0)\n",
    "        Ato0abssort = np.sort(Ato0abs, axis=axis)\n",
    "        if axis == 0:\n",
    "            threshold = Ato0abssort[np.ix_([axis_quantity - ix_threshold], range(Ato0abssort.shape[1]))]\n",
    "        elif axis == 1:\n",
    "            threshold = Ato0abssort[np.ix_(range(Ato0abssort.shape[0]), [axis_quantity - ix_threshold])]\n",
    "        mins_new = ranges_ori/2. + mins_ori - threshold\n",
    "        ranges_new = 2 * threshold\n",
    "        # print('ranges_ori')\n",
    "        # print(ranges_ori)\n",
    "        # print('mins_ori')\n",
    "        # print(mins_ori)\n",
    "        # print('Ato0')\n",
    "        # print(Ato0)\n",
    "        # print('Ato0abs')\n",
    "        # print(Ato0abs)\n",
    "        # print('Ato0abssort')\n",
    "        # print(Ato0abssort)\n",
    "        # print('threshold')\n",
    "        # print(threshold)\n",
    "        return mins_new, ranges_new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zx = np.random.randint(1,100,(11,3))\n",
    "# print(zx)\n",
    "# mins_new, ranges_new = saturation_sort(zx)\n",
    "# print(mins_new, ranges_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _scalar_quantize(A, proportion = 0.3, axis=0, signed=False, nbits=8):\n",
    "    unsigned_maxval = float(1 << int(nbits)) - 1\n",
    "\n",
    "    # # TODO rm\n",
    "    # # return np.zeros((A.shape[0], 1)), np.ones((A.shape[0], 1)), A\n",
    "    # # offsets = np.zeros((A.shape[0], 1))\n",
    "    # offsets = A.min(axis=1, keepdims=True)\n",
    "    # # scales = maxval / np.ones((A.shape[0], 1))\n",
    "    # scales = maxval / A.max(axis=1, keepdims=True)\n",
    "    # Aq = (A - offsets) * scales\n",
    "    # return offsets, scales, Aq\n",
    "    mins, ranges = saturation_sort(A, proportion = proportion, axis = axis)\n",
    "    # maxval = float(1 << int(nbits)) - 1\n",
    "    # mins = A.min(axis=axis, keepdims=True)\n",
    "    # A_offset = A - offsets\n",
    "    # ranges = (A - mins).max(axis=axis, keepdims=True) + 1e-20\n",
    "    # print(\"ranges:\")\n",
    "    # print(ranges)\n",
    "    scales = unsigned_maxval / ranges\n",
    "    # Aq = (A_offset * (maxval / scales)).astype(np.int)\n",
    "    # Aq = (A_offset * scales).astype(np.int)\n",
    "\n",
    "    if signed:\n",
    "        # sign_offset = 1 << (nbits - 1)  # 8 bits -> 128\n",
    "        # A_offset -= sign_offset\n",
    "        offsets = mins + (ranges * (128. / 255))\n",
    "        minval = -(1 << (nbits - 1))\n",
    "        maxval = -minval - 1\n",
    "    else:\n",
    "        offsets = mins\n",
    "        minval = 0\n",
    "        maxval = (1 << nbits) - 1\n",
    "\n",
    "    Aq = (A - offsets) * scales\n",
    "    # print(\"min, max A:\", Aq.min(), Aq.max())  # looks good\n",
    "    Aq = np.clip(Aq, minval, maxval).astype(int)\n",
    "\n",
    "    return offsets, scales, Aq, minval, maxval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_user_quantize(A, B, offsets, scales, minval, maxval, axis=0, signed=False, nbits=8):\n",
    "    Aq = (A - offsets) * scales\n",
    "    Aq = np.clip(Aq, minval, maxval).astype(int) # 量化后的值（整数\n",
    "    Aqreal = Aq / scales + offsets # 量化后对应的实际值\n",
    "    print(\"A:\")\n",
    "    print(A)\n",
    "    print(\"Aq:\")\n",
    "    print(Aq)\n",
    "    print(\"Aqreal\")\n",
    "    print(Aqreal)\n",
    "    C = np.matmul(Aqreal, B)\n",
    "\n",
    "    return C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_user_scalar_quantize(A, B, A_offsets, A_scales, A_minval, A_maxval, B_offsets, B_scales, B_minval, B_maxval):\n",
    "    Aq = (A - A_offsets) * A_scales\n",
    "    Aq = np.clip(Aq, A_minval, A_maxval).astype(int) # 量化后的值（整数\n",
    "    Aqreal = Aq / A_scales + A_offsets # 量化后对应的实际值\n",
    "\n",
    "    Bq = (B - B_offsets) * B_scales\n",
    "    Bq = np.clip(Bq, B_minval, B_maxval).astype(int) # 量化后的值（整数\n",
    "    Bqreal = Bq / B_scales + B_offsets # 量化后对应的实际值\n",
    "\n",
    "    # print(\"A:\")\n",
    "    # print(A)\n",
    "    # print(\"Aq:\")\n",
    "    # print(Aq)\n",
    "    # print(\"Aqreal\")\n",
    "    # print(Aqreal)\n",
    "    C = np.matmul(Aqreal, Bqreal)\n",
    "\n",
    "    return C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ran_mat = np.rint(10*np.random.random(size=(5,5)))\n",
    "# print(ran_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# offsets, scales, Aq, minval, maxval = _scalar_quantize(ran_mat, proportion=prop, axis=0, signed=False, nbits=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0. 2. 1.]]\n",
      "[[51.         36.42857143 42.5        36.42857143 28.33333333]]\n",
      "[[  0 255 170  36   0]\n",
      " [255  72 255 255  28]\n",
      " [204 109  85 109 255]\n",
      " [ 51   0   0   0 141]\n",
      " [102 109 127 255  28]]\n",
      "0\n",
      "255\n"
     ]
    }
   ],
   "source": [
    "# print(offsets)\n",
    "# print(scales)\n",
    "# print(Aq)\n",
    "# print(minval)\n",
    "# print(maxval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(96000, 2048)\n",
      "(2048, 256)\n",
      "(32000, 2048)\n"
     ]
    }
   ],
   "source": [
    "data_to_fc_train = np.load(os.path.join(dir_train, data_to_fcpath_train))\n",
    "print(data_to_fc_train.shape)\n",
    "weight = np.load(os.path.join(dir_train, weightpath))\n",
    "print(weight.shape)\n",
    "data_to_fc_test = np.load(os.path.join(dir_train, data_to_fcpath_test))\n",
    "print(data_to_fc_test.shape)\n",
    "bias = np.load(dir_train+'/'+biaspath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_offsets, train_scales, train_Aq, train_minval, train_maxval = _scalar_quantize(data_to_fc_train, proportion=prop, axis=0, signed=False, nbits=qbits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A:\n",
      "[[ 0.001161   -0.0003292   0.00079327 ...  0.02352978  0.02011615\n",
      "   0.01869451]\n",
      " [-0.00108941 -0.0003551  -0.00034218 ...  0.01012411  0.00046477\n",
      "   0.00978941]\n",
      " [ 0.00097858  0.00035693  0.00280184 ... -0.01709364  0.01152093\n",
      "   0.00830318]\n",
      " ...\n",
      " [ 0.0044448  -0.00065186  0.00043888 ... -0.0145436  -0.00225845\n",
      "   0.00354694]\n",
      " [ 0.00094269 -0.0011471   0.00078288 ...  0.00279342  0.00330969\n",
      "  -0.01324401]\n",
      " [ 0.00324066  0.00071579  0.00377456 ... -0.0036882   0.00070076\n",
      "  -0.00470257]]\n",
      "Aq:\n",
      "[[163 130 181 ... 255 255 255]\n",
      " [ 20 126  62 ... 135 102 255]\n",
      " [151 235 255 ...   0 251 255]\n",
      " ...\n",
      " [255  81 144 ...   0  65 223]\n",
      " [149   5 179 ...  66 140  57]\n",
      " [255 255 255 ...   6 105 142]]\n",
      "Aqreal\n",
      "[[ 0.00115585 -0.000333    0.00079299 ...  0.02292155  0.01175397\n",
      "   0.00669053]\n",
      " [-0.00109537 -0.00035916 -0.00034607 ...  0.01007552  0.00046017\n",
      "   0.00669053]\n",
      " [ 0.00096694  0.00035359  0.00150132 ... -0.00437626  0.01145871\n",
      "   0.00669053]\n",
      " ...\n",
      " [ 0.00260419 -0.00065341  0.00043883 ... -0.00437626 -0.00227101\n",
      "   0.00346258]\n",
      " [ 0.00093545 -0.00115038  0.00077385 ...  0.00268905  0.00326517\n",
      "  -0.01328244]\n",
      " [ 0.00260419  0.00048438  0.00150132 ... -0.00373396  0.00068162\n",
      "  -0.00470819]]\n"
     ]
    }
   ],
   "source": [
    "if user_method == \"METHOD_USER_QUANTIZE\":\n",
    "    y_out_matmul = test_user_quantize(data_to_fc_test, weight, train_offsets, train_scales, train_minval, train_maxval)\n",
    "    y_out_last = y_out_matmul + bias.T # MADDNESS替换后当前层输出，即+bias并不需要激活函数后的结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.0632925   0.11510547 -0.38953638 ... -0.00586694 -0.0227966\n",
      "   0.07346666]\n",
      " [-0.11025896  0.01035206 -0.18747466 ... -0.22178045 -0.02247104\n",
      "  -0.01913035]\n",
      " [ 0.09450215  0.10371651 -0.19693512 ... -0.1460753   0.02490801\n",
      "   0.15774144]\n",
      " ...\n",
      " [ 0.1046813   0.06164711 -0.35373129 ... -0.03216408 -0.10479045\n",
      "  -0.08956613]\n",
      " [ 0.1305362   0.0284576  -0.22534953 ...  0.03662261 -0.01087786\n",
      "   0.03341703]\n",
      " [ 0.00086727  0.11816691 -0.30380601 ... -0.09984724 -0.1072027\n",
      "  -0.00366244]]\n",
      "float64\n",
      "(32000, 256)\n"
     ]
    }
   ],
   "source": [
    "if user_method == \"METHOD_USER_QUANTIZE\":\n",
    "    print(y_out_last)\n",
    "    print(y_out_last.dtype)\n",
    "    print(y_out_last.shape)\n",
    "    np.save(dir_result+'/'+'UserQuantize'+'fc1_prop%0.3f_fb%i_qb%i.npy' % (prop, feedback_bits, qbits), y_out_last.astype(np.float32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(train_offsets.shape)\n",
    "# print(train_scales.shape)\n",
    "# print(train_Aq.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(train_offsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if user_method == \"METHOD_USER_SCALAR_QUANTIZE\":\n",
    "    weight_offsets, weight_scales, weight_Aq, weight_minval, weight_maxval = _scalar_quantize(weight, proportion=prop, axis=1, signed=False, nbits=qbits)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('pqhdr')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ec04f7dc2b3ae4a422de9aaf96e8c62fe190a2869a08d14112cb2d7713497448"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
