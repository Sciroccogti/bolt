{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "合并decoder transformer层的linear层（dtl）训练数据集（e39_0-6999）,测试数据集（e39_7000-7999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import socket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bits = 256\n",
    "batch_size = 32\n",
    "S1 = 32 # linear大小为batch_size*S1*S2\n",
    "whole_train_sam_num = 7000 # 完整的训练集样本数\n",
    "smaller_train_sam_num = 3000 # 减小内存消耗的训练集样本数\n",
    "smallerer_train_sam_num = 1000\n",
    "smallererer_train_sam_num = 500\n",
    "smallerererer_train_sam_num = 50\n",
    "\n",
    "test_sam_num = 1000\n",
    "\n",
    "host_name = socket.gethostname()\n",
    "if host_name == 'DESKTOP-PLRL7TK':\n",
    "    dir_intermediate = ''\n",
    "elif host_name == 'DESKTOP-6FOH47P':\n",
    "    dir_intermediate = 'F:\\\\Projects\\\\python\\\\PQ\\\\intermediate8dbfc1\\\\'\n",
    "elif host_name == 'jm-System-Product-Name':\n",
    "    dir_intermediate = '/data/hdr/transformer_data/intermediate/'\n",
    "    dir_train = os.path.join('/data/hdr/transformer_data/joined', 'train', 'f'+str(bits))\n",
    "    dir_test = os.path.join('/data/hdr/transformer_data/joined', 'test', 'f'+str(bits))\n",
    "    # dir1 = '/data/hdr/transformer_data/joined/'\n",
    "else:\n",
    "    raise NameError(\"You are running the script in a new computer, please define dir_intermediate\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_from_intermediate_j1(dir_intermediate, dir_t, bits, intermediate_name, sam_num, trainortest):#j1代表合并第一维\n",
    "    #sam_num:合并的样本数;trainortest:合成训练集填\"train\",测试集填\"test\"\n",
    "    linearpath0= os.path.join(dir_intermediate, str(bits), intermediate_name+'_f%i_e39_0.npy' % bits)#例：此处intermediate_name为linear\n",
    "    linear0 = np.load(linearpath0)\n",
    "    print(\"合并第一维前大小：\", linear0.shape)\n",
    "    #把第一维合并\n",
    "    linear0_join1 = np.reshape(linear0, (-1, linear0.shape[-1]))\n",
    "    print(\"合并第一维后大小：\", linear0_join1.shape)\n",
    "    if trainortest == \"test\":\n",
    "        add = 7000\n",
    "    else:\n",
    "        add = 0\n",
    "    for i in range(1+add, sam_num+add):\n",
    "        linearpath1= os.path.join(dir_intermediate, str(bits), intermediate_name+'_f%i_e39_%i.npy' % (bits, i) )\n",
    "        linear1 = np.load(linearpath1)\n",
    "        linear1_join1 = np.reshape(linear1, (-1, linear1.shape[-1]))\n",
    "        if linear1_join1.shape[0]!=1024:\n",
    "            print(\"i\",str(i),\",shape\",str(linear1_join1.shape[0]))\n",
    "        linear0_join1 = np.append(linear0_join1, linear1_join1, axis=0)\n",
    "    print(linear0_join1.shape)\n",
    "    np.save(os.path.join(dir_t, '%s_%s_f%i_sam%i.npy' % (intermediate_name,trainortest,bits,sam_num)), linear0_join1) \n",
    "    # linear_name = \"\"\n",
    "    # if intermediate_name[-2:] == \"in\":\n",
    "    #     linear_name=intermediate_name[:-2]\n",
    "    print(\"intermediate_name[-3:] == out:\",intermediate_name[-3:] == \"out\")\n",
    "    if intermediate_name[-3:] == \"out\":\n",
    "        \n",
    "        linear_name=intermediate_name[:-3]\n",
    "        bias = np.load(os.path.join(dir_train, \"%s_b_f%i.npy\" % (linear_name, bits)))\n",
    "        y = linear0_join1 - bias\n",
    "        np.save(os.path.join(dir_t, '%s_y_%s_f%i_sam%i.npy' % (linear_name, trainortest, bits, sam_num)), y) \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_from_joined(dir_t, intermediate_name, bits, joined_sam_num, sam_num, batch_size, S1, trainortest):# 从已合成训练/测试集中提取更小的训练测试集\n",
    "    # 例:intermediate_name:'ex_linear1in'\n",
    "    # joined_sam_num：已合成训练/测试集的样本数\n",
    "    # sam_num：提取出的训练/测试集的样本数\n",
    "    linear_whole = np.load(os.path.join(dir_t,  '%s_%s_f%i_sam%i.npy' % (intermediate_name, trainortest, bits,joined_sam_num)))\n",
    "    print(linear_whole.shape)\n",
    "    linear_smaller = linear_whole[np.ix_(range(sam_num*batch_size*S1), range(linear_whole.shape[1]))]\n",
    "    print(linear_smaller.shape)\n",
    "    np.save(os.path.join(dir_t, '%s_train_f%i_sam%i.npy' % (intermediate_name, bits, sam_num)), linear_smaller) \n",
    "    if intermediate_name[-3:] == \"out\":\n",
    "        linear_name=intermediate_name[:-3]\n",
    "        bias = np.load(os.path.join(dir_train, \"%s_b_f%i.npy\" % (linear_name, bits)))\n",
    "        y = linear_smaller - bias\n",
    "        np.save(os.path.join(dir_t, '%s_y_%s_f%i_sam%i.npy' % (linear_name, trainortest, bits, sam_num)), y) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 合并dx_linear1训练数据集（e39_0-6999），把第一维合并"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "合并第一维前大小： (32, 32, 64)\n",
      "合并第一维后大小： (1024, 64)\n",
      "(7168000, 64)\n"
     ]
    }
   ],
   "source": [
    "join_from_intermediate_j1(dir_intermediate, dir_train, bits, \"dx_linear1in\", whole_train_sam_num, \"train\")#j1代表合并第一维"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7168000, 64)\n",
      "(3072000, 64)\n"
     ]
    }
   ],
   "source": [
    "join_from_joined(dir_train, \"dx_linear1in\", bits, whole_train_sam_num, smaller_train_sam_num, batch_size, S1, \"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3072000, 64)\n",
      "(1024000, 64)\n"
     ]
    }
   ],
   "source": [
    "join_from_joined(dir_train, \"dx_linear1in\", bits, smaller_train_sam_num, smallerer_train_sam_num, batch_size, S1, \"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1024000, 64)\n",
      "(512000, 64)\n"
     ]
    }
   ],
   "source": [
    "join_from_joined(dir_train, \"dx_linear1in\", bits, smallerer_train_sam_num, smallererer_train_sam_num, batch_size, S1, \"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512000, 64)\n",
      "(51200, 64)\n"
     ]
    }
   ],
   "source": [
    "join_from_joined(dir_train, \"dx_linear1in\", bits, smallererer_train_sam_num, smallerererer_train_sam_num, batch_size, S1, \"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "合并第一维前大小： (32, 32, 128)\n",
      "合并第一维后大小： (1024, 128)\n",
      "(7168000, 128)\n",
      "(7168000, 128)\n",
      "(3072000, 128)\n",
      "(3072000, 128)\n",
      "(1024000, 128)\n",
      "(1024000, 128)\n",
      "(512000, 128)\n",
      "(512000, 128)\n",
      "(51200, 128)\n"
     ]
    }
   ],
   "source": [
    "join_from_intermediate_j1(dir_intermediate, dir_train, bits, \"dx_linear1out\", whole_train_sam_num, \"train\")#j1代表合并第一维\n",
    "join_from_joined(dir_train, \"dx_linear1out\", bits, whole_train_sam_num, smaller_train_sam_num, batch_size, S1, \"train\")\n",
    "join_from_joined(dir_train, \"dx_linear1out\", bits, smaller_train_sam_num, smallerer_train_sam_num, batch_size, S1, \"train\")\n",
    "join_from_joined(dir_train, \"dx_linear1out\", bits, smallerer_train_sam_num, smallererer_train_sam_num, batch_size, S1, \"train\")\n",
    "join_from_joined(dir_train, \"dx_linear1out\", bits, smallererer_train_sam_num, smallerererer_train_sam_num, batch_size, S1, \"train\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128,)\n"
     ]
    }
   ],
   "source": [
    "# bias = np.load(os.path.join(dir_train, \"dx_linear1_b_f%i.npy\" % bits))\n",
    "# print(bias.shape)\n",
    "# dx_linear1_trainpath= os.path.join(dir_train, 'dx_linear1out_train_f%i_sam%i.npy' % (bits, whole_train_sam_num))\n",
    "# dx_linear1_train = np.load(dx_linear1_trainpath, mmap_mode=None, allow_pickle=False, fix_imports=True, encoding='ASCII')\n",
    "# y_smaller = dx_linear1_train - bias\n",
    "# np.save(os.path.join(dir_train, 'dx_linear1_y_train_f%i_sam%i.npy' % (bits, whole_train_sam_num)), y_smaller) \n",
    "# # y_smallerer = ex_linear1out_smallerer - bias\n",
    "# # np.save(os.path.join(dir_train, 'ex_linear1_y_train_f%i_sam%i.npy' % (bits, smallerer_train_sam_num)), y_smallerer) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dx_linear1_trainpath= os.path.join(dir_train, 'dx_linear1out_train_f%i_sam%i.npy' % (bits, smallerererer_train_sam_num))\n",
    "# dx_linear1_train = np.load(dx_linear1_trainpath, mmap_mode=None, allow_pickle=False, fix_imports=True, encoding='ASCII')\n",
    "# y_smaller = dx_linear1_train - bias\n",
    "# np.save(os.path.join(dir_train, 'dx_linear1_y_train_f%i_sam%i.npy' % (bits, smallerererer_train_sam_num)), y_smaller) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 合并ex_linear2训练数据集（e39_0-6999），把第一维合并"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "合并第一维前大小： (32, 32, 128)\n",
      "合并第一维后大小： (1024, 128)\n",
      "(7168000, 128)\n"
     ]
    }
   ],
   "source": [
    "join_from_intermediate_j1(dir_intermediate, dir_train, bits, \"dx_linear2in\", whole_train_sam_num, \"train\")#j1代表合并第一维"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7168000, 128)\n",
      "(3072000, 128)\n",
      "(3072000, 128)\n",
      "(1024000, 128)\n",
      "(1024000, 128)\n",
      "(512000, 128)\n",
      "(512000, 128)\n",
      "(51200, 128)\n"
     ]
    }
   ],
   "source": [
    "join_from_joined(dir_train, \"dx_linear2in\", bits, whole_train_sam_num, smaller_train_sam_num, batch_size, S1, \"train\")\n",
    "join_from_joined(dir_train, \"dx_linear2in\", bits, smaller_train_sam_num, smallerer_train_sam_num, batch_size, S1, \"train\")\n",
    "join_from_joined(dir_train, \"dx_linear2in\", bits, smallerer_train_sam_num, smallererer_train_sam_num, batch_size, S1, \"train\")\n",
    "join_from_joined(dir_train, \"dx_linear2in\", bits, smallererer_train_sam_num, smallerererer_train_sam_num, batch_size, S1, \"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "join_from_intermediate_j1(dir_intermediate, dir_train, bits, \"dx_linear2out\", whole_train_sam_num, \"train\")#j1代表合并第一维\n",
    "join_from_joined(dir_train, \"dx_linear2out\", bits, whole_train_sam_num, smaller_train_sam_num, batch_size, S1, \"train\")\n",
    "join_from_joined(dir_train, \"dx_linear2out\", bits, smaller_train_sam_num, smallerer_train_sam_num, batch_size, S1, \"train\")\n",
    "join_from_joined(dir_train, \"dx_linear2out\", bits, smallerer_train_sam_num, smallererer_train_sam_num, batch_size, S1, \"train\")\n",
    "join_from_joined(dir_train, \"dx_linear2out\", bits, smallererer_train_sam_num, smallerererer_train_sam_num, batch_size, S1, \"train\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 合并dx_linear1测试数据集（e39_7000-7999），把第一维合并"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "合并第一维前大小： (32, 32, 64)\n",
      "合并第一维后大小： (1024, 64)\n",
      "(1024000, 64)\n"
     ]
    }
   ],
   "source": [
    "join_from_intermediate_j1(dir_intermediate, dir_test, bits, \"dx_linear1in\", test_sam_num, \"test\")#j1代表合并第一维"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "合并第一维前大小： (32, 32, 128)\n",
      "合并第一维后大小： (1024, 128)\n",
      "(1024000, 128)\n",
      "intermediate_name[-3:] == out: True\n"
     ]
    }
   ],
   "source": [
    "join_from_intermediate_j1(dir_intermediate, dir_test, bits, \"dx_linear1out\", test_sam_num, \"test\")#j1代表合并第一维"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 合并ex_linear2测试数据集（e39_7000-7999），把第一维合并"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "合并第一维前大小： (32, 32, 128)\n",
      "合并第一维后大小： (1024, 128)\n",
      "(1024000, 128)\n",
      "intermediate_name[-3:] == out: False\n",
      "合并第一维前大小： (32, 32, 64)\n",
      "合并第一维后大小： (1024, 64)\n",
      "(1024000, 64)\n",
      "intermediate_name[-3:] == out: True\n"
     ]
    }
   ],
   "source": [
    "join_from_intermediate_j1(dir_intermediate, dir_test, bits, \"dx_linear2in\", test_sam_num, \"test\")#j1代表合并第一维\n",
    "join_from_intermediate_j1(dir_intermediate, dir_test, bits, \"dx_linear2out\", test_sam_num, \"test\")#j1代表合并第一维\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('pqhdr')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ec04f7dc2b3ae4a422de9aaf96e8c62fe190a2869a08d14112cb2d7713497448"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
