{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "dir_now = os.getcwd()\n",
    "sys.path.append(dir_now)\n",
    "sys.path.append(os.path.join(dir_now, '../'))\n",
    "import matmul as mm\n",
    "import math_util as mu\n",
    "import scipy.io as io\n",
    "from amm_methods import *\n",
    "import socket # Obtain the current host name, which can be used to select different data directories and result saving directories\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method = METHOD_MITHRAL\n",
    "# method = METHOD_PQ\n",
    "# method = METHOD_EXACT\n",
    "method = METHOD_SCALAR_QUANTIZE\n",
    "user_method = \"METHOD_USER_SCALAR_QUANTIZE\"\n",
    "# user_method = \"METHOD_USER_QUANTIZE\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "feedback_bits = 256\n",
    "ncodebooks=64\n",
    "ncentroids=256\n",
    "train_sam_num = 3000 # 训练集样本数\n",
    "qbits = 8\n",
    "prop_A = 0\n",
    "prop_B = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "host_name = socket.gethostname()\n",
    "if host_name == 'DESKTOP-PLRL7TK':\n",
    "    dir_train = 'E:\\\\hdr\\\\研一\\\\华为-深度学习\\\\intermediate\\\\intermediate8dbfc1'\n",
    "    dir_result = ''\n",
    "elif host_name == 'DESKTOP-6FOH47P':\n",
    "    dir_train = 'F:\\\\Projects\\\\python\\\\PQ\\\\intermediate8dbfc1'\n",
    "    dir_result = 'F:\\\\Projects\\\\python\\\\PQ\\\\res'\n",
    "    data_to_fcpath_train= 'data_to_fc_e39_7999.npy'\n",
    "    featurepath_train= 'feature_e39_7999.npy'\n",
    "    data_to_fcpath_test = 'data_to_fc_e39_7999.npy'\n",
    "    featurepath_test = 'feature_e39_7999.npy'\n",
    "elif host_name == 'jm-System-Product-Name':\n",
    "    dir_train = os.path.join('/data/hdr/transformer_data/joined', 'train', 'f'+str(feedback_bits))\n",
    "    dir_test = os.path.join('/data/hdr/transformer_data/joined', 'test', 'f'+str(feedback_bits))\n",
    "    dir_result = '/data/hdr/pq/res'\n",
    "    data_to_fcpath_train= 'data_to_fc_train_f%i_sam%i.npy' % (feedback_bits, train_sam_num)\n",
    "    y_train = 'y_train_f%i_sam%i.npy' % (feedback_bits, train_sam_num)\n",
    "    featurepath_train= 'feature_train_f%i_sam%i.npy' % (feedback_bits, train_sam_num)\n",
    "    data_to_fcpath_test = 'data_to_fc_test.npy'\n",
    "    featurepath_test = 'feature_test.npy'\n",
    "    y_test = 'y_test.npy'\n",
    "else:\n",
    "    raise NameError(\"You are running the script in a new computer, please define dir_train\")\n",
    "\n",
    "\n",
    "weightpath = 'encoder_fcw.npy'\n",
    "biaspath = 'encoder_fcb.npy'\n",
    "\n",
    "# dir_result = os.path.join(dir_result, method)\n",
    "dir_result = os.path.join(dir_result, method, \"f%i\" % feedback_bits, \"fc1\")\n",
    "try:\n",
    "    os.mkdir(dir_result)\n",
    "except FileExistsError:\n",
    "    pass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from turtle import right\n",
    "\n",
    "\n",
    "def saturation_sort(A, proportion = 0.3, axis = 0): #饱和排序：proportion:饱和比例（一般为30%）\n",
    "    axis_quantity = A.shape[axis] # axis = 0返回行数，1返回列数\n",
    "    \n",
    "    mins_ori = A.min(axis=axis, keepdims=True)\n",
    "    # A_offset = A - offsets\n",
    "    ranges_ori = (A - mins_ori).max(axis=axis, keepdims=True) + 1e-20\n",
    "    if proportion == 0:\n",
    "        return mins_ori, ranges_ori\n",
    "    elif proportion > 0 and proportion <= 1:\n",
    "        ix_threshold = math.floor(proportion*axis_quantity) # 前proportion%的最后一位\n",
    "        Ato0 = A - ranges_ori/2. - mins_ori # 使A的axis维的最大最小值关于0对称\n",
    "        Ato0abs = np.absolute(Ato0)\n",
    "        Ato0abssort = np.sort(Ato0abs, axis=axis)\n",
    "        if axis == 0:\n",
    "            threshold = Ato0abssort[np.ix_([axis_quantity - ix_threshold], range(Ato0abssort.shape[1]))]\n",
    "        elif axis == 1:\n",
    "            threshold = Ato0abssort[np.ix_(range(Ato0abssort.shape[0]), [axis_quantity - ix_threshold])]\n",
    "        mins_new = ranges_ori/2. + mins_ori - threshold\n",
    "        ranges_new = 2 * threshold\n",
    "        # print('ranges_ori')\n",
    "        # print(ranges_ori)\n",
    "        # print('mins_ori')\n",
    "        # print(mins_ori)\n",
    "        # print('Ato0')\n",
    "        # print(Ato0)\n",
    "        # print('Ato0abs')\n",
    "        # print(Ato0abs)\n",
    "        # print('Ato0abssort')\n",
    "        # print(Ato0abssort)\n",
    "        # print('threshold')\n",
    "        # print(threshold)\n",
    "        return mins_new, ranges_new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zx = np.random.randint(1,100,(11,3))\n",
    "# print(zx)\n",
    "# mins_new, ranges_new = saturation_sort(zx)\n",
    "# print(mins_new, ranges_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _scalar_quantize(A, proportion = 0.3, axis=0, signed=False, nbits=8):\n",
    "    unsigned_maxval = float(1 << int(nbits)) - 1\n",
    "\n",
    "    # # TODO rm\n",
    "    # # return np.zeros((A.shape[0], 1)), np.ones((A.shape[0], 1)), A\n",
    "    # # offsets = np.zeros((A.shape[0], 1))\n",
    "    # offsets = A.min(axis=1, keepdims=True)\n",
    "    # # scales = maxval / np.ones((A.shape[0], 1))\n",
    "    # scales = maxval / A.max(axis=1, keepdims=True)\n",
    "    # Aq = (A - offsets) * scales\n",
    "    # return offsets, scales, Aq\n",
    "    mins, ranges = saturation_sort(A, proportion = proportion, axis = axis)\n",
    "    # maxval = float(1 << int(nbits)) - 1\n",
    "    # mins = A.min(axis=axis, keepdims=True)\n",
    "    # A_offset = A - offsets\n",
    "    # ranges = (A - mins).max(axis=axis, keepdims=True) + 1e-20\n",
    "    # print(\"ranges:\")\n",
    "    # print(ranges)\n",
    "    scales = unsigned_maxval / ranges\n",
    "    # Aq = (A_offset * (maxval / scales)).astype(np.int)\n",
    "    # Aq = (A_offset * scales).astype(np.int)\n",
    "\n",
    "    if signed:\n",
    "        # sign_offset = 1 << (nbits - 1)  # 8 bits -> 128\n",
    "        # A_offset -= sign_offset\n",
    "        offsets = mins + (ranges * (128. / 255))\n",
    "        minval = -(1 << (nbits - 1))\n",
    "        maxval = -minval - 1\n",
    "    else:\n",
    "        offsets = mins\n",
    "        minval = 0\n",
    "        maxval = (1 << nbits) - 1\n",
    "\n",
    "    Aq = (A - offsets) * scales\n",
    "    # print(\"min, max A:\", Aq.min(), Aq.max())  # looks good\n",
    "    Aq = np.clip(Aq, minval, maxval).astype(int)\n",
    "\n",
    "    return offsets, scales, Aq, minval, maxval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_user_quantize(A, B, offsets, scales, minval, maxval, axis=0, signed=False, nbits=8):\n",
    "    Aq = (A - offsets) * scales\n",
    "    Aq = np.clip(Aq, minval, maxval).astype(int) # 量化后的值（整数\n",
    "    Aqreal = Aq / scales + offsets # 量化后对应的实际值\n",
    "    print(\"A:\")\n",
    "    print(A)\n",
    "    print(\"Aq:\")\n",
    "    print(Aq)\n",
    "    print(\"Aqreal\")\n",
    "    print(Aqreal)\n",
    "    C = np.matmul(Aqreal, B)\n",
    "\n",
    "    return C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_user_scalar_quantize(A, B, A_offsets, A_scales, A_minval, A_maxval, B_offsets, B_scales, B_minval, B_maxval):\n",
    "    Aq = (A - A_offsets) * A_scales\n",
    "    Aq = np.clip(Aq, A_minval, A_maxval).astype(int) # 量化后的值（整数\n",
    "    Aqreal = Aq / A_scales + A_offsets # 量化后对应的实际值\n",
    "\n",
    "    Bq = (B - B_offsets) * B_scales\n",
    "    Bq = np.clip(Bq, B_minval, B_maxval).astype(int) # 量化后的值（整数\n",
    "    Bqreal = Bq / B_scales + B_offsets # 量化后对应的实际值\n",
    "\n",
    "    # print(\"A:\")\n",
    "    # print(A)\n",
    "    # print(\"Aq:\")\n",
    "    # print(Aq)\n",
    "    # print(\"Aqreal\")\n",
    "    # print(Aqreal)\n",
    "    C = np.matmul(Aqreal, Bqreal)\n",
    "\n",
    "    return C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ran_mat = np.rint(10*np.random.random(size=(5,5)))\n",
    "# print(ran_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# offsets, scales, Aq, minval, maxval = _scalar_quantize(ran_mat, proportion=prop, axis=0, signed=False, nbits=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(offsets)\n",
    "# print(scales)\n",
    "# print(Aq)\n",
    "# print(minval)\n",
    "# print(maxval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(96000, 2048)\n",
      "(2048, 256)\n",
      "(32000, 2048)\n"
     ]
    }
   ],
   "source": [
    "data_to_fc_train = np.load(os.path.join(dir_train, data_to_fcpath_train))\n",
    "print(data_to_fc_train.shape)\n",
    "weight = np.load(os.path.join(dir_train, weightpath))\n",
    "print(weight.shape)\n",
    "data_to_fc_test = np.load(os.path.join(dir_test, data_to_fcpath_test))\n",
    "print(data_to_fc_test.shape)\n",
    "bias = np.load(dir_train+'/'+biaspath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_offsets, train_scales, train_Aq, train_minval, train_maxval = _scalar_quantize(data_to_fc_train, proportion=prop_A, axis=0, signed=False, nbits=qbits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if user_method == \"METHOD_USER_QUANTIZE\":\n",
    "    y_out_matmul = test_user_quantize(data_to_fc_test, weight, train_offsets, train_scales, train_minval, train_maxval)\n",
    "    y_out_last = y_out_matmul + bias.T # MADDNESS替换后当前层输出，即+bias并不需要激活函数后的结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if user_method == \"METHOD_USER_QUANTIZE\":\n",
    "    print(y_out_last)\n",
    "    print(y_out_last.dtype)\n",
    "    print(y_out_last.shape)\n",
    "    np.save(dir_result+'/'+'UserQuantize'+'fc1_prop%0.3f_fb%i_qb%i.npy' % (prop, feedback_bits, qbits), y_out_last.astype(np.float32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(train_offsets.shape)\n",
    "# print(train_scales.shape)\n",
    "# print(train_Aq.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(train_offsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "if user_method == \"METHOD_USER_SCALAR_QUANTIZE\":\n",
    "    weight_offsets, weight_scales, weight_Aq, weight_minval, weight_maxval = _scalar_quantize(weight, proportion=prop_B, axis=1, signed=False, nbits=qbits)\n",
    "    y_out_matmul = test_user_scalar_quantize(data_to_fc_test, weight, train_offsets, train_scales, train_minval, train_maxval, weight_offsets, weight_scales, weight_minval, weight_maxval)\n",
    "    y_out_last = y_out_matmul + bias.T # MADDNESS替换后当前层输出，即+bias并不需要激活函数后的结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.08589713  0.01957862 -0.54318082 ... -0.07518468  0.08027018\n",
      "   0.00573426]\n",
      " [-0.23335717 -0.12642624 -0.29166916 ... -0.37956292  0.01083382\n",
      "  -0.07693753]\n",
      " [ 0.39297602 -0.04998817 -0.23789372 ... -0.50742883  0.18774957\n",
      "   0.11985465]\n",
      " ...\n",
      " [ 0.35143678  0.1430799  -0.52140565 ... -0.17485511 -0.2048602\n",
      "   0.00773251]\n",
      " [ 0.24491932  0.01230494 -0.24259499 ...  0.05879867 -0.00268466\n",
      "   0.05266514]\n",
      " [-0.30797064  0.11154683 -0.42690159 ... -0.34412207 -0.14496699\n",
      "   0.17692375]]\n",
      "float64\n",
      "(32000, 256)\n"
     ]
    }
   ],
   "source": [
    "if user_method == \"METHOD_USER_SCALAR_QUANTIZE\":\n",
    "    print(y_out_last)\n",
    "    print(y_out_last.dtype)\n",
    "    print(y_out_last.shape)\n",
    "    np.save(dir_result+'/'+'UserScalarQuantize'+'fc1_propA%0.3f_propB%0.3f_fb%i_qb%i.npy' % (prop_A, prop_B, feedback_bits, qbits), y_out_last.astype(np.float32))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('pqhdr')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ec04f7dc2b3ae4a422de9aaf96e8c62fe190a2869a08d14112cb2d7713497448"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
