{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 合并data_to_fc/feature训练数据集（e39_0-6999）,测试数据集（e39_7000-7999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import socket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bits = 64\n",
    "batch_size = 32\n",
    "whole_train_sam_num = 7000 # 完整的训练集样本数\n",
    "smaller_train_sam_num = 3000 # 减小内存消耗的训练集样本数\n",
    "smallerer_train_sam_num = 1000\n",
    "\n",
    "host_name = socket.gethostname()\n",
    "if host_name == 'DESKTOP-PLRL7TK':\n",
    "    dir_intermediate = ''\n",
    "elif host_name == 'DESKTOP-6FOH47P':\n",
    "    dir_intermediate = 'F:\\\\Projects\\\\python\\\\PQ\\\\intermediate8dbfc1\\\\'\n",
    "elif host_name == 'jm-System-Product-Name':\n",
    "    dir_intermediate = '/data/hdr/transformer_data/intermediate/'+str(bits)+'/'\n",
    "    dir_train = os.path.join('/data/hdr/transformer_data/joined', 'train', 'f'+str(bits))\n",
    "    dir_test = os.path.join('/data/hdr/transformer_data/joined', 'test', 'f'+str(bits))\n",
    "    # dir1 = '/data/hdr/transformer_data/joined/'\n",
    "    # dir2 = '/data/hdr/transformer_data/model/'\n",
    "else:\n",
    "    raise NameError(\"You are running the script in a new computer, please define dir_intermediate\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_from_intermediate(dir_intermediate, dir_train, bits, intermediate_name, sam_num, trainortest):#不需要合并第一维\n",
    "    #sam_num:合并的样本数;trainortest:合成训练集填\"train\",测试集填\"test\"\n",
    "    linearinpath0= os.path.join(dir_intermediate, str(bits), intermediate_name+'_f%i_e39_0.npy' % bits)#例：此处intermediate_name为linearin\n",
    "    linearin0 = np.load(linearinpath0)\n",
    "    print(\"合并第一维前大小：\", linearin0.shape)\n",
    "    #把第一维合并\n",
    "    # linearin0_join1 = np.reshape(linearin0, (-1, linearin0.shape[-1]))\n",
    "    # print(\"合并第一维后大小：\", linearin0_join1.shape)\n",
    "    if trainortest == \"test\":\n",
    "        add = 7000\n",
    "    else:\n",
    "        add = 0\n",
    "    for i in range(1+add, sam_num+add):\n",
    "        linearinpath1= os.path.join(dir_intermediate, str(bits), intermediate_name+'_f%i_e39_%i.npy' % (bits, i) )\n",
    "        linearin1 = np.load(linearinpath1)\n",
    "        linearin1 = np.reshape(linearin1, (-1, linearin1.shape[-1]))\n",
    "        if linearin1.shape[0]!=1024:\n",
    "            print(\"i\",str(i),\",shape\",str(linearin1.shape[0]))\n",
    "        linearin0 = np.append(linearin0, linearin1, axis=0)\n",
    "    print(linearin0.shape)\n",
    "    np.save(os.path.join(dir_train, intermediate_name+trainortest+'_f%i_sam%i.npy' % (bits,whole_train_sam_num)), linearin0) \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_from_joined(dir_train, linear_name, bits, joined_sam_num, smaller_sam_sum, batch_size):# 从已合成训练/测试集中提取更小的训练测试集\n",
    "    # 例:linear_name:'ex_linear1in'\n",
    "    # joined_sam_num：已合成训练/测试集的样本数\n",
    "    # sam_num：提取出的训练/测试集的样本数\n",
    "    ex_linear1in_whole = np.load(os.path.join(dir_train, linear_name + '_train_f%i_sam%i.npy' % (bits,joined_sam_num)))\n",
    "    print(ex_linear1in_whole.shape)\n",
    "    ex_linear1in_smaller = ex_linear1in_whole[np.ix_(range(smaller_sam_sum*batch_size), range(ex_linear1in_whole.shape[1]))]\n",
    "    print(ex_linear1in_smaller.shape)\n",
    "    np.save(os.path.join(dir_train, '%s_train_f%i_sam%i.npy' % (linear_name, bits, smaller_sam_sum)), ex_linear1in_smaller) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224000, 2048)\n"
     ]
    }
   ],
   "source": [
    "data_to_fcpath0= os.path.join(dir_intermediate, 'data_to_fc_f%i_e39_0.npy' % bits)\n",
    "data_to_fc0 = np.load(data_to_fcpath0, mmap_mode=None, allow_pickle=False, fix_imports=True, encoding='ASCII')\n",
    "# 合并data_to_fc训练数据集（e39_0-6999）\n",
    "for i in range(1,whole_train_sam_num):\n",
    "    data_to_fcpath1= os.path.join(dir_intermediate, 'data_to_fc_f%i_e39_%i.npy' % (bits, i) )\n",
    "    data_to_fc1 = np.load(data_to_fcpath1, mmap_mode=None, allow_pickle=False, fix_imports=True, encoding='ASCII')\n",
    "    data_to_fc0 = np.append(data_to_fc0, data_to_fc1, axis=0)\n",
    "print(data_to_fc0.shape)\n",
    "np.save(os.path.join(dir_train, 'data_to_fc_train_f%i_sam%i.npy' % (bits, whole_train_sam_num)), data_to_fc0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224000, 2048)\n",
      "(96000, 2048)\n"
     ]
    }
   ],
   "source": [
    "join_from_joined(dir_train, \"data_to_fc\", bits, whole_train_sam_num, smaller_train_sam_num, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224000, 64)\n"
     ]
    }
   ],
   "source": [
    "featurepath0= os.path.join(dir_intermediate, 'feature_f%i_e39_0.npy' % bits)\n",
    "feature0 = np.load(featurepath0, mmap_mode=None, allow_pickle=False, fix_imports=True, encoding='ASCII')\n",
    "# 合并feature训练数据集（e39_0-6999）\n",
    "for i in range(1,whole_train_sam_num):\n",
    "    featurepath1= os.path.join(dir_intermediate, 'feature_f%i_e39_%i.npy' % (bits, i) )\n",
    "    feature1 = np.load(featurepath1, mmap_mode=None, allow_pickle=False, fix_imports=True, encoding='ASCII')\n",
    "    feature0 = np.append(feature0, feature1, axis=0)\n",
    "print(feature0.shape)\n",
    "np.save(os.path.join(dir_train, 'feature_train_f%i_sam%i.npy' % (bits, whole_train_sam_num)), feature0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224000, 64)\n",
      "(96000, 64)\n"
     ]
    }
   ],
   "source": [
    "join_from_joined(dir_train, \"feature\", bits, whole_train_sam_num, smaller_train_sam_num, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32000, 64)\n"
     ]
    }
   ],
   "source": [
    "featurepath0= os.path.join(dir_intermediate, 'feature_f%i_e39_7000.npy' % bits)\n",
    "feature0 = np.load(featurepath0, mmap_mode=None, allow_pickle=False, fix_imports=True, encoding='ASCII')\n",
    "# 合并feature测试数据集（e39_7000-7999）\n",
    "for i in range(7001,8000):\n",
    "    featurepath1= os.path.join(dir_intermediate, 'feature_f%i_e39_%i.npy' % (bits, i) )\n",
    "    feature1 = np.load(featurepath1, mmap_mode=None, allow_pickle=False, fix_imports=True, encoding='ASCII')\n",
    "    feature0 = np.append(feature0, feature1, axis=0)\n",
    "print(feature0.shape)\n",
    "np.save(os.path.join(dir_test, 'feature_test_f%i.npy' % bits), feature0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32000, 2048)\n"
     ]
    }
   ],
   "source": [
    "data_to_fcpath0= os.path.join(dir_intermediate, 'data_to_fc_f%i_e39_7000.npy' % bits)\n",
    "data_to_fc0 = np.load(data_to_fcpath0, mmap_mode=None, allow_pickle=False, fix_imports=True, encoding='ASCII')\n",
    "# 合并data_to_fc测试数据集（e39_7000-7999）\n",
    "for i in range(7001,8000):\n",
    "    data_to_fcpath1= os.path.join(dir_intermediate, 'data_to_fc_f%i_e39_%i.npy' % (bits, i) )\n",
    "    data_to_fc1 = np.load(data_to_fcpath1, mmap_mode=None, allow_pickle=False, fix_imports=True, encoding='ASCII')\n",
    "    data_to_fc0 = np.append(data_to_fc0, data_to_fc1, axis=0)\n",
    "print(data_to_fc0.shape)\n",
    "np.save(os.path.join(dir_test, 'data_to_fc_test_f%i.npy' % bits), data_to_fc0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 2, 16, 32)\n"
     ]
    }
   ],
   "source": [
    "inputpath0= os.path.join(dir_intermediate , 'input_f%i_e39_7000.npy' % bits)\n",
    "input0 = np.load(inputpath0, mmap_mode=None, allow_pickle=False, fix_imports=True, encoding='ASCII')\n",
    "print(input0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32000, 2, 16, 32)\n"
     ]
    }
   ],
   "source": [
    "# 合并input测试数据集（e39_7000-7999）\n",
    "for i in range(7001,8000):\n",
    "    inputpath1= os.path.join(dir_intermediate, 'input_f%i_e39_%i.npy' % (bits, i)) \n",
    "    input1 = np.load(inputpath1, mmap_mode=None, allow_pickle=False, fix_imports=True, encoding='ASCII')\n",
    "    input0 = np.append(input0, input1, axis=0)\n",
    "print(input0.shape)\n",
    "np.save(os.path.join(dir_test, 'input_test_f%i.npy' % bits), data_to_fc0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 计算xw乘法结果作为训练集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_fc_trainpath= os.path.join(dir_train, 'data_to_fc_train_f%i_sam%i.npy' % (bits, whole_train_sam_num))\n",
    "data_to_fc_train = np.load(data_to_fc_trainpath, mmap_mode=None, allow_pickle=False, fix_imports=True, encoding='ASCII')\n",
    "feature_trainpath= os.path.join(dir_train, 'feature_train_f%i_sam%i.npy' % (bits, whole_train_sam_num))\n",
    "feature_train = np.load(feature_trainpath, mmap_mode=None, allow_pickle=False, fix_imports=True, encoding='ASCII')\n",
    "biaspath= os.path.join(dir_train, 'encoder_fcb_f%i.npy' % bits)\n",
    "bias = np.load(biaspath, mmap_mode=None, allow_pickle=False, fix_imports=True, encoding='ASCII')\n",
    "weightpath= os.path.join(dir_train, 'encoder_fcw_f%i.npy' % bits)\n",
    "weight = np.load(weightpath, mmap_mode=None, allow_pickle=False, fix_imports=True, encoding='ASCII')\n",
    "data_to_fc_testpath= os.path.join(dir_test, 'data_to_fc_test_f%i.npy' % bits)\n",
    "data_to_fc_test = np.load(data_to_fc_testpath, mmap_mode=None, allow_pickle=False, fix_imports=True, encoding='ASCII')\n",
    "feature_testpath= os.path.join(dir_test, 'feature_test_f%i.npy' % bits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_trainpath = os.path.join(dir_train, 'y_train_f%i_sam%i.npy' % (bits, whole_train_sam_num))\n",
    "y_testpath = os.path.join(dir_test, 'y_test_f%i_sam%i.npy' % (bits, whole_train_sam_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.matmul(data_to_fc_train, weight)\n",
    "# 计算直接乘积加bias\n",
    "y_train_lastns = y_train + bias.T\n",
    "\n",
    "y_test = np.matmul(data_to_fc_test, weight)\n",
    "# 计算直接乘积加bias\n",
    "y_test_lastns = y_test + bias.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存ytrain、ytest\n",
    "np.save(y_trainpath, y_train)\n",
    "np.save(y_testpath, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 计算feature-bias作为训练集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_fc_trainpath= os.path.join(dir_train, 'data_to_fc_train_f%i_sam%i.npy' % (bits, whole_train_sam_num))\n",
    "data_to_fc_train = np.load(data_to_fc_trainpath, mmap_mode=None, allow_pickle=False, fix_imports=True, encoding='ASCII')\n",
    "feature_trainpath= os.path.join(dir_train, 'feature_train_f%i_sam%i.npy' % (bits, whole_train_sam_num))\n",
    "feature_train = np.load(feature_trainpath, mmap_mode=None, allow_pickle=False, fix_imports=True, encoding='ASCII')\n",
    "smaller_data_to_fc_trainpath= os.path.join(dir_train, 'data_to_fc_train_f%i_sam%i.npy' % (bits, smaller_train_sam_num))\n",
    "smaller_data_to_fc_train = np.load(smaller_data_to_fc_trainpath, mmap_mode=None, allow_pickle=False, fix_imports=True, encoding='ASCII')\n",
    "smaller_feature_trainpath= os.path.join(dir_train, 'feature_train_f%i_sam%i.npy' % (bits, smaller_train_sam_num))\n",
    "smaller_feature_train = np.load(smaller_feature_trainpath, mmap_mode=None, allow_pickle=False, fix_imports=True, encoding='ASCII')\n",
    "biaspath= os.path.join(dir_train, 'encoder_fcb_f%i.npy' % bits)\n",
    "bias = np.load(biaspath, mmap_mode=None, allow_pickle=False, fix_imports=True, encoding='ASCII')\n",
    "weightpath= os.path.join(dir_train, 'encoder_fcw_f%i.npy' % bits)\n",
    "weight = np.load(weightpath, mmap_mode=None, allow_pickle=False, fix_imports=True, encoding='ASCII')\n",
    "data_to_fc_testpath= os.path.join(dir_test, 'data_to_fc_test_f%i.npy' % bits)\n",
    "data_to_fc_test = np.load(data_to_fc_testpath, mmap_mode=None, allow_pickle=False, fix_imports=True, encoding='ASCII')\n",
    "feature_testpath= os.path.join(dir_test, 'feature_test_f%i.npy' % bits)\n",
    "feature_test = np.load(feature_testpath, mmap_mode=None, allow_pickle=False, fix_imports=True, encoding='ASCII')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_trainpath = os.path.join(dir_train, 'y_train_f%i_sam%i.npy' % (bits, whole_train_sam_num))\n",
    "y_testpath = os.path.join(dir_test, 'y_test_f%i.npy' % (bits))\n",
    "smaller_y_trainpath = os.path.join(dir_train, 'y_train_f%i_sam%i.npy' % (bits, smaller_train_sam_num))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = feature_train - bias\n",
    "y_test = feature_test - bias\n",
    "smaller_y_train = smaller_feature_train - bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存ytrain、ytest\n",
    "np.save(y_trainpath, y_train)\n",
    "np.save(y_testpath, y_test)\n",
    "np.save(smaller_y_trainpath, y_train)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('pqhdr')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ec04f7dc2b3ae4a422de9aaf96e8c62fe190a2869a08d14112cb2d7713497448"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
