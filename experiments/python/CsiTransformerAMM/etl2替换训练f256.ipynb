{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "encoder transformer层的linear2层（etl2）替换为近似矩阵乘法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "# 获取当前文件所在的文件夹路径\n",
    "if \"__file__\" in globals():\n",
    "    # 获取__file__变量的值\n",
    "    file_path = __file__\n",
    "    # 获取当前文件所在的文件夹路径\n",
    "    dir_now = os.path.dirname(file_path)\n",
    "else:\n",
    "    # 获取当前工作目录\n",
    "    dir_now = os.getcwd()\n",
    "sys.path.append(dir_now)\n",
    "sys.path.append(os.path.join(dir_now, '../'))\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\" # 防止jupyter爆内存\n",
    "import matmul as mm\n",
    "import math_util as mu\n",
    "from NNutils import *\n",
    "# import scipy.io as io\n",
    "from amm_methods import *\n",
    "import socket # Obtain the current host name, which can be used to select different data directories and result saving directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method = METHOD_MITHRAL\n",
    "method = METHOD_PQ\n",
    "# method = METHOD_PLUTO\n",
    "# method = METHOD_MITHRALPQ\n",
    "# method = METHOD_EXACT\n",
    "# method = METHOD_SCALAR_QUANTIZE\n",
    "quantize_lut = True\n",
    "# for method in [METHOD_MITHRAL, METHOD_PQ]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_name = 'etl2'\n",
    "feedback_bits = 256\n",
    "linear_name_full = \"ex_linear2\"\n",
    "\n",
    "auto_train_change_nbits = False # 是否根据已运行的训练性能结果改变nbits自动训练，（train_sam_num取已训练的最大值）\n",
    "auto_train_change_upcast = False # 是否根据已运行的训练性能结果改变upcast自动训练，（train_sam_num取已训练的最大值）\n",
    "\n",
    "if auto_train_change_nbits:\n",
    "    nbits_trained = 8\n",
    "if auto_train_change_upcast:\n",
    "    upcast_trained = 16\n",
    "nbits_goal = 8\n",
    "upcast_goal = -1\n",
    "if quantize_lut == False:\n",
    "    nbits_goal = 0\n",
    "nbits = nbits_goal # 要运行的量化比特数\n",
    "upcast_every = upcast_goal # 要运行的upcast\n",
    "\n",
    "test_sam_num = 1000 # 测试集样本数(如需修改，请同时修改下面的读取文件，现文件默认1000个样本)\n",
    "\n",
    "if not auto_train_change_nbits and not auto_train_change_upcast:\n",
    "    ncodebooks = 512 # max:512\n",
    "    ncentroids = 256\n",
    "    train_sam_num = 1000 # 训练集样本数\n",
    "elif auto_train_change_nbits:\n",
    "    param2change = \"nbits\"\n",
    "    param_trained = nbits_trained\n",
    "    param_goal = nbits_goal\n",
    "    cb_ct_ntr_combinations_unique = change_param_auto_run_list(linear_name, method, feedback_bits, param2change, param_trained, param_goal, \"upcast_every\", 16)\n",
    "    print(cb_ct_ntr_combinations_unique)\n",
    "    # 遍历每个cb、ct、n_train_sam组合\n",
    "    # for _, row_ref in cb_ct_ntr_combinations_unique.iterrows():\n",
    "    #     ncodebooks = int(row_ref['cb'])\n",
    "        # ncentroids = int(row_ref['ct'])\n",
    "        # train_sam_num = int(row_ref['n_train_sam'])\n",
    "elif auto_train_change_upcast:\n",
    "    param2change = \"upcast_every\"\n",
    "    param_trained = upcast_trained\n",
    "    param_goal = upcast_goal\n",
    "    cb_ct_ntr_combinations_unique = change_param_auto_run_list(linear_name, method, feedback_bits, param2change, param_trained, param_goal, \"nbits\", 8)\n",
    "    print(cb_ct_ntr_combinations_unique)\n",
    "    # 遍历每个cb、ct、n_train_sam组合\n",
    "    # for _, row_ref in cb_ct_ntr_combinations_unique.iterrows():\n",
    "    #     ncodebooks = int(row_ref['cb'])\n",
    "        # ncentroids = int(row_ref['ct'])\n",
    "        # train_sam_num = int(row_ref['n_train_sam'])\n",
    "\n",
    "batch_size = 32\n",
    "if method == METHOD_EXACT:\n",
    "    ncodebooks = 0\n",
    "    ncentroids = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "AMM_train_dirs = get_AMM_train_dirs(linear_name, linear_name_full, method, feedback_bits, train_sam_num, test_sam_num)\n",
    "create_dir(AMM_train_dirs[\"dir_result\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_prepare(AMM_train_dirs[\"dir_joined\"], linear_name_full, feedback_bits, [train_sam_num, test_sam_num], \n",
    "                batch_size, S1 = S1_dict[linear_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "running method:  PQ\n",
      "running kmeans in subspace 1/512... mse / {var(X_subs), var(X)}: 0.0813, 0.00249\n",
      "running kmeans in subspace 2/512... mse / {var(X_subs), var(X)}: 0.654, 0.00498\n",
      "running kmeans in subspace 3/512... mse / {var(X_subs), var(X)}: 1, 0.00556\n",
      "running kmeans in subspace 4/512... mse / {var(X_subs), var(X)}: 0.125, 0.00416\n",
      "running kmeans in subspace 5/512... mse / {var(X_subs), var(X)}: 0.998, 0.0028\n",
      "running kmeans in subspace 6/512... mse / {var(X_subs), var(X)}: 0.0191, 0.0078\n",
      "running kmeans in subspace 7/512... mse / {var(X_subs), var(X)}: 3.11e-05, 0.000736\n",
      "running kmeans in subspace 8/512... X.shape:  (1024000, 1)\n",
      "k:  256\n",
      "nnz_rows:  104\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (104,1) into shape (1,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [6], line 7\u001b[0m\n\u001b[1;32m      2\u001b[0m     est3 \u001b[39m=\u001b[39m mm\u001b[39m.\u001b[39mestFactory(X_path\u001b[39m=\u001b[39mAMM_train_dirs[\u001b[39m\"\u001b[39m\u001b[39mlinearin_path_train\u001b[39m\u001b[39m\"\u001b[39m], W_path\u001b[39m=\u001b[39mAMM_train_dirs[\u001b[39m\"\u001b[39m\u001b[39mweightpath\u001b[39m\u001b[39m\"\u001b[39m], \n\u001b[1;32m      3\u001b[0m                         Y_path\u001b[39m=\u001b[39mAMM_train_dirs[\u001b[39m\"\u001b[39m\u001b[39my_train\u001b[39m\u001b[39m\"\u001b[39m], \u001b[39mdir\u001b[39m\u001b[39m=\u001b[39m AMM_train_dirs[\u001b[39m\"\u001b[39m\u001b[39mdir_train\u001b[39m\u001b[39m\"\u001b[39m], ncodebooks\u001b[39m=\u001b[39mncodebooks, \n\u001b[1;32m      4\u001b[0m                         ncentroids\u001b[39m=\u001b[39mncentroids, methods\u001b[39m=\u001b[39m[method], nbits\u001b[39m=\u001b[39mnbits, quantize_lut \u001b[39m=\u001b[39m quantize_lut, \n\u001b[1;32m      5\u001b[0m                         upcast_every\u001b[39m=\u001b[39mupcast_every, bias_path\u001b[39m=\u001b[39mAMM_train_dirs[\u001b[39m\"\u001b[39m\u001b[39mbiaspath\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m      6\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m----> 7\u001b[0m     est3 \u001b[39m=\u001b[39m mm\u001b[39m.\u001b[39;49mestFactory(X_path\u001b[39m=\u001b[39;49mAMM_train_dirs[\u001b[39m\"\u001b[39;49m\u001b[39mlinearin_path_train\u001b[39;49m\u001b[39m\"\u001b[39;49m], W_path\u001b[39m=\u001b[39;49mAMM_train_dirs[\u001b[39m\"\u001b[39;49m\u001b[39mweightpath\u001b[39;49m\u001b[39m\"\u001b[39;49m], \n\u001b[1;32m      8\u001b[0m                         Y_path\u001b[39m=\u001b[39;49mAMM_train_dirs[\u001b[39m\"\u001b[39;49m\u001b[39my_train\u001b[39;49m\u001b[39m\"\u001b[39;49m], \u001b[39mdir\u001b[39;49m\u001b[39m=\u001b[39;49m AMM_train_dirs[\u001b[39m\"\u001b[39;49m\u001b[39mdir_train\u001b[39;49m\u001b[39m\"\u001b[39;49m], ncodebooks\u001b[39m=\u001b[39;49mncodebooks, \n\u001b[1;32m      9\u001b[0m                         ncentroids\u001b[39m=\u001b[39;49mncentroids, methods\u001b[39m=\u001b[39;49m[method], nbits\u001b[39m=\u001b[39;49mnbits, quantize_lut \u001b[39m=\u001b[39;49m quantize_lut,\n\u001b[1;32m     10\u001b[0m                         upcast_every\u001b[39m=\u001b[39;49mupcast_every)\n",
      "File \u001b[0;32m/data/hdr/pq/bolt/experiments/python/CsiTransformerAMM/../matmul.py:334\u001b[0m, in \u001b[0;36mestFactory\u001b[0;34m(methods, ntasks, ncodebooks, ncentroids, verbose, limit_ntasks, tasks_all_same_shape, tasks, X_path, W_path, Y_path, bias_path, dir, nbits, quantize_lut, upcast_every)\u001b[0m\n\u001b[1;32m    330\u001b[0m         est \u001b[39m=\u001b[39m _fitted_est_for_hparams(\n\u001b[1;32m    331\u001b[0m             method_id, hparams_dict,\n\u001b[1;32m    332\u001b[0m             task\u001b[39m.\u001b[39mX_train, task\u001b[39m.\u001b[39mW_train, task\u001b[39m.\u001b[39mY_train, bias\u001b[39m=\u001b[39mtask\u001b[39m.\u001b[39mbias)\n\u001b[1;32m    333\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 334\u001b[0m         est \u001b[39m=\u001b[39m _fitted_est_for_hparams(\n\u001b[1;32m    335\u001b[0m             method_id, hparams_dict,\n\u001b[1;32m    336\u001b[0m             task\u001b[39m.\u001b[39;49mX_train, task\u001b[39m.\u001b[39;49mW_train, task\u001b[39m.\u001b[39;49mY_train)\n\u001b[1;32m    337\u001b[0m \u001b[39mexcept\u001b[39;00m amm\u001b[39m.\u001b[39mInvalidParametersException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    338\u001b[0m     \u001b[39m# hparams don't make sense for task (eg, D < d)\u001b[39;00m\n\u001b[1;32m    339\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mhparams apparently invalid: \u001b[39m\u001b[39m{\u001b[39;00me\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/pqhdr/lib/python3.8/site-packages/joblib/memory.py:594\u001b[0m, in \u001b[0;36mMemorizedFunc.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    593\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 594\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cached_call(args, kwargs)[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/.conda/envs/pqhdr/lib/python3.8/site-packages/joblib/memory.py:537\u001b[0m, in \u001b[0;36mMemorizedFunc._cached_call\u001b[0;34m(self, args, kwargs, shelving)\u001b[0m\n\u001b[1;32m    534\u001b[0m         must_call \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    536\u001b[0m \u001b[39mif\u001b[39;00m must_call:\n\u001b[0;32m--> 537\u001b[0m     out, metadata \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcall(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    538\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmmap_mode \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    539\u001b[0m         \u001b[39m# Memmap the output at the first call to be consistent with\u001b[39;00m\n\u001b[1;32m    540\u001b[0m         \u001b[39m# later calls\u001b[39;00m\n\u001b[1;32m    541\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_verbose:\n",
      "File \u001b[0;32m~/.conda/envs/pqhdr/lib/python3.8/site-packages/joblib/memory.py:779\u001b[0m, in \u001b[0;36mMemorizedFunc.call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_verbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    778\u001b[0m     \u001b[39mprint\u001b[39m(format_call(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunc, args, kwargs))\n\u001b[0;32m--> 779\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunc(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    780\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstore_backend\u001b[39m.\u001b[39mdump_item(\n\u001b[1;32m    781\u001b[0m     [func_id, args_id], output, verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_verbose)\n\u001b[1;32m    783\u001b[0m duration \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n",
      "File \u001b[0;32m/data/hdr/pq/bolt/experiments/python/CsiTransformerAMM/../matmul.py:247\u001b[0m, in \u001b[0;36m_fitted_est_for_hparams\u001b[0;34m(method_id, hparams_dict, X_train, W_train, Y_train, **kwargs)\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[39m@_memory\u001b[39m\u001b[39m.\u001b[39mcache\n\u001b[1;32m    244\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_fitted_est_for_hparams\u001b[39m(method_id, hparams_dict, X_train, W_train,\n\u001b[1;32m    245\u001b[0m                             Y_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    246\u001b[0m     est \u001b[39m=\u001b[39m _estimator_for_method_id(method_id, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mhparams_dict)\n\u001b[0;32m--> 247\u001b[0m     est\u001b[39m.\u001b[39;49mfit(X_train, W_train, Y\u001b[39m=\u001b[39;49mY_train, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    248\u001b[0m     \u001b[39mreturn\u001b[39;00m est\n",
      "File \u001b[0;32m/data/hdr/pq/bolt/experiments/python/CsiTransformerAMM/../vq_amm.py:52\u001b[0m, in \u001b[0;36mVQMatmul.fit\u001b[0;34m(self, A, B, Y)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[39mraise\u001b[39;00m amm\u001b[39m.\u001b[39mInvalidParametersException(\n\u001b[1;32m     50\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mD < C: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m < \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(D, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mncodebooks))\n\u001b[1;32m     51\u001b[0m \u001b[39m# A = X_train B = W_train Y = Y_train\u001b[39;00m\n\u001b[0;32m---> 52\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menc\u001b[39m.\u001b[39;49mfit(A, B\u001b[39m.\u001b[39;49mT)\n",
      "File \u001b[0;32m/data/hdr/pq/bolt/experiments/python/CsiTransformerAMM/../vquantizers.py:443\u001b[0m, in \u001b[0;36mPQEncoder.fit\u001b[0;34m(self, X, Q)\u001b[0m\n\u001b[1;32m    431\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msplits_lists, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcentroids \u001b[39m=\u001b[39m \\\n\u001b[1;32m    432\u001b[0m             clusterize\u001b[39m.\u001b[39mlearn_splits_in_subspaces(\n\u001b[1;32m    433\u001b[0m                 X, subvect_len\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msubvect_len,\n\u001b[1;32m    434\u001b[0m                 nsplits_per_subs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcode_bits, algo\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencode_algo)\n\u001b[1;32m    435\u001b[0m         \u001b[39m# print(\"centroids shape: \", self.centroids.shape)\u001b[39;00m\n\u001b[1;32m    436\u001b[0m \n\u001b[1;32m    437\u001b[0m         \u001b[39m# # TODO rm\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    441\u001b[0m         \u001b[39m# print(\"centroids shape: \", self.centroids.shape)\u001b[39;00m\n\u001b[1;32m    442\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 443\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcentroids \u001b[39m=\u001b[39m _learn_centroids(\n\u001b[1;32m    444\u001b[0m             X, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mncentroids, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mncodebooks, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msubvect_len)\n\u001b[1;32m    446\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_learn_lut_quantization(X, Q, nbits\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnbits)\n",
      "File \u001b[0;32m/data/hdr/pq/bolt/experiments/python/CsiTransformerAMM/../vquantizers.py:345\u001b[0m, in \u001b[0;36m_learn_centroids\u001b[0;34m(X, ncentroids, ncodebooks, subvect_len)\u001b[0m\n\u001b[1;32m    343\u001b[0m X_in \u001b[39m=\u001b[39m X[:, start_col:end_col]\n\u001b[1;32m    344\u001b[0m \u001b[39m# centroids, labels = kmeans(X_in, ncentroids)\u001b[39;00m\n\u001b[0;32m--> 345\u001b[0m centroids, labels, sse \u001b[39m=\u001b[39m kmeans(X_in, ncentroids, return_sse\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    347\u001b[0m \u001b[39m# X_bar = X_in - np.mean(X_in, axis=0)\u001b[39;00m\n\u001b[1;32m    348\u001b[0m \u001b[39m# sse_using_mean = np.sum(X_bar * X_bar) + 1e-14\u001b[39;00m\n\u001b[1;32m    349\u001b[0m subspace_sse \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msum(col_sses[start_col:end_col])\n",
      "File \u001b[0;32m~/.conda/envs/pqhdr/lib/python3.8/site-packages/joblib/memory.py:594\u001b[0m, in \u001b[0;36mMemorizedFunc.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    593\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 594\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cached_call(args, kwargs)[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/.conda/envs/pqhdr/lib/python3.8/site-packages/joblib/memory.py:537\u001b[0m, in \u001b[0;36mMemorizedFunc._cached_call\u001b[0;34m(self, args, kwargs, shelving)\u001b[0m\n\u001b[1;32m    534\u001b[0m         must_call \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    536\u001b[0m \u001b[39mif\u001b[39;00m must_call:\n\u001b[0;32m--> 537\u001b[0m     out, metadata \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcall(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    538\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmmap_mode \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    539\u001b[0m         \u001b[39m# Memmap the output at the first call to be consistent with\u001b[39;00m\n\u001b[1;32m    540\u001b[0m         \u001b[39m# later calls\u001b[39;00m\n\u001b[1;32m    541\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_verbose:\n",
      "File \u001b[0;32m~/.conda/envs/pqhdr/lib/python3.8/site-packages/joblib/memory.py:779\u001b[0m, in \u001b[0;36mMemorizedFunc.call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_verbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    778\u001b[0m     \u001b[39mprint\u001b[39m(format_call(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunc, args, kwargs))\n\u001b[0;32m--> 779\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunc(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    780\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstore_backend\u001b[39m.\u001b[39mdump_item(\n\u001b[1;32m    781\u001b[0m     [func_id, args_id], output, verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_verbose)\n\u001b[1;32m    783\u001b[0m duration \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n",
      "File \u001b[0;32m/data/hdr/pq/bolt/experiments/python/CsiTransformerAMM/../utils.py:195\u001b[0m, in \u001b[0;36mkmeans\u001b[0;34m(X, k, max_iter, init, return_sse)\u001b[0m\n\u001b[1;32m    190\u001b[0m labels \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mfull(X\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], nnz_rows, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mint)\n\u001b[1;32m    191\u001b[0m \u001b[39mif\u001b[39;00m nnz_rows \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:  \u001b[39m# special case, because can't have slice of size 0\u001b[39;00m\n\u001b[1;32m    192\u001b[0m     \u001b[39m# make a centroid out of each nonzero row, and assign only those\u001b[39;00m\n\u001b[1;32m    193\u001b[0m     \u001b[39m# rows to that centroid; all other rows get assigned to next\u001b[39;00m\n\u001b[1;32m    194\u001b[0m     \u001b[39m# centroid after those, which is all zeros\u001b[39;00m\n\u001b[0;32m--> 195\u001b[0m     centroids[nnz_rows] \u001b[39m=\u001b[39m X[nonzero_mask]\n\u001b[1;32m    196\u001b[0m     labels[nonzero_mask] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marange(nnz_rows)\n\u001b[1;32m    197\u001b[0m \u001b[39mif\u001b[39;00m return_sse:\n",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (104,1) into shape (1,)"
     ]
    }
   ],
   "source": [
    "if method == METHOD_PLUTO:\n",
    "    est3 = mm.estFactory(X_path=AMM_train_dirs[\"linearin_path_train\"], W_path=AMM_train_dirs[\"weightpath\"], \n",
    "                        Y_path=AMM_train_dirs[\"y_train\"], dir= AMM_train_dirs[\"dir_train\"], ncodebooks=ncodebooks, \n",
    "                        ncentroids=ncentroids, methods=[method], nbits=nbits, quantize_lut = quantize_lut, \n",
    "                        upcast_every=upcast_every, bias_path=AMM_train_dirs[\"biaspath\"])\n",
    "else:\n",
    "    est3 = mm.estFactory(X_path=AMM_train_dirs[\"linearin_path_train\"], W_path=AMM_train_dirs[\"weightpath\"], \n",
    "                        Y_path=AMM_train_dirs[\"y_train\"], dir= AMM_train_dirs[\"dir_train\"], ncodebooks=ncodebooks, \n",
    "                        ncentroids=ncentroids, methods=[method], nbits=nbits, quantize_lut = quantize_lut,\n",
    "                        upcast_every=upcast_every)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.load(AMM_train_dirs[\"dir_test\"]+'/'+AMM_train_dirs[\"linearin_path_test\"])\n",
    "w_test = np.load(AMM_train_dirs[\"dir_train\"]+'/'+AMM_train_dirs[\"weightpath\"])\n",
    "bias = np.load(AMM_train_dirs[\"dir_train\"]+'/'+AMM_train_dirs[\"biaspath\"])\n",
    "# print(type(est3))\n",
    "y_out_matmul = mm.eval_matmul(est3, x_test, w_test) # MADDNESS乘法的结果\n",
    "# y_out_last = mu.softmax(y_out_matmul + bias.T) # MADDNESS替换后当前层输出，即+bias并激活函数后的结果\n",
    "if method == METHOD_PLUTO:\n",
    "    y_out_last = y_out_matmul\n",
    "else:\n",
    "    y_out_last = y_out_matmul + bias.T # MADDNESS替换后当前层输出，即+bias并不需要激活函数后的结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.3087928  -0.9443369  -0.21137223 ... -0.42848942 -0.705882\n",
      "  -0.23357466]\n",
      " [-0.33731493 -0.89204633 -0.24464807 ... -0.40472096 -0.71063566\n",
      "  -0.2620968 ]\n",
      " [-0.2992854  -0.9443369  -0.19711116 ... -0.45225787 -0.7011283\n",
      "  -0.2145599 ]\n",
      " ...\n",
      " [-0.2612559  -0.78271145 -0.45381045 ... -0.45701155 -0.43492165\n",
      "  -0.39044642]\n",
      " [-0.41337398 -0.97761273 -0.44430307 ... -0.52831686 -0.6773598\n",
      "  -0.4522444 ]\n",
      " [-0.4609109  -0.7922188  -0.4775789  ... -0.618637   -0.62031555\n",
      "  -0.43798333]]\n",
      "y_out_last.shape:  (1024000, 64)\n",
      "y_out_last_re.shape:  (1000, 32, 32, 64)\n"
     ]
    }
   ],
   "source": [
    "print(y_out_last)\n",
    "print(\"y_out_last.shape: \", y_out_last.shape)\n",
    "y_out_last_re = y_out_last.reshape(test_sam_num, batch_size, -1, y_out_last.shape[-1]) #AMM字典模式需要复原y大小\n",
    "print(\"y_out_last_re.shape: \", y_out_last_re.shape)\n",
    "if method == METHOD_SCALAR_QUANTIZE:\n",
    "    np.save(os.path.join(AMM_train_dirs[\"dir_result\"], '%s%s_trsam%i_tesam%i_fb%i_nbits%i.npy' % \n",
    "                                                        (method, linear_name, train_sam_num, test_sam_num, feedback_bits, nbits)), \n",
    "                                                        y_out_last_re.astype(np.float32))\n",
    "elif method == METHOD_MITHRAL or method == METHOD_PQ or method == METHOD_PLUTO or method == METHOD_MITHRALPQ:\n",
    "    np.save(os.path.join(AMM_train_dirs[\"dir_result\"], '%s%s_trsam%i_tesam%i_fb%i_cb%i_ct%i_ql%i_nb%i_uc%i.npy' % \n",
    "                                                        (method, linear_name, train_sam_num, test_sam_num, feedback_bits, \n",
    "                                                        ncodebooks, ncentroids, quantize_lut, nbits, upcast_every)), y_out_last_re)\n",
    "else:\n",
    "    np.save(os.path.join(AMM_train_dirs[\"dir_result\"], '%s%s_trsam%i_tesam%i_fb%i_cb%i_ct%i.npy' % \n",
    "                                                        (method, linear_name, train_sam_num, test_sam_num, feedback_bits, \n",
    "                                                        ncodebooks, ncentroids)), y_out_last_re)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pqhdr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ec04f7dc2b3ae4a422de9aaf96e8c62fe190a2869a08d14112cb2d7713497448"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
