{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "encoder transformer层的linear2层（etl2）替换为近似矩阵乘法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'type' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/data/hdr/pq/bolt/experiments/python/CsiTransformerAMM/etl2替换训练f256.ipynb 单元格 2\u001b[0m in \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.129.7.201/data/hdr/pq/bolt/experiments/python/CsiTransformerAMM/etl2%E6%9B%BF%E6%8D%A2%E8%AE%AD%E7%BB%83f256.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m sys\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mappend(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(dir_now, \u001b[39m'\u001b[39m\u001b[39m../\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.129.7.201/data/hdr/pq/bolt/experiments/python/CsiTransformerAMM/etl2%E6%9B%BF%E6%8D%A2%E8%AE%AD%E7%BB%83f256.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m os\u001b[39m.\u001b[39menviron[\u001b[39m\"\u001b[39m\u001b[39mKMP_DUPLICATE_LIB_OK\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTRUE\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m# 防止jupyter爆内存\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B10.129.7.201/data/hdr/pq/bolt/experiments/python/CsiTransformerAMM/etl2%E6%9B%BF%E6%8D%A2%E8%AE%AD%E7%BB%83f256.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatmul\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mmm\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.129.7.201/data/hdr/pq/bolt/experiments/python/CsiTransformerAMM/etl2%E6%9B%BF%E6%8D%A2%E8%AE%AD%E7%BB%83f256.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmath_util\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mmu\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.129.7.201/data/hdr/pq/bolt/experiments/python/CsiTransformerAMM/etl2%E6%9B%BF%E6%8D%A2%E8%AE%AD%E7%BB%83f256.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mNNutils\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n",
      "File \u001b[0;32m/data/hdr/pq/bolt/experiments/python/CsiTransformerAMM/../matmul.py:21\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mamm_methods\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[0;32m---> 21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdpq\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdpq_encoder\u001b[39;00m \u001b[39mimport\u001b[39;00m sliceData\n\u001b[1;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mjoblib\u001b[39;00m \u001b[39mimport\u001b[39;00m Memory\n\u001b[1;32m     23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mLogger\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n",
      "File \u001b[0;32m/data/hdr/pq/bolt/experiments/python/CsiTransformerAMM/../dpq/dpq_encoder.py:17\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtqdm\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mvquantizers\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mvq\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdpq\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdpq_nn\u001b[39;00m \u001b[39mimport\u001b[39;00m DPQNetwork\n\u001b[1;32m     18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtensorboard\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mwriter\u001b[39;00m \u001b[39mimport\u001b[39;00m SummaryWriter\n\u001b[1;32m     20\u001b[0m device \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mis_available() \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m  \u001b[39m# TODO: set in params\u001b[39;00m\n",
      "File \u001b[0;32m/data/hdr/pq/bolt/experiments/python/CsiTransformerAMM/../dpq/dpq_nn.py:17\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfunctional\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mF\u001b[39;00m\n\u001b[1;32m     14\u001b[0m device \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mis_available() \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m---> 17\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mDPQNetwork\u001b[39;00m(torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mModule):\n\u001b[1;32m     18\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, ncentroids: \u001b[39mint\u001b[39m, ncodebooks: \u001b[39mint\u001b[39m, subvect_len: \u001b[39mint\u001b[39m,\n\u001b[1;32m     19\u001b[0m                  W: np\u001b[39m.\u001b[39mndarray, centroids: np\u001b[39m.\u001b[39mndarray,\n\u001b[1;32m     20\u001b[0m                  tie_in_n_out: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m, query_metric: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mdot\u001b[39m\u001b[39m\"\u001b[39m, shared_centroids: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m     21\u001b[0m                  beta: \u001b[39mfloat\u001b[39m \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m, tau: \u001b[39mfloat\u001b[39m \u001b[39m=\u001b[39m \u001b[39m1.0\u001b[39m, softmax_BN: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m     22\u001b[0m                  use_EMA: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m     23\u001b[0m                  ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m         \u001b[39m'''\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[39m        :param ncentroids: K\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[39m        :param ncodebooks: C in mithral, or D in kpq\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[39m        :param use_EMA: use Exponential Moving Average to update centroids, or use regularization\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[39m        '''\u001b[39;00m\n",
      "File \u001b[0;32m/data/hdr/pq/bolt/experiments/python/CsiTransformerAMM/../dpq/dpq_nn.py:68\u001b[0m, in \u001b[0;36mDPQNetwork\u001b[0;34m()\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mLinear(np\u001b[39m.\u001b[39mshape(W)[\u001b[39m0\u001b[39m], np\u001b[39m.\u001b[39mshape(W)[\u001b[39m1\u001b[39m], bias\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, device\u001b[39m=\u001b[39mdevice)\n\u001b[1;32m     65\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc\u001b[39m.\u001b[39mweight\u001b[39m.\u001b[39mdata \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mfrom_numpy(W\u001b[39m.\u001b[39mT)\u001b[39m.\u001b[39mfloat()\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     67\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, inputs: torch\u001b[39m.\u001b[39mTensor, is_training: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m, lr: \u001b[39mfloat\u001b[39m \u001b[39m=\u001b[39m \u001b[39m0.001\u001b[39m\n\u001b[0;32m---> 68\u001b[0m             ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mtuple\u001b[39;49m[torch\u001b[39m.\u001b[39;49mTensor, torch\u001b[39m.\u001b[39;49mTensor, torch\u001b[39m.\u001b[39;49mTensor]:\n\u001b[1;32m     69\u001b[0m     \u001b[39m'''\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[39m    :param inputs: (batch_size, ncodebooks, subvect_len)\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39m    '''\u001b[39;00m\n\u001b[1;32m     72\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mtype\u001b[39m(inputs) \u001b[39m!=\u001b[39m torch\u001b[39m.\u001b[39mTensor:\n",
      "\u001b[0;31mTypeError\u001b[0m: 'type' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "# 获取当前文件所在的文件夹路径\n",
    "if \"__file__\" in globals():\n",
    "    # 获取__file__变量的值\n",
    "    file_path = __file__\n",
    "    # 获取当前文件所在的文件夹路径\n",
    "    dir_now = os.path.dirname(file_path)\n",
    "else:\n",
    "    # 获取当前工作目录\n",
    "    dir_now = os.getcwd()\n",
    "sys.path.append(dir_now)\n",
    "sys.path.append(os.path.join(dir_now, '../'))\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\" # 防止jupyter爆内存\n",
    "import matmul as mm\n",
    "import math_util as mu\n",
    "from NNutils import *\n",
    "# import scipy.io as io\n",
    "from amm_methods import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = METHOD_MITHRAL\n",
    "# method = METHOD_PQ\n",
    "# method = METHOD_PLUTO\n",
    "# method = METHOD_MITHRALPQ\n",
    "# method = METHOD_EXACT\n",
    "# method = METHOD_SCALAR_QUANTIZE\n",
    "# for method in [METHOD_MITHRAL, METHOD_PQ]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_name = 'etl2'\n",
    "feedback_bits = 256\n",
    "linear_name_full = \"ex_linear2\"\n",
    "\n",
    "auto_train_change_nbits = False # 是否根据已运行的训练性能结果改变nbits自动训练，（train_sam_num取已训练的最大值）\n",
    "auto_train_change_upcast = False # 是否根据已运行的训练性能结果改变upcast自动训练，（train_sam_num取已训练的最大值）\n",
    "\n",
    "if auto_train_change_nbits:\n",
    "    nbits_trained = 8\n",
    "if auto_train_change_upcast:\n",
    "    upcast_trained = 16\n",
    "quantize_lut = False\n",
    "nbits_goal = 8\n",
    "upcast_goal = -1\n",
    "lut_work_const = -2\n",
    "if quantize_lut == False:\n",
    "    nbits_goal = 0\n",
    "nbits = nbits_goal # 要运行的量化比特数\n",
    "upcast_every = upcast_goal # 要运行的upcast\n",
    "\n",
    "test_sam_num = 1000 # 测试集样本数(如需修改，请同时修改下面的读取文件，现文件默认1000个样本)\n",
    "\n",
    "if not auto_train_change_nbits and not auto_train_change_upcast:\n",
    "    ncodebooks = 256 # max:512\n",
    "    ncentroids = 32\n",
    "    train_sam_num = 1000 # 训练集样本数\n",
    "elif auto_train_change_nbits:\n",
    "    param2change = \"nbits\"\n",
    "    param_trained = nbits_trained\n",
    "    param_goal = nbits_goal\n",
    "    cb_ct_ntr_combinations_unique = change_param_auto_run_list(linear_name, method, feedback_bits, param2change, param_trained, param_goal, \"upcast_every\", 16)\n",
    "    print(cb_ct_ntr_combinations_unique)\n",
    "    # 遍历每个cb、ct、n_train_sam组合\n",
    "    # for _, row_ref in cb_ct_ntr_combinations_unique.iterrows():\n",
    "    #     ncodebooks = int(row_ref['cb'])\n",
    "        # ncentroids = int(row_ref['ct'])\n",
    "        # train_sam_num = int(row_ref['n_train_sam'])\n",
    "elif auto_train_change_upcast:\n",
    "    param2change = \"upcast_every\"\n",
    "    param_trained = upcast_trained\n",
    "    param_goal = upcast_goal\n",
    "    cb_ct_ntr_combinations_unique = change_param_auto_run_list(linear_name, method, feedback_bits, param2change, param_trained, param_goal, \"nbits\", 8)\n",
    "    print(cb_ct_ntr_combinations_unique)\n",
    "    # 遍历每个cb、ct、n_train_sam组合\n",
    "    # for _, row_ref in cb_ct_ntr_combinations_unique.iterrows():\n",
    "    #     ncodebooks = int(row_ref['cb'])\n",
    "        # ncentroids = int(row_ref['ct'])\n",
    "        # train_sam_num = int(row_ref['n_train_sam'])\n",
    "\n",
    "batch_size = 32\n",
    "if method == METHOD_EXACT:\n",
    "    ncodebooks = 0\n",
    "    ncentroids = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of linearin_train_without_all0_row: (1024000, 512)\n"
     ]
    }
   ],
   "source": [
    "AMM_train_dirs = get_AMM_train_dirs(linear_name, linear_name_full, method, feedback_bits, train_sam_num, test_sam_num)\n",
    "create_dir(AMM_train_dirs[\"dir_result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_prepare(AMM_train_dirs[\"dir_joined\"], linear_name_full, feedback_bits, [train_sam_num, test_sam_num], \n",
    "                batch_size, S1 = S1_dict[linear_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "running method:  Mithral\n",
      "X.shape:  (76800, 512)\n",
      "_learn_mithral_initialization heuristic pq\n",
      "================================\n",
      "learn_multisplits(): initial loss:    14.627148500077402\n",
      "learn_multisplits(): returning loss:  0.27572295741935554\n",
      "================================\n",
      "learn_multisplits(): initial loss:    14.93508012914209\n",
      "learn_multisplits(): returning loss:  0.08072678476411044\n",
      "================================\n",
      "learn_multisplits(): initial loss:    158.06299718333872\n",
      "learn_multisplits(): returning loss:  0.7827477464527216\n",
      "================================\n",
      "learn_multisplits(): initial loss:    8878.823581226608\n",
      "learn_multisplits(): returning loss:  10.579495280981064\n",
      "================================\n",
      "learn_multisplits(): initial loss:    79.91735881238303\n",
      "learn_multisplits(): returning loss:  0.40093763782396513\n",
      "================================\n",
      "learn_multisplits(): initial loss:    197.59010763361442\n",
      "learn_multisplits(): returning loss:  3.854197355410722\n",
      "================================\n",
      "learn_multisplits(): initial loss:    42.87518622717821\n",
      "learn_multisplits(): returning loss:  1.0918983397938309\n",
      "================================\n",
      "learn_multisplits(): initial loss:    12.268131855873511\n",
      "learn_multisplits(): returning loss:  0.11073016959284573\n",
      "================================\n",
      "learn_multisplits(): initial loss:    1.6903794754141381\n",
      "learn_multisplits(): returning loss:  0.02697748258180667\n",
      "================================\n",
      "learn_multisplits(): initial loss:    70.43007614966656\n",
      "learn_multisplits(): returning loss:  1.3916390765187914\n",
      "================================\n",
      "learn_multisplits(): initial loss:    5397.279204498456\n",
      "learn_multisplits(): returning loss:  10.605418309569359\n",
      "================================\n",
      "learn_multisplits(): initial loss:    3.8155592799276383\n",
      "learn_multisplits(): returning loss:  0.002731817117785\n",
      "================================\n",
      "learn_multisplits(): initial loss:    92.03714327703578\n",
      "learn_multisplits(): returning loss:  1.476799710113099\n",
      "================================\n",
      "learn_multisplits(): initial loss:    8210.197310490543\n",
      "learn_multisplits(): returning loss:  25.033988505601883\n",
      "================================\n",
      "learn_multisplits(): initial loss:    54.1288161812192\n",
      "learn_multisplits(): returning loss:  0.5363386002136394\n",
      "================================\n",
      "learn_multisplits(): initial loss:    454.88567334375966\n",
      "learn_multisplits(): returning loss:  31.49630844965577\n",
      "================================\n",
      "learn_multisplits(): initial loss:    54.42368568747283\n",
      "learn_multisplits(): returning loss:  1.540948078620049\n",
      "================================\n",
      "learn_multisplits(): initial loss:    0.9824809170496214\n",
      "learn_multisplits(): returning loss:  0.000792980077676475\n",
      "================================\n",
      "learn_multisplits(): initial loss:    23.92272987974293\n",
      "learn_multisplits(): returning loss:  0.27595098639038695\n",
      "================================\n",
      "learn_multisplits(): initial loss:    24.883549953508204\n",
      "learn_multisplits(): returning loss:  0.29039420598373356\n",
      "================================\n",
      "learn_multisplits(): initial loss:    0.399924228426756\n",
      "learn_multisplits(): returning loss:  2.911051649716907e-06\n",
      "================================\n",
      "learn_multisplits(): initial loss:    27.730431643507423\n",
      "learn_multisplits(): returning loss:  0.4630644730814799\n",
      "================================\n",
      "learn_multisplits(): initial loss:    1.6492456899001122\n",
      "learn_multisplits(): returning loss:  0.03160383562311238\n",
      "================================\n",
      "learn_multisplits(): initial loss:    20.31029242967093\n",
      "learn_multisplits(): returning loss:  0.45717560248552275\n",
      "================================\n",
      "learn_multisplits(): initial loss:    101.40324066955249\n",
      "learn_multisplits(): returning loss:  1.0406780546109076\n",
      "================================\n",
      "learn_multisplits(): initial loss:    44.391125245825556\n",
      "learn_multisplits(): returning loss:  0.38293158300493124\n",
      "================================\n",
      "learn_multisplits(): initial loss:    23.62672973255659\n",
      "learn_multisplits(): returning loss:  0.28273752405923946\n",
      "================================\n",
      "learn_multisplits(): initial loss:    13.068697069185674\n",
      "learn_multisplits(): returning loss:  0.2149263782438346\n",
      "================================\n",
      "learn_multisplits(): initial loss:    11.503641425379234\n",
      "learn_multisplits(): returning loss:  0.016481852497928128\n",
      "================================\n",
      "learn_multisplits(): initial loss:    105.56790825519282\n",
      "learn_multisplits(): returning loss:  1.3003614619769914\n",
      "================================\n",
      "learn_multisplits(): initial loss:    18.62870548318716\n",
      "learn_multisplits(): returning loss:  0.34297009733456196\n",
      "================================\n",
      "learn_multisplits(): initial loss:    4744.1208033721805\n",
      "learn_multisplits(): returning loss:  8.098583623766899\n",
      "================================\n",
      "learn_multisplits(): initial loss:    23.59740792644044\n",
      "learn_multisplits(): returning loss:  0.015522208504947302\n",
      "================================\n",
      "learn_multisplits(): initial loss:    320.0586805746316\n",
      "learn_multisplits(): returning loss:  7.814667291007936\n",
      "================================\n",
      "learn_multisplits(): initial loss:    68.05828300723809\n",
      "learn_multisplits(): returning loss:  1.3783089642946735\n",
      "================================\n",
      "learn_multisplits(): initial loss:    475.2458490350787\n",
      "learn_multisplits(): returning loss:  19.643836431205273\n",
      "================================\n",
      "learn_multisplits(): initial loss:    10511.504499938772\n",
      "learn_multisplits(): returning loss:  50.41896091401577\n",
      "================================\n",
      "learn_multisplits(): initial loss:    0.4174590815122171\n",
      "learn_multisplits(): returning loss:  0.0001568831503391266\n",
      "================================\n",
      "learn_multisplits(): initial loss:    23.58382928713193\n",
      "learn_multisplits(): returning loss:  0.010942219798208941\n",
      "================================\n",
      "learn_multisplits(): initial loss:    390.09458096149314\n",
      "learn_multisplits(): returning loss:  1.6700777909508615\n",
      "================================\n",
      "learn_multisplits(): initial loss:    25.53989126956579\n",
      "learn_multisplits(): returning loss:  0.170051363898415\n",
      "================================\n",
      "learn_multisplits(): initial loss:    73.41912520880174\n",
      "learn_multisplits(): returning loss:  0.5235359762040952\n",
      "================================\n",
      "learn_multisplits(): initial loss:    8182.970509454477\n",
      "learn_multisplits(): returning loss:  10.741697624325752\n",
      "================================\n",
      "learn_multisplits(): initial loss:    0.3606878500130252\n",
      "learn_multisplits(): returning loss:  0.0065516518178844844\n",
      "================================\n",
      "learn_multisplits(): initial loss:    8.34445727172648\n",
      "learn_multisplits(): returning loss:  0.06888129994848494\n",
      "================================\n",
      "learn_multisplits(): initial loss:    10064.591602286884\n",
      "learn_multisplits(): returning loss:  13.917400792241096\n",
      "================================\n",
      "learn_multisplits(): initial loss:    17847.81831648352\n",
      "learn_multisplits(): returning loss:  287.0074243545532\n",
      "================================\n",
      "learn_multisplits(): initial loss:    2.2202691819826907\n",
      "learn_multisplits(): returning loss:  0.036115621627867044\n",
      "================================\n",
      "learn_multisplits(): initial loss:    150.64121545586138\n",
      "learn_multisplits(): returning loss:  2.619450929109007\n",
      "================================\n",
      "learn_multisplits(): initial loss:    24.028839859074903\n",
      "learn_multisplits(): returning loss:  0.10901725469765397\n",
      "================================\n",
      "learn_multisplits(): initial loss:    21.785247858676723\n",
      "learn_multisplits(): returning loss:  0.1846454794514359\n",
      "================================\n",
      "learn_multisplits(): initial loss:    46.661983497293896\n",
      "learn_multisplits(): returning loss:  0.4146548067403334\n",
      "================================\n",
      "learn_multisplits(): initial loss:    30.949888977730133\n",
      "learn_multisplits(): returning loss:  0.8988041066385906\n",
      "================================\n",
      "learn_multisplits(): initial loss:    20.16918884153642\n",
      "learn_multisplits(): returning loss:  0.30298634332158647\n",
      "================================\n",
      "learn_multisplits(): initial loss:    18.539076822566333\n",
      "learn_multisplits(): returning loss:  0.17834658960750088\n",
      "================================\n",
      "learn_multisplits(): initial loss:    20.232188506907853\n",
      "learn_multisplits(): returning loss:  0.21003704997092054\n",
      "================================\n",
      "learn_multisplits(): initial loss:    29.515963268954735\n",
      "learn_multisplits(): returning loss:  0.46403519011225913\n",
      "================================\n",
      "learn_multisplits(): initial loss:    9034.446272992476\n",
      "learn_multisplits(): returning loss:  52.58054776903009\n",
      "================================\n",
      "learn_multisplits(): initial loss:    80.18542077379198\n",
      "learn_multisplits(): returning loss:  0.743590102691035\n",
      "================================\n",
      "learn_multisplits(): initial loss:    1.319248039648149\n",
      "learn_multisplits(): returning loss:  0.019804978803616764\n",
      "================================\n",
      "learn_multisplits(): initial loss:    48.65167982725927\n",
      "learn_multisplits(): returning loss:  0.4479812879418275\n",
      "================================\n",
      "learn_multisplits(): initial loss:    7.181689291167523\n",
      "learn_multisplits(): returning loss:  0.14240738673082476\n",
      "================================\n",
      "learn_multisplits(): initial loss:    4.377117672316889\n",
      "learn_multisplits(): returning loss:  0.02578321995932037\n",
      "================================\n",
      "learn_multisplits(): initial loss:    5.484240314821429\n",
      "learn_multisplits(): returning loss:  0.06120856185716944\n",
      "================================\n",
      "learn_multisplits(): initial loss:    70.00697328172892\n",
      "learn_multisplits(): returning loss:  0.4462159170562499\n",
      "================================\n",
      "learn_multisplits(): initial loss:    61.44731345962224\n",
      "learn_multisplits(): returning loss:  1.0736210909672081\n",
      "================================\n",
      "learn_multisplits(): initial loss:    3.6546467524649744\n",
      "learn_multisplits(): returning loss:  0.02883780522115559\n",
      "================================\n",
      "learn_multisplits(): initial loss:    52.797422467469666\n",
      "learn_multisplits(): returning loss:  1.5201613477387923\n",
      "================================\n",
      "learn_multisplits(): initial loss:    1.7455502823099023\n",
      "learn_multisplits(): returning loss:  0.037624522656487365\n",
      "================================\n",
      "learn_multisplits(): initial loss:    44.28318056601407\n",
      "learn_multisplits(): returning loss:  0.5583079599220022\n",
      "================================\n",
      "learn_multisplits(): initial loss:    233.95034707272674\n",
      "learn_multisplits(): returning loss:  3.043159195454791\n",
      "================================\n",
      "learn_multisplits(): initial loss:    418.83137213649627\n",
      "learn_multisplits(): returning loss:  5.65547997597605\n",
      "================================\n",
      "learn_multisplits(): initial loss:    1153.81503392129\n",
      "learn_multisplits(): returning loss:  6.837434161454439\n",
      "================================\n",
      "learn_multisplits(): initial loss:    576.2548108744655\n",
      "learn_multisplits(): returning loss:  5.044951620744541\n",
      "================================\n",
      "learn_multisplits(): initial loss:    54.13991371293688\n",
      "learn_multisplits(): returning loss:  0.5920492159653722\n",
      "================================\n",
      "learn_multisplits(): initial loss:    0.631299658350488\n",
      "learn_multisplits(): returning loss:  0.0041773736077354295\n",
      "================================\n",
      "learn_multisplits(): initial loss:    269.0975872248704\n",
      "learn_multisplits(): returning loss:  1.7459817804046907\n",
      "================================\n",
      "learn_multisplits(): initial loss:    111.78892111686847\n",
      "learn_multisplits(): returning loss:  1.6436468124419572\n",
      "================================\n",
      "learn_multisplits(): initial loss:    65.43949122436861\n",
      "learn_multisplits(): returning loss:  1.4731216773193605\n",
      "================================\n",
      "learn_multisplits(): initial loss:    40.10328101276672\n",
      "learn_multisplits(): returning loss:  0.10250665508165929\n",
      "================================\n",
      "learn_multisplits(): initial loss:    5.6337794924555\n",
      "learn_multisplits(): returning loss:  0.022544398924453212\n",
      "================================\n",
      "learn_multisplits(): initial loss:    11.14757762277468\n",
      "learn_multisplits(): returning loss:  0.008514364936023238\n",
      "================================\n",
      "learn_multisplits(): initial loss:    26.073611536166176\n",
      "learn_multisplits(): returning loss:  0.27512113439609764\n",
      "================================\n",
      "learn_multisplits(): initial loss:    92.46170260854717\n",
      "learn_multisplits(): returning loss:  2.697805834694125\n",
      "================================\n",
      "learn_multisplits(): initial loss:    1.2052760769867588\n",
      "learn_multisplits(): returning loss:  0.03707727552460332\n",
      "================================\n",
      "learn_multisplits(): initial loss:    9965.389523399284\n",
      "learn_multisplits(): returning loss:  15.60260984301567\n",
      "================================\n",
      "learn_multisplits(): initial loss:    297.9903019823322\n",
      "learn_multisplits(): returning loss:  3.9617345090955496\n",
      "================================\n",
      "learn_multisplits(): initial loss:    89.0612570321285\n",
      "learn_multisplits(): returning loss:  0.768417217561354\n",
      "================================\n",
      "learn_multisplits(): initial loss:    34.22418644403812\n",
      "learn_multisplits(): returning loss:  0.27801311920814414\n",
      "================================\n",
      "learn_multisplits(): initial loss:    65.04108511307156\n",
      "learn_multisplits(): returning loss:  2.428271319484338\n",
      "================================\n",
      "learn_multisplits(): initial loss:    19.091326256124802\n",
      "learn_multisplits(): returning loss:  0.371893169641086\n",
      "================================\n",
      "learn_multisplits(): initial loss:    17.320677855981938\n",
      "learn_multisplits(): returning loss:  0.1067991357649824\n",
      "================================\n",
      "learn_multisplits(): initial loss:    62.993677382971256\n",
      "learn_multisplits(): returning loss:  0.33032328420541124\n",
      "================================\n",
      "learn_multisplits(): initial loss:    52.85702381151558\n",
      "learn_multisplits(): returning loss:  1.3974160222161909\n",
      "================================\n",
      "learn_multisplits(): initial loss:    8.455289498511847\n",
      "learn_multisplits(): returning loss:  0.11468976308831147\n",
      "================================\n",
      "learn_multisplits(): initial loss:    1.8048287131056724\n",
      "learn_multisplits(): returning loss:  0.03772338004666367\n",
      "================================\n",
      "learn_multisplits(): initial loss:    7378.806980470921\n",
      "learn_multisplits(): returning loss:  9.326132088899612\n",
      "================================\n",
      "learn_multisplits(): initial loss:    8.168468822285195\n",
      "learn_multisplits(): returning loss:  0.15444035523294777\n",
      "================================\n",
      "learn_multisplits(): initial loss:    397.593101407529\n",
      "learn_multisplits(): returning loss:  6.029656993341632\n",
      "================================\n",
      "learn_multisplits(): initial loss:    0.34267110013400304\n",
      "learn_multisplits(): returning loss:  0.004299589703414526\n",
      "================================\n",
      "learn_multisplits(): initial loss:    10.52968279151374\n",
      "learn_multisplits(): returning loss:  0.12562288980425826\n",
      "================================\n",
      "learn_multisplits(): initial loss:    810.5716204305501\n",
      "learn_multisplits(): returning loss:  35.519486784935\n",
      "================================\n",
      "learn_multisplits(): initial loss:    927.7257891595519\n",
      "learn_multisplits(): returning loss:  2.1082130912691355\n",
      "================================\n",
      "learn_multisplits(): initial loss:    0.7450435614172639\n",
      "learn_multisplits(): returning loss:  0.009251799353819243\n",
      "================================\n",
      "learn_multisplits(): initial loss:    9.968831186755093\n",
      "learn_multisplits(): returning loss:  0.11848219056874033\n",
      "================================\n",
      "learn_multisplits(): initial loss:    7294.050293852099\n",
      "learn_multisplits(): returning loss:  8.430105894804\n",
      "================================\n",
      "learn_multisplits(): initial loss:    42.331939042877174\n",
      "learn_multisplits(): returning loss:  0.4848574967039872\n",
      "================================\n",
      "learn_multisplits(): initial loss:    441.4571119524689\n",
      "learn_multisplits(): returning loss:  19.962651025969535\n",
      "================================\n",
      "learn_multisplits(): initial loss:    62.97813014814684\n",
      "learn_multisplits(): returning loss:  0.8501472033528096\n",
      "================================\n",
      "learn_multisplits(): initial loss:    1.828914451462255\n",
      "learn_multisplits(): returning loss:  0.021269115870455546\n",
      "================================\n",
      "learn_multisplits(): initial loss:    30.0647235925242\n",
      "learn_multisplits(): returning loss:  0.36410830997122895\n",
      "================================\n",
      "learn_multisplits(): initial loss:    18.359752640576964\n",
      "learn_multisplits(): returning loss:  0.21959263000384022\n",
      "================================\n",
      "learn_multisplits(): initial loss:    674.8752629652104\n",
      "learn_multisplits(): returning loss:  12.258870610035956\n",
      "================================\n",
      "learn_multisplits(): initial loss:    16.793864634013207\n",
      "learn_multisplits(): returning loss:  0.19246007944631113\n",
      "================================\n",
      "learn_multisplits(): initial loss:    26.07770001858703\n",
      "learn_multisplits(): returning loss:  0.06794503391020519\n",
      "================================\n",
      "learn_multisplits(): initial loss:    1.287172470760218\n",
      "learn_multisplits(): returning loss:  0.015699237701127935\n",
      "================================\n",
      "learn_multisplits(): initial loss:    18.666951333935373\n",
      "learn_multisplits(): returning loss:  0.0934593323716037\n",
      "================================\n",
      "learn_multisplits(): initial loss:    132.43421109324103\n",
      "learn_multisplits(): returning loss:  4.836522470045296\n",
      "================================\n",
      "learn_multisplits(): initial loss:    46.302262734788954\n",
      "learn_multisplits(): returning loss:  1.4456537461417909\n",
      "================================\n",
      "learn_multisplits(): initial loss:    13.267111254626919\n",
      "learn_multisplits(): returning loss:  0.3024984808784349\n",
      "================================\n",
      "learn_multisplits(): initial loss:    8.271675532848583\n",
      "learn_multisplits(): returning loss:  0.08747286740254427\n",
      "================================\n",
      "learn_multisplits(): initial loss:    21.6711791545772\n",
      "learn_multisplits(): returning loss:  0.39504675695179226\n",
      "================================\n",
      "learn_multisplits(): initial loss:    5545.059882663916\n",
      "learn_multisplits(): returning loss:  10.306248553097248\n",
      "================================\n",
      "learn_multisplits(): initial loss:    7338.136568956807\n",
      "learn_multisplits(): returning loss:  10.551507830619812\n",
      "================================\n",
      "learn_multisplits(): initial loss:    7.376851370173245\n",
      "learn_multisplits(): returning loss:  0.08762576547474049\n",
      "================================\n",
      "learn_multisplits(): initial loss:    504.6362158370868\n",
      "learn_multisplits(): returning loss:  0.8608071634080261\n",
      "================================\n",
      "learn_multisplits(): initial loss:    46.11502289886989\n",
      "learn_multisplits(): returning loss:  1.0297515734720086\n",
      "================================\n",
      "learn_multisplits(): initial loss:    40.71031535559498\n",
      "learn_multisplits(): returning loss:  0.3149991397325479\n",
      "================================\n",
      "learn_multisplits(): initial loss:    436.342637302241\n",
      "learn_multisplits(): returning loss:  2.3225635625422\n",
      "================================\n",
      "learn_multisplits(): initial loss:    132.7743490017749\n",
      "learn_multisplits(): returning loss:  0.6927781379253886\n",
      "================================\n",
      "learn_multisplits(): initial loss:    13.56892838773518\n",
      "learn_multisplits(): returning loss:  0.16358145864667847\n",
      "================================\n",
      "learn_multisplits(): initial loss:    4.302434732456377\n",
      "learn_multisplits(): returning loss:  0.04984824029421134\n",
      "================================\n",
      "learn_multisplits(): initial loss:    48.78283573727694\n",
      "learn_multisplits(): returning loss:  2.5276066414150287\n",
      "================================\n",
      "learn_multisplits(): initial loss:    8315.532052869788\n",
      "learn_multisplits(): returning loss:  177.22394108772278\n",
      "================================\n",
      "learn_multisplits(): initial loss:    14.471559631727898\n",
      "learn_multisplits(): returning loss:  0.09412536793060786\n",
      "================================\n",
      "learn_multisplits(): initial loss:    703.9900270449307\n",
      "learn_multisplits(): returning loss:  52.22276867926121\n",
      "================================\n",
      "learn_multisplits(): initial loss:    80.10887501472678\n",
      "learn_multisplits(): returning loss:  1.956578066307685\n",
      "================================\n",
      "learn_multisplits(): initial loss:    164.17068583874885\n",
      "learn_multisplits(): returning loss:  2.895857455135695\n",
      "================================\n",
      "learn_multisplits(): initial loss:    30.94917265401728\n",
      "learn_multisplits(): returning loss:  0.2790084727055731\n",
      "================================\n",
      "learn_multisplits(): initial loss:    1.2314700951763804\n",
      "learn_multisplits(): returning loss:  0.011668657807236547\n",
      "================================\n",
      "learn_multisplits(): initial loss:    1.7540268158114074\n",
      "learn_multisplits(): returning loss:  0.04080089079404487\n",
      "================================\n",
      "learn_multisplits(): initial loss:    19.381645704352884\n",
      "learn_multisplits(): returning loss:  0.07219376556770882\n",
      "================================\n",
      "learn_multisplits(): initial loss:    51.865669586106435\n",
      "learn_multisplits(): returning loss:  0.5340456029425732\n",
      "================================\n",
      "learn_multisplits(): initial loss:    4.257099082424287\n",
      "learn_multisplits(): returning loss:  0.04167538187308596\n",
      "================================\n",
      "learn_multisplits(): initial loss:    30.89211175673192\n",
      "learn_multisplits(): returning loss:  0.37657520834290015\n",
      "================================\n",
      "learn_multisplits(): initial loss:    1.1321262061102877\n",
      "learn_multisplits(): returning loss:  0.0003585081867640838\n",
      "================================\n",
      "learn_multisplits(): initial loss:    383.8196990621922\n",
      "learn_multisplits(): returning loss:  8.86388442479074\n",
      "================================\n",
      "learn_multisplits(): initial loss:    0.9915042077827451\n",
      "learn_multisplits(): returning loss:  0.008837869537008188\n",
      "================================\n",
      "learn_multisplits(): initial loss:    1.0571048715692846\n",
      "learn_multisplits(): returning loss:  0.0162555631657429\n",
      "================================\n",
      "learn_multisplits(): initial loss:    23.253834519157962\n",
      "learn_multisplits(): returning loss:  0.2002199593552762\n",
      "================================\n",
      "learn_multisplits(): initial loss:    68.65538679566417\n",
      "learn_multisplits(): returning loss:  0.36219687848785154\n",
      "================================\n",
      "learn_multisplits(): initial loss:    28.245234063418017\n",
      "learn_multisplits(): returning loss:  0.2547403574277599\n",
      "================================\n",
      "learn_multisplits(): initial loss:    6.1266932622022745\n",
      "learn_multisplits(): returning loss:  0.09084479613831298\n",
      "================================\n",
      "learn_multisplits(): initial loss:    517.7898823788479\n",
      "learn_multisplits(): returning loss:  11.565968798473477\n",
      "================================\n",
      "learn_multisplits(): initial loss:    24.109925447587283\n",
      "learn_multisplits(): returning loss:  0.5569086789284071\n",
      "================================\n",
      "learn_multisplits(): initial loss:    8.72960177657462\n",
      "learn_multisplits(): returning loss:  0.15942227918592355\n",
      "================================\n",
      "learn_multisplits(): initial loss:    7.980701510326847\n",
      "learn_multisplits(): returning loss:  0.10372364088062694\n",
      "================================\n",
      "learn_multisplits(): initial loss:    17.194390307049357\n",
      "learn_multisplits(): returning loss:  0.11900577590207359\n",
      "================================\n",
      "learn_multisplits(): initial loss:    0.8015389361241592\n",
      "learn_multisplits(): returning loss:  0.002276559825520021\n",
      "================================\n",
      "learn_multisplits(): initial loss:    151.6681101260203\n",
      "learn_multisplits(): returning loss:  0.33860648986692315\n",
      "================================\n",
      "learn_multisplits(): initial loss:    77.33377896577342\n",
      "learn_multisplits(): returning loss:  0.3334145724955168\n",
      "================================\n",
      "learn_multisplits(): initial loss:    8.020984513082588\n",
      "learn_multisplits(): returning loss:  0.0875763462086666\n",
      "================================\n",
      "learn_multisplits(): initial loss:    42.23940711047147\n",
      "learn_multisplits(): returning loss:  0.42069932396960846\n",
      "================================\n",
      "learn_multisplits(): initial loss:    15.903855616437275\n",
      "learn_multisplits(): returning loss:  0.0946255152999268\n",
      "================================\n",
      "learn_multisplits(): initial loss:    131.29373751131536\n",
      "learn_multisplits(): returning loss:  0.8977247153852184\n",
      "================================\n",
      "learn_multisplits(): initial loss:    11.441997015270042\n",
      "learn_multisplits(): returning loss:  0.10189356516492284\n",
      "================================\n",
      "learn_multisplits(): initial loss:    0.7445931016075866\n",
      "learn_multisplits(): returning loss:  0.004511465196589308\n",
      "================================\n",
      "learn_multisplits(): initial loss:    27.713053468755955\n",
      "learn_multisplits(): returning loss:  0.46986534871043173\n",
      "================================\n",
      "learn_multisplits(): initial loss:    5.22480518493141\n",
      "learn_multisplits(): returning loss:  0.08430543994226894\n",
      "================================\n",
      "learn_multisplits(): initial loss:    32.78787619645716\n",
      "learn_multisplits(): returning loss:  0.35093325465854064\n",
      "================================\n",
      "learn_multisplits(): initial loss:    2.8225245624904214\n",
      "learn_multisplits(): returning loss:  0.0896466829384055\n",
      "================================\n",
      "learn_multisplits(): initial loss:    14.865038383205686\n",
      "learn_multisplits(): returning loss:  0.07741179670349754\n",
      "================================\n",
      "learn_multisplits(): initial loss:    16.960250117972315\n",
      "learn_multisplits(): returning loss:  0.01040583762437206\n",
      "================================\n",
      "learn_multisplits(): initial loss:    41.656758772890534\n",
      "learn_multisplits(): returning loss:  0.1647538414677866\n",
      "================================\n",
      "learn_multisplits(): initial loss:    17.53427368157204\n",
      "learn_multisplits(): returning loss:  0.2858546658000227\n",
      "================================\n",
      "learn_multisplits(): initial loss:    71.18828778984054\n",
      "learn_multisplits(): returning loss:  0.2721836036688503\n",
      "================================\n",
      "learn_multisplits(): initial loss:    304.7619467398497\n",
      "learn_multisplits(): returning loss:  4.711680131033063\n",
      "================================\n",
      "learn_multisplits(): initial loss:    524.4103497073617\n",
      "learn_multisplits(): returning loss:  15.02997799217701\n",
      "================================\n",
      "learn_multisplits(): initial loss:    24.100738090879606\n",
      "learn_multisplits(): returning loss:  0.3201297618103932\n",
      "================================\n",
      "learn_multisplits(): initial loss:    44.0364772652712\n",
      "learn_multisplits(): returning loss:  0.5009327172045527\n",
      "================================\n",
      "learn_multisplits(): initial loss:    956.7455350793568\n",
      "learn_multisplits(): returning loss:  26.451127417385578\n",
      "================================\n",
      "learn_multisplits(): initial loss:    4.827387432091553\n",
      "learn_multisplits(): returning loss:  0.0389493617156805\n",
      "================================\n",
      "learn_multisplits(): initial loss:    3.7723817976372476\n",
      "learn_multisplits(): returning loss:  0.06855376197286378\n",
      "================================\n",
      "learn_multisplits(): initial loss:    17.914646513664337\n",
      "learn_multisplits(): returning loss:  0.14682785363585232\n",
      "================================\n",
      "learn_multisplits(): initial loss:    119.97025567327194\n",
      "learn_multisplits(): returning loss:  0.5176453125016227\n",
      "================================\n",
      "learn_multisplits(): initial loss:    76.04889894203531\n",
      "learn_multisplits(): returning loss:  0.8113191650540671\n",
      "================================\n",
      "learn_multisplits(): initial loss:    209.8757268825402\n",
      "learn_multisplits(): returning loss:  0.6832256767565303\n",
      "================================\n",
      "learn_multisplits(): initial loss:    14.776191472253883\n",
      "learn_multisplits(): returning loss:  0.3770979308464089\n",
      "================================\n",
      "learn_multisplits(): initial loss:    27.49922048672844\n",
      "learn_multisplits(): returning loss:  0.44312602963731673\n",
      "================================\n",
      "learn_multisplits(): initial loss:    7.784453689910144\n",
      "learn_multisplits(): returning loss:  0.15925090184052182\n",
      "================================\n",
      "learn_multisplits(): initial loss:    73.48918796411658\n",
      "learn_multisplits(): returning loss:  0.3049446286590875\n",
      "================================\n",
      "learn_multisplits(): initial loss:    105.70860801238135\n",
      "learn_multisplits(): returning loss:  4.252598342898331\n",
      "================================\n",
      "learn_multisplits(): initial loss:    0.3464999734999366\n",
      "learn_multisplits(): returning loss:  0.0008262261644483939\n",
      "================================\n",
      "learn_multisplits(): initial loss:    1.2915158342437492\n",
      "learn_multisplits(): returning loss:  0.007858256651265876\n",
      "================================\n",
      "learn_multisplits(): initial loss:    44.25929934909648\n",
      "learn_multisplits(): returning loss:  1.2473568754329012\n",
      "================================\n",
      "learn_multisplits(): initial loss:    117.42082436723106\n",
      "learn_multisplits(): returning loss:  0.37836706137776377\n",
      "================================\n",
      "learn_multisplits(): initial loss:    10.973446083589428\n",
      "learn_multisplits(): returning loss:  0.1443149704973243\n",
      "================================\n",
      "learn_multisplits(): initial loss:    37.80822484956659\n",
      "learn_multisplits(): returning loss:  0.7368835141105625\n",
      "================================\n",
      "learn_multisplits(): initial loss:    5.345435066676448\n",
      "learn_multisplits(): returning loss:  0.08681874556603604\n",
      "================================\n",
      "learn_multisplits(): initial loss:    176.14973039764052\n",
      "learn_multisplits(): returning loss:  3.6168026003288105\n",
      "================================\n",
      "learn_multisplits(): initial loss:    46.59193559408405\n",
      "learn_multisplits(): returning loss:  0.31351157526883033\n",
      "================================\n",
      "learn_multisplits(): initial loss:    3.732560966814388\n",
      "learn_multisplits(): returning loss:  0.06334858985789937\n",
      "================================\n",
      "learn_multisplits(): initial loss:    9.011253133308038\n",
      "learn_multisplits(): returning loss:  0.11439415855657964\n",
      "================================\n",
      "learn_multisplits(): initial loss:    29.944220476668686\n",
      "learn_multisplits(): returning loss:  0.3045431965094403\n",
      "================================\n",
      "learn_multisplits(): initial loss:    69.48432684390589\n",
      "learn_multisplits(): returning loss:  1.1338818723925383\n",
      "================================\n",
      "learn_multisplits(): initial loss:    8793.579760955163\n",
      "learn_multisplits(): returning loss:  15.26340962946415\n",
      "================================\n",
      "learn_multisplits(): initial loss:    57.42064286767577\n",
      "learn_multisplits(): returning loss:  0.3540139251411014\n",
      "================================\n",
      "learn_multisplits(): initial loss:    3.095646273164642\n",
      "learn_multisplits(): returning loss:  0.020848163202425756\n",
      "================================\n",
      "learn_multisplits(): initial loss:    18.853688854780682\n",
      "learn_multisplits(): returning loss:  0.08084702271426467\n",
      "================================\n",
      "learn_multisplits(): initial loss:    25.324683097306984\n",
      "learn_multisplits(): returning loss:  0.1551569364307214\n",
      "================================\n",
      "learn_multisplits(): initial loss:    28.983206048229448\n",
      "learn_multisplits(): returning loss:  0.3057870498025995\n",
      "================================\n",
      "learn_multisplits(): initial loss:    96.57933043675627\n",
      "learn_multisplits(): returning loss:  2.025675407019805\n",
      "================================\n",
      "learn_multisplits(): initial loss:    15.088527712989995\n",
      "learn_multisplits(): returning loss:  0.27742060261535395\n",
      "================================\n",
      "learn_multisplits(): initial loss:    71.23333079960544\n",
      "learn_multisplits(): returning loss:  1.8561659212716632\n",
      "================================\n",
      "learn_multisplits(): initial loss:    113.23052116255838\n",
      "learn_multisplits(): returning loss:  0.6982869188809382\n",
      "================================\n",
      "learn_multisplits(): initial loss:    11.706420008312982\n",
      "learn_multisplits(): returning loss:  0.057224649502852984\n",
      "================================\n",
      "learn_multisplits(): initial loss:    20.150586436419754\n",
      "learn_multisplits(): returning loss:  0.3981761508566778\n",
      "================================\n",
      "learn_multisplits(): initial loss:    70.80989634697849\n",
      "learn_multisplits(): returning loss:  0.08680945232921239\n",
      "================================\n",
      "learn_multisplits(): initial loss:    60.62638355017784\n",
      "learn_multisplits(): returning loss:  1.1170757718892057\n",
      "================================\n",
      "learn_multisplits(): initial loss:    29.367214228162887\n",
      "learn_multisplits(): returning loss:  0.32722748069927765\n",
      "================================\n",
      "learn_multisplits(): initial loss:    7.0917158000775435\n",
      "learn_multisplits(): returning loss:  0.08304481877636653\n",
      "================================\n",
      "learn_multisplits(): initial loss:    21.23398891575561\n",
      "learn_multisplits(): returning loss:  0.2085516971695231\n",
      "================================\n",
      "learn_multisplits(): initial loss:    4947.40453854436\n",
      "learn_multisplits(): returning loss:  87.1948014497757\n",
      "================================\n",
      "learn_multisplits(): initial loss:    57.30189296450675\n",
      "learn_multisplits(): returning loss:  1.339264947268382\n",
      "================================\n",
      "learn_multisplits(): initial loss:    3.346299223445736\n",
      "learn_multisplits(): returning loss:  0.04852872382990631\n",
      "================================\n",
      "learn_multisplits(): initial loss:    11.311081721550808\n",
      "learn_multisplits(): returning loss:  0.06517198184340989\n",
      "================================\n",
      "learn_multisplits(): initial loss:    84.88346727534244\n",
      "learn_multisplits(): returning loss:  0.9079667385556757\n",
      "================================\n",
      "learn_multisplits(): initial loss:    17.703917570835124\n",
      "learn_multisplits(): returning loss:  0.25058912045275306\n",
      "================================\n",
      "learn_multisplits(): initial loss:    5.255430490906983\n",
      "learn_multisplits(): returning loss:  0.08262343836144088\n",
      "================================\n",
      "learn_multisplits(): initial loss:    5785.553785316255\n",
      "learn_multisplits(): returning loss:  40.19281170517206\n",
      "================================\n",
      "learn_multisplits(): initial loss:    16.536726794921044\n",
      "learn_multisplits(): returning loss:  0.49472234123590764\n",
      "================================\n",
      "learn_multisplits(): initial loss:    3.450801516508759\n",
      "learn_multisplits(): returning loss:  0.09416145431250152\n",
      "================================\n",
      "learn_multisplits(): initial loss:    14.614208600764382\n",
      "learn_multisplits(): returning loss:  0.4159501591340295\n",
      "================================\n",
      "learn_multisplits(): initial loss:    107.17399450076593\n",
      "learn_multisplits(): returning loss:  2.055402110765928\n",
      "================================\n",
      "learn_multisplits(): initial loss:    5.944340161993972\n",
      "learn_multisplits(): returning loss:  0.07642581932912385\n",
      "================================\n",
      "learn_multisplits(): initial loss:    213.5472026763794\n",
      "learn_multisplits(): returning loss:  11.527713682502508\n",
      "================================\n",
      "learn_multisplits(): initial loss:    14.121025927445576\n",
      "learn_multisplits(): returning loss:  0.3387114617750613\n",
      "================================\n",
      "learn_multisplits(): initial loss:    7.654714468671117\n",
      "learn_multisplits(): returning loss:  0.14704065257911872\n",
      "================================\n",
      "learn_multisplits(): initial loss:    85.51175711918052\n",
      "learn_multisplits(): returning loss:  0.6692050032943728\n",
      "================================\n",
      "learn_multisplits(): initial loss:    14.562241647936332\n",
      "learn_multisplits(): returning loss:  0.18441707946529742\n",
      "================================\n",
      "learn_multisplits(): initial loss:    9743.106186039468\n",
      "learn_multisplits(): returning loss:  24.544892132282257\n",
      "================================\n",
      "learn_multisplits(): initial loss:    4.524464583044886\n",
      "learn_multisplits(): returning loss:  0.018452124961815503\n",
      "================================\n",
      "learn_multisplits(): initial loss:    34.78185234557845\n",
      "learn_multisplits(): returning loss:  0.5728516938317343\n",
      "================================\n",
      "learn_multisplits(): initial loss:    19.197615525993253\n",
      "learn_multisplits(): returning loss:  0.23976315572227305\n",
      "================================\n",
      "learn_multisplits(): initial loss:    2.520238596017139\n",
      "learn_multisplits(): returning loss:  0.036720913571967946\n",
      "================================\n",
      "learn_multisplits(): initial loss:    1.775577631430614\n",
      "learn_multisplits(): returning loss:  0.03700239520969734\n",
      "================================\n",
      "learn_multisplits(): initial loss:    1.94387158666766\n",
      "learn_multisplits(): returning loss:  0.040597627591161325\n",
      "================================\n",
      "learn_multisplits(): initial loss:    5.30160862117328\n",
      "learn_multisplits(): returning loss:  0.07650627150654943\n",
      "================================\n",
      "learn_multisplits(): initial loss:    131.56126037595067\n",
      "learn_multisplits(): returning loss:  5.45045680378098\n",
      "================================\n",
      "learn_multisplits(): initial loss:    71.531277400312\n",
      "learn_multisplits(): returning loss:  0.3865050994836345\n",
      "================================\n",
      "learn_multisplits(): initial loss:    32.39972646112059\n",
      "learn_multisplits(): returning loss:  0.6524447073728961\n",
      "================================\n",
      "learn_multisplits(): initial loss:    7068.674073446071\n",
      "learn_multisplits(): returning loss:  28.901128947734833\n",
      "================================\n",
      "learn_multisplits(): initial loss:    11.249142194625339\n",
      "learn_multisplits(): returning loss:  0.010142977784708941\n",
      "================================\n",
      "learn_multisplits(): initial loss:    2.6249800636536897\n",
      "learn_multisplits(): returning loss:  0.02336269381398591\n",
      "================================\n",
      "learn_multisplits(): initial loss:    26.834143878609055\n",
      "learn_multisplits(): returning loss:  0.8954260120633096\n",
      "================================\n",
      "learn_multisplits(): initial loss:    6848.163874343506\n",
      "learn_multisplits(): returning loss:  13.393120065331459\n",
      "X_res mse / X mse:  0.0006192425\n",
      "X_res mse / X mse after lstsq:  0.027322868\n"
     ]
    }
   ],
   "source": [
    "if method == METHOD_PLUTO:\n",
    "    est3 = mm.estFactory(X_path=AMM_train_dirs[\"linearin_path_train\"], W_path=AMM_train_dirs[\"weightpath\"], \n",
    "                        Y_path=AMM_train_dirs[\"y_train\"], dir= AMM_train_dirs[\"dir_train\"], ncodebooks=ncodebooks, \n",
    "                        ncentroids=ncentroids, methods=[method], nbits=nbits, quantize_lut = quantize_lut, \n",
    "                        upcast_every=upcast_every, bias_path=AMM_train_dirs[\"biaspath\"],lut_work_const=-1)\n",
    "elif method == METHOD_MITHRAL:\n",
    "    est3 = mm.estFactory(X_path=AMM_train_dirs[\"linearin_path_train\"], W_path=AMM_train_dirs[\"weightpath\"], \n",
    "                        Y_path=AMM_train_dirs[\"y_train\"], dir= AMM_train_dirs[\"dir_train\"], ncodebooks=ncodebooks, \n",
    "                        ncentroids=ncentroids, methods=[method], nbits=nbits, quantize_lut = quantize_lut,\n",
    "                        upcast_every=upcast_every, lut_work_const=lut_work_const)\n",
    "else:\n",
    "    est3 = mm.estFactory(X_path=AMM_train_dirs[\"linearin_path_train\"], W_path=AMM_train_dirs[\"weightpath\"], \n",
    "                        Y_path=AMM_train_dirs[\"y_train\"], dir= AMM_train_dirs[\"dir_train\"], ncodebooks=ncodebooks, \n",
    "                        ncentroids=ncentroids, methods=[method], nbits=nbits, quantize_lut = quantize_lut,\n",
    "                        upcast_every=upcast_every)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.load(AMM_train_dirs[\"dir_test\"]+'/'+AMM_train_dirs[\"linearin_path_test\"])\n",
    "w_test = np.load(AMM_train_dirs[\"dir_train\"]+'/'+AMM_train_dirs[\"weightpath\"])\n",
    "bias = np.load(AMM_train_dirs[\"dir_train\"]+'/'+AMM_train_dirs[\"biaspath\"])\n",
    "# print(type(est3))\n",
    "y_out_matmul = mm.eval_matmul(est3, x_test, w_test) # MADDNESS乘法的结果\n",
    "# y_out_last = mu.softmax(y_out_matmul + bias.T) # MADDNESS替换后当前层输出，即+bias并激活函数后的结果\n",
    "if method == METHOD_PLUTO:\n",
    "    y_out_last = y_out_matmul\n",
    "else:\n",
    "    y_out_last = y_out_matmul + bias.T # MADDNESS替换后当前层输出，即+bias并不需要激活函数后的结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.5608179  -0.00333595  0.57549685 ...  0.29517347  0.06012775\n",
      "   0.5719095 ]\n",
      " [ 0.49712175  0.0350047   0.56627613 ...  0.25265834  0.01070945\n",
      "   0.501087  ]\n",
      " [ 0.47568503  0.00229609  0.5270201  ...  0.2707689   0.04615272\n",
      "   0.51801956]\n",
      " ...\n",
      " [ 0.4403619   0.12603964  0.27567023 ...  0.2853439   0.20030597\n",
      "   0.33327356]\n",
      " [ 0.34505352 -0.13143547  0.11088285 ...  0.34841108  0.09070411\n",
      "   0.39584517]\n",
      " [ 0.34405532  0.01896085  0.28083256 ...  0.05437541  0.14851482\n",
      "   0.2602688 ]]\n",
      "y_out_last.shape:  (1024000, 64)\n",
      "y_out_last_re.shape:  (1000, 32, 32, 64)\n"
     ]
    }
   ],
   "source": [
    "print(y_out_last)\n",
    "print(\"y_out_last.shape: \", y_out_last.shape)\n",
    "y_out_last_re = y_out_last.reshape(test_sam_num, batch_size, -1, y_out_last.shape[-1]) #AMM字典模式需要复原y大小\n",
    "print(\"y_out_last_re.shape: \", y_out_last_re.shape)\n",
    "if method == METHOD_SCALAR_QUANTIZE:\n",
    "    np.save(os.path.join(AMM_train_dirs[\"dir_result\"], '%s%s_trsam%i_tesam%i_fb%i_nbits%i.npy' % \n",
    "                                                        (method, linear_name, train_sam_num, test_sam_num, feedback_bits, nbits)), \n",
    "                                                        y_out_last_re.astype(np.float32))\n",
    "elif method == METHOD_MITHRAL or method == METHOD_PLUTO:\n",
    "    np.save(os.path.join(AMM_train_dirs[\"dir_result\"], '%s%s_trsam%i_tesam%i_fb%i_cb%i_ct%i_ql%i_nb%i_uc%i_lwc%i.npy' % \n",
    "                                                        (method, linear_name, train_sam_num, test_sam_num, feedback_bits, \n",
    "                                                        ncodebooks, ncentroids, quantize_lut, nbits, upcast_every, lut_work_const)), y_out_last_re)\n",
    "elif method == METHOD_PQ or method == METHOD_MITHRALPQ:\n",
    "    np.save(os.path.join(AMM_train_dirs[\"dir_result\"], '%s%s_trsam%i_tesam%i_fb%i_cb%i_ct%i_ql%i_nb%i_uc%i.npy' % \n",
    "                                                        (method, linear_name, train_sam_num, test_sam_num, feedback_bits, \n",
    "                                                        ncodebooks, ncentroids, quantize_lut, nbits, upcast_every)), y_out_last_re)\n",
    "else:\n",
    "    np.save(os.path.join(AMM_train_dirs[\"dir_result\"], '%s%s_trsam%i_tesam%i_fb%i_cb%i_ct%i.npy' % \n",
    "                                                        (method, linear_name, train_sam_num, test_sam_num, feedback_bits, \n",
    "                                                        ncodebooks, ncentroids)), y_out_last_re)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pqhdr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ec04f7dc2b3ae4a422de9aaf96e8c62fe190a2869a08d14112cb2d7713497448"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
