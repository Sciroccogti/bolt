{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matmul as mm\n",
    "import math_util as mu\n",
    "import scipy.io as io\n",
    "from amm_methods import *\n",
    "import socket # Obtain the current host name, which can be used to select different data directories and result saving directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = METHOD_MITHRAL\n",
    "# method = METHOD_PQ\n",
    "# method = METHOD_EXACT\n",
    "# method = METHOD_SCALAR_QUANTIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "feedback_bits = 256\n",
    "ncodebooks=128\n",
    "ncentroids=16\n",
    "train_sam_num = 3000 # 训练集样本数\n",
    "split = 16 # A的列、B的行分割成split份"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "host_name = socket.gethostname()\n",
    "if host_name == 'DESKTOP-PLRL7TK':\n",
    "    dir_train = 'E:\\\\hdr\\\\研一\\\\华为-深度学习\\\\intermediate\\\\intermediate8dbfc1'\n",
    "    dir_result = ''\n",
    "elif host_name == 'DESKTOP-6FOH47P':\n",
    "    dir_train = 'F:\\\\Projects\\\\python\\\\PQ\\\\intermediate8dbfc1'\n",
    "    dir_result = 'F:\\\\Projects\\\\python\\\\PQ\\\\res'\n",
    "    data_to_fcpath_train= 'data_to_fc_e39_7999.npy'\n",
    "    featurepath_train= 'feature_e39_7999.npy'\n",
    "    data_to_fcpath_test = 'data_to_fc_e39_7999.npy'\n",
    "    featurepath_test = 'feature_e39_7999.npy'\n",
    "elif host_name == 'jm-System-Product-Name':\n",
    "    dir_train = '/data/hdr/transformer_data/joined'\n",
    "    dir_result = '/data/hdr/pq/res'\n",
    "    data_to_fcpath_train= 'data_to_fc_train_f%i_sam%i.npy' % (feedback_bits, train_sam_num)\n",
    "    y_train = 'y_train_f%i_sam%i.npy' % (feedback_bits, train_sam_num)\n",
    "    featurepath_train= 'feature_train_f%i_sam%i.npy' % (feedback_bits, train_sam_num)\n",
    "    data_to_fcpath_test = 'data_to_fc_test.npy'\n",
    "    featurepath_test = 'feature_test.npy'\n",
    "    y_test = 'y_test.npy'\n",
    "else:\n",
    "    raise NameError(\"You are running the script in a new computer, please define dir_train\")\n",
    "\n",
    "dir_train_split = os.path.join(dir_train, 'train', 'f'+str(feedback_bits), 'split'+str(split))\n",
    "try:\n",
    "    os.mkdir(dir_train_split)\n",
    "except FileExistsError:\n",
    "    pass\n",
    "# print(dir_train_split)\n",
    "dir_test_split = os.path.join(dir_train, 'test', 'f'+str(feedback_bits), 'split'+str(split))\n",
    "try:\n",
    "    os.mkdir(dir_test_split)\n",
    "except FileExistsError:\n",
    "    pass \n",
    "\n",
    "\n",
    "weightpath = 'encoder_fcw.npy'\n",
    "biaspath = 'encoder_fcb.npy'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "切分训练集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(96000, 2048)\n"
     ]
    }
   ],
   "source": [
    "data_to_fc_train = np.load(os.path.join(dir_train, data_to_fcpath_train))\n",
    "print(data_to_fc_train.shape)\n",
    "split_size = int(data_to_fc_train.shape[1] / split) # split后单个训练集A的列数\n",
    "data_to_fc_train_split_path_list = []\n",
    "for i in range(split):\n",
    "    data_to_fc_train_split_path_list.append(os.path.join(dir_train_split, 'data_to_fc_train_f'+str(feedback_bits)+'_split'+str(split)+'_'+str(i)+'.npy'))\n",
    "    np.save(data_to_fc_train_split_path_list[i], data_to_fc_train[np.ix_(range(data_to_fc_train.shape[0]), range(i*split_size,(i+1)*split_size))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2048, 256)\n"
     ]
    }
   ],
   "source": [
    "weight_train = np.load(os.path.join(dir_train, weightpath))\n",
    "print(weight_train.shape)\n",
    "weight_train_split_path_list = []\n",
    "for i in range(split):\n",
    "    weight_train_split_path_list.append(os.path.join(dir_train_split, 'weight_train_f'+str(feedback_bits)+'_split'+str(split)+'_'+str(i)+'.npy'))\n",
    "    np.save(weight_train_split_path_list[i], weight_train[np.ix_(range(i*split_size,(i+1)*split_size), range(weight_train.shape[1]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输入与weight相乘\n",
    "y_train_split_path_list = []\n",
    "for i in range(split):\n",
    "    y_train_split_path_list.append(os.path.join(dir_train_split, 'y_train_f'+str(feedback_bits)+'_split'+str(split)+'_'+str(i)+'.npy'))\n",
    "    xx = np.load(data_to_fc_train_split_path_list[i])\n",
    "    ww = np.load(weight_train_split_path_list[i])\n",
    "    np.save(y_train_split_path_list[i], np.matmul(xx, ww))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "切分测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32000, 2048)\n"
     ]
    }
   ],
   "source": [
    "data_to_fc_test = np.load(os.path.join(dir_train, data_to_fcpath_test))\n",
    "print(data_to_fc_test.shape)\n",
    "# split_size = int(data_to_fc_train.shape[1] / split) # split后单个训练集A的列数\n",
    "data_to_fc_test_split_path_list = []\n",
    "for i in range(split):\n",
    "    data_to_fc_test_split_path_list.append(os.path.join(dir_test_split, 'data_to_fc_test_f'+str(feedback_bits)+'_split'+str(split)+'_'+str(i)+'.npy'))\n",
    "    np.save(data_to_fc_test_split_path_list[i], data_to_fc_test[np.ix_(range(data_to_fc_test.shape[0]), range(i*split_size,(i+1)*split_size))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输入与weight相乘\n",
    "y_test_split_path_list = []\n",
    "for i in range(split):\n",
    "    y_test_split_path_list.append(os.path.join(dir_test_split, 'y_test_f'+str(feedback_bits)+'_split'+str(split)+'_'+str(i)+'.npy'))\n",
    "    xx = np.load(data_to_fc_test_split_path_list[i])\n",
    "    ww = np.load(weight_train_split_path_list[i])\n",
    "    np.save(y_test_split_path_list[i], np.matmul(xx, ww))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "running method:  Mithral\n",
      "X_res mse / X mse:  0.016641002\n",
      "fitting dense lstsq to X_res\n",
      "X_res mse / X mse after lstsq:  0.012994092\n",
      "==============================\n",
      "running method:  Mithral\n",
      "X_res mse / X mse:  0.0152959125\n",
      "fitting dense lstsq to X_res\n",
      "X_res mse / X mse after lstsq:  0.012704283\n",
      "==============================\n",
      "running method:  Mithral\n",
      "X_res mse / X mse:  0.015475823\n",
      "fitting dense lstsq to X_res\n",
      "X_res mse / X mse after lstsq:  0.013594396\n",
      "==============================\n",
      "running method:  Mithral\n",
      "X_res mse / X mse:  0.015384653\n",
      "fitting dense lstsq to X_res\n",
      "X_res mse / X mse after lstsq:  0.01340051\n",
      "==============================\n",
      "running method:  Mithral\n",
      "X_res mse / X mse:  0.016944893\n",
      "fitting dense lstsq to X_res\n",
      "X_res mse / X mse after lstsq:  0.013002489\n",
      "==============================\n",
      "running method:  Mithral\n",
      "X_res mse / X mse:  0.015139081\n",
      "fitting dense lstsq to X_res\n",
      "X_res mse / X mse after lstsq:  0.012707036\n",
      "==============================\n",
      "running method:  Mithral\n",
      "X_res mse / X mse:  0.015480162\n",
      "fitting dense lstsq to X_res\n",
      "X_res mse / X mse after lstsq:  0.013525557\n",
      "==============================\n",
      "running method:  Mithral\n",
      "X_res mse / X mse:  0.015347608\n",
      "fitting dense lstsq to X_res\n",
      "X_res mse / X mse after lstsq:  0.013368352\n",
      "==============================\n",
      "running method:  Mithral\n",
      "X_res mse / X mse:  0.02165235\n",
      "fitting dense lstsq to X_res\n",
      "X_res mse / X mse after lstsq:  0.014663053\n",
      "==============================\n",
      "running method:  Mithral\n",
      "X_res mse / X mse:  0.018540455\n",
      "fitting dense lstsq to X_res\n",
      "X_res mse / X mse after lstsq:  0.014850765\n",
      "==============================\n",
      "running method:  Mithral\n",
      "X_res mse / X mse:  0.017878644\n",
      "fitting dense lstsq to X_res\n",
      "X_res mse / X mse after lstsq:  0.015481544\n",
      "==============================\n",
      "running method:  Mithral\n",
      "X_res mse / X mse:  0.01775342\n",
      "fitting dense lstsq to X_res\n",
      "X_res mse / X mse after lstsq:  0.015130152\n",
      "==============================\n",
      "running method:  Mithral\n",
      "X_res mse / X mse:  0.021757897\n",
      "fitting dense lstsq to X_res\n",
      "X_res mse / X mse after lstsq:  0.014640632\n",
      "==============================\n",
      "running method:  Mithral\n",
      "X_res mse / X mse:  0.01870864\n",
      "fitting dense lstsq to X_res\n",
      "X_res mse / X mse after lstsq:  0.014936002\n",
      "==============================\n",
      "running method:  Mithral\n",
      "X_res mse / X mse:  0.017864214\n",
      "fitting dense lstsq to X_res\n",
      "X_res mse / X mse after lstsq:  0.015365292\n",
      "==============================\n",
      "running method:  Mithral\n",
      "X_res mse / X mse:  0.017780326\n",
      "fitting dense lstsq to X_res\n",
      "X_res mse / X mse after lstsq:  0.015147157\n"
     ]
    }
   ],
   "source": [
    "est_list = []\n",
    "for i in range(split):\n",
    "    dir_est, X_path = os.path.split(data_to_fc_train_split_path_list[i])\n",
    "    dir_est, W_path = os.path.split(weight_train_split_path_list[i])\n",
    "    dir_est, Y_path = os.path.split(y_train_split_path_list[i])\n",
    "    est3 = mm.estFactory(X_path=X_path, W_path=W_path, Y_path=Y_path, dir= dir_est, ncodebooks=ncodebooks, ncentroids=ncentroids, methods=[method])\n",
    "    est_list.append(est3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_split_out_matmul_list = []\n",
    "for i in range(split):\n",
    "    x_test = np.load(data_to_fc_test_split_path_list[i])\n",
    "    w_test = np.load(weight_train_split_path_list[i])\n",
    "    y_split_out_matmul = mm.eval_matmul(est_list[i], x_test, w_test)\n",
    "    y_split_out_matmul_list.append(y_split_out_matmul)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split 的矩阵结果合成\n",
    "y_out_matmul = y_split_out_matmul_list[0]\n",
    "if split>1:\n",
    "    for i in range(1, split):\n",
    "        y_out_matmul += y_split_out_matmul_list[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias = np.load(dir_train+'/'+biaspath)\n",
    "y_out_last = y_out_matmul + bias.T # MADDNESS替换后当前层输出，即+bias并不需要激活函数后的结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.23255426 -0.19161709 -0.62854695 ... -0.10785938  0.10200073\n",
      "  -0.09245922]\n",
      " [-0.2756071  -0.01940576 -0.34674653 ... -0.39357367  0.03546455\n",
      "   0.00147425]\n",
      " [ 0.5541385  -0.01549185 -0.17453521 ... -0.64014894  0.16853695\n",
      "   0.06801046]\n",
      " ...\n",
      " [ 0.4132383   0.22325568 -0.5072162  ... -0.19005117 -0.3441832\n",
      "   0.01712981]\n",
      " [ 0.29190758 -0.08202806 -0.27629647 ...  0.04086862  0.04720623\n",
      "   0.18934117]\n",
      " [-0.52609634  0.03930264 -0.46024948 ... -0.307468   -0.15631628\n",
      "   0.17368561]]\n",
      "(32000, 256)\n"
     ]
    }
   ],
   "source": [
    "print(y_out_last)\n",
    "print(y_out_last.shape)\n",
    "# np.save(\"LDPC_decoder_NET_testdata/\" + snr + \"nomul_matmul_yout_matmul\", y_out_matmul)\n",
    "# np.save(dir_result+'/'+method+'fc1_fb256_cb%i_ct%i.npy' % (ncodebooks, ncentroids), y_out_matmul)\n",
    "np.save(dir_result+'/'+method+'fc1_split%i_fb%i_cb%i_ct%i.npy' % (split, feedback_bits, ncodebooks, ncentroids), y_out_last)\n",
    "# io.savemat(dir_result+'\\\\fc1_256.mat', {\"NN_output_buffer\": y_out_last})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('pqhdr')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ec04f7dc2b3ae4a422de9aaf96e8c62fe190a2869a08d14112cb2d7713497448"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
