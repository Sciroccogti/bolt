{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "decoder transformer层的linear2层（dtl2）替换为近似矩阵乘法, 32\\*32\\*128, 128\\*64, 32\\*32\\*64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matmul as mm\n",
    "import math_util as mu\n",
    "# import scipy.io as io\n",
    "from amm_methods import *\n",
    "import socket # Obtain the current host name, which can be used to select different data directories and result saving directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# root_path = '/data/hdr/csi_transformer/pic/'\n",
    "# print(root_path)\n",
    "# root_path2 = '/'.join(root_path.split(\"/\")[:-2])\n",
    "# # sys.path.append(root_path)\n",
    "# print(root_path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = METHOD_MITHRAL\n",
    "# method = METHOD_PQ\n",
    "# method = METHOD_EXACT\n",
    "# method = METHOD_SCALAR_QUANTIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_name = 'dtl2'\n",
    "feedback_bits = 256\n",
    "ncodebooks = 128 # max:128\n",
    "ncentroids = 256\n",
    "if method == METHOD_MITHRAL:\n",
    "    ncentroids = 16\n",
    "train_sam_num = 200 # 训练集样本数\n",
    "test_sam_num = 1000 # 测试集样本数\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "host_name = socket.gethostname()\n",
    "if host_name == 'DESKTOP-PLRL7TK':\n",
    "    dir_train = 'E:\\\\hdr\\\\研一\\\\华为-深度学习\\\\intermediate\\\\intermediate8dbfc1'\n",
    "    dir_result = ''\n",
    "elif host_name == 'DESKTOP-6FOH47P':\n",
    "    dir_train = 'F:\\\\Projects\\\\python\\\\PQ\\\\intermediate8dbfc1'\n",
    "    dir_result = 'F:\\\\Projects\\\\python\\\\PQ\\\\res'\n",
    "    data_to_fcpath_train= ''\n",
    "    featurepath_train= ''\n",
    "    data_to_fcpath_test = ''\n",
    "    featurepath_test = ''\n",
    "elif host_name == 'jm-System-Product-Name':\n",
    "    dir_train = os.path.join('/data/hdr/transformer_data/joined', 'train', 'f'+str(feedback_bits))\n",
    "    dir_test = os.path.join('/data/hdr/transformer_data/joined', 'test', 'f'+str(feedback_bits))\n",
    "    dir_result = '/data/hdr/pq/res'\n",
    "    data_to_fcpath_train= 'dx_linear2in_train_f%i_sam%i.npy' % (feedback_bits, train_sam_num)\n",
    "    y_train = 'dx_linear2_y_train_f%i_sam%i.npy' % (feedback_bits, train_sam_num)\n",
    "    featurepath_train= 'dx_linear2out_train_f%i_sam%i.npy' % (feedback_bits, train_sam_num)\n",
    "    data_to_fcpath_test = 'dx_linear2in_test_f%i_sam%i.npy' % (feedback_bits, test_sam_num)\n",
    "    featurepath_test = 'dx_linear2out_test_f%i_sam%i.npy' % (feedback_bits, test_sam_num)\n",
    "    # y_test = 'y_test.npy'\n",
    "else:\n",
    "    raise NameError(\"You are running the script in a new computer, please define dirs\")\n",
    "\n",
    "\n",
    "weightpath = 'dx_linear2_w_f256.npy'\n",
    "biaspath = 'dx_linear2_b_f256.npy'\n",
    "dir_result = os.path.join(dir_result, method, \"f%i\" % feedback_bits, linear_name)\n",
    "try:\n",
    "    os.mkdir(dir_result)\n",
    "except FileExistsError:\n",
    "    pass \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "running method:  Mithral\n",
      "_learn_mithral_initialization heuristic pq\n",
      "================================\n",
      "learn_multisplits(): initial loss:    15335.366763896935\n",
      "learn_multisplits(): returning loss:  116.17975596431643\n",
      "================================\n",
      "learn_multisplits(): initial loss:    2729.5847010158745\n",
      "learn_multisplits(): returning loss:  12.348652828484774\n",
      "================================\n",
      "learn_multisplits(): initial loss:    34684.49062377929\n",
      "learn_multisplits(): returning loss:  140.88686467846568\n",
      "================================\n",
      "learn_multisplits(): initial loss:    5804.05514449954\n",
      "learn_multisplits(): returning loss:  51.06512192636728\n",
      "================================\n",
      "learn_multisplits(): initial loss:    4465.688923904597\n",
      "learn_multisplits(): returning loss:  29.832055100705475\n",
      "================================\n",
      "learn_multisplits(): initial loss:    332277.4404678556\n",
      "learn_multisplits(): returning loss:  185.87064290046692\n",
      "================================\n",
      "learn_multisplits(): initial loss:    13935.287383412127\n",
      "learn_multisplits(): returning loss:  107.04461818165146\n",
      "================================\n",
      "learn_multisplits(): initial loss:    3783.001805448234\n",
      "learn_multisplits(): returning loss:  25.572614498902112\n",
      "================================\n",
      "learn_multisplits(): initial loss:    4478.80417510502\n",
      "learn_multisplits(): returning loss:  25.859825311228633\n",
      "================================\n",
      "learn_multisplits(): initial loss:    849.9132458496094\n",
      "learn_multisplits(): returning loss:  4.09726411943412\n",
      "================================\n",
      "learn_multisplits(): initial loss:    3666.1240901348\n",
      "learn_multisplits(): returning loss:  21.56999462004751\n",
      "================================\n",
      "learn_multisplits(): initial loss:    2125.8585814211474\n",
      "learn_multisplits(): returning loss:  10.033977911822785\n",
      "================================\n",
      "learn_multisplits(): initial loss:    32386.436994732594\n",
      "learn_multisplits(): returning loss:  163.3772145807743\n",
      "================================\n",
      "learn_multisplits(): initial loss:    13218.837648158069\n",
      "learn_multisplits(): returning loss:  88.00556846702239\n",
      "================================\n",
      "learn_multisplits(): initial loss:    4320.076416910888\n",
      "learn_multisplits(): returning loss:  27.7841271199286\n",
      "================================\n",
      "learn_multisplits(): initial loss:    5152.661844341084\n",
      "learn_multisplits(): returning loss:  37.02357539348304\n",
      "================================\n",
      "learn_multisplits(): initial loss:    1284.0016957353753\n",
      "learn_multisplits(): returning loss:  5.973073330579065\n",
      "================================\n",
      "learn_multisplits(): initial loss:    16192.691895664939\n",
      "learn_multisplits(): returning loss:  85.45449960138649\n",
      "================================\n",
      "learn_multisplits(): initial loss:    16163.247858856925\n",
      "learn_multisplits(): returning loss:  177.95197166875005\n",
      "================================\n",
      "learn_multisplits(): initial loss:    56709.181155390754\n",
      "learn_multisplits(): returning loss:  442.38302659988403\n",
      "================================\n",
      "learn_multisplits(): initial loss:    2494.936367265415\n",
      "learn_multisplits(): returning loss:  17.01709047848711\n",
      "================================\n",
      "learn_multisplits(): initial loss:    5279.453123944329\n",
      "learn_multisplits(): returning loss:  23.527957770973444\n",
      "================================\n",
      "learn_multisplits(): initial loss:    3644.0079967471966\n",
      "learn_multisplits(): returning loss:  14.490649106376\n",
      "================================\n",
      "learn_multisplits(): initial loss:    58368.93738132003\n",
      "learn_multisplits(): returning loss:  474.0404028892517\n",
      "================================\n",
      "learn_multisplits(): initial loss:    3457.2077752887453\n",
      "learn_multisplits(): returning loss:  18.4369381852448\n",
      "================================\n",
      "learn_multisplits(): initial loss:    10107.826157416104\n",
      "learn_multisplits(): returning loss:  65.54074917733669\n",
      "================================\n",
      "learn_multisplits(): initial loss:    9602.328782992361\n",
      "learn_multisplits(): returning loss:  50.68865842116065\n",
      "================================\n",
      "learn_multisplits(): initial loss:    3101.905124478042\n",
      "learn_multisplits(): returning loss:  20.41486712240514\n",
      "================================\n",
      "learn_multisplits(): initial loss:    676.3708778121404\n",
      "learn_multisplits(): returning loss:  2.7215757818497663\n",
      "================================\n",
      "learn_multisplits(): initial loss:    80.40896263582601\n",
      "learn_multisplits(): returning loss:  0.3672078958231493\n",
      "================================\n",
      "learn_multisplits(): initial loss:    3724.9722347640245\n",
      "learn_multisplits(): returning loss:  14.255131091786877\n",
      "================================\n",
      "learn_multisplits(): initial loss:    5668.424376964572\n",
      "learn_multisplits(): returning loss:  44.17527206102386\n",
      "================================\n",
      "learn_multisplits(): initial loss:    5915.546890371964\n",
      "learn_multisplits(): returning loss:  33.97475561313331\n",
      "================================\n",
      "learn_multisplits(): initial loss:    13932.24908597947\n",
      "learn_multisplits(): returning loss:  130.91363048553467\n",
      "================================\n",
      "learn_multisplits(): initial loss:    3501.9762854310684\n",
      "learn_multisplits(): returning loss:  17.164502751082182\n",
      "================================\n",
      "learn_multisplits(): initial loss:    1427.61447877984\n",
      "learn_multisplits(): returning loss:  5.518724133530435\n",
      "================================\n",
      "learn_multisplits(): initial loss:    5937.345183347987\n",
      "learn_multisplits(): returning loss:  34.94871310144663\n",
      "================================\n",
      "learn_multisplits(): initial loss:    1859.1727668276242\n",
      "learn_multisplits(): returning loss:  6.002699305907665\n",
      "================================\n",
      "learn_multisplits(): initial loss:    3779.9937311291515\n",
      "learn_multisplits(): returning loss:  21.01302961473549\n",
      "================================\n",
      "learn_multisplits(): initial loss:    5731.518474895488\n",
      "learn_multisplits(): returning loss:  17.961362872333222\n",
      "================================\n",
      "learn_multisplits(): initial loss:    5716.366981201168\n",
      "learn_multisplits(): returning loss:  42.67520383000374\n",
      "================================\n",
      "learn_multisplits(): initial loss:    6579.099187060521\n",
      "learn_multisplits(): returning loss:  43.421504540368915\n",
      "================================\n",
      "learn_multisplits(): initial loss:    26714.721105803255\n",
      "learn_multisplits(): returning loss:  149.35918518924154\n",
      "================================\n",
      "learn_multisplits(): initial loss:    6678.568121652673\n",
      "learn_multisplits(): returning loss:  19.983056620623994\n",
      "================================\n",
      "learn_multisplits(): initial loss:    2374.258848532568\n",
      "learn_multisplits(): returning loss:  8.102198345457325\n",
      "================================\n",
      "learn_multisplits(): initial loss:    4175.01164191298\n",
      "learn_multisplits(): returning loss:  36.37642985582352\n",
      "================================\n",
      "learn_multisplits(): initial loss:    3672.129119285867\n",
      "learn_multisplits(): returning loss:  19.209015192463994\n",
      "================================\n",
      "learn_multisplits(): initial loss:    2264.4083808183195\n",
      "learn_multisplits(): returning loss:  8.511967896396717\n",
      "================================\n",
      "learn_multisplits(): initial loss:    11712.42080980688\n",
      "learn_multisplits(): returning loss:  16.409598877369845\n",
      "================================\n",
      "learn_multisplits(): initial loss:    33.50700177189697\n",
      "learn_multisplits(): returning loss:  0.06802891306840836\n",
      "================================\n",
      "learn_multisplits(): initial loss:    6124.723045108021\n",
      "learn_multisplits(): returning loss:  60.59128411859274\n",
      "================================\n",
      "learn_multisplits(): initial loss:    2904.39536002947\n",
      "learn_multisplits(): returning loss:  16.916904056910425\n",
      "================================\n",
      "learn_multisplits(): initial loss:    12095.105774687523\n",
      "learn_multisplits(): returning loss:  100.6197977613192\n",
      "================================\n",
      "learn_multisplits(): initial loss:    1032.1059352333832\n",
      "learn_multisplits(): returning loss:  2.9060278556612062\n",
      "================================\n",
      "learn_multisplits(): initial loss:    15802.063129834834\n",
      "learn_multisplits(): returning loss:  89.45507380738854\n",
      "================================\n",
      "learn_multisplits(): initial loss:    12802.37628798962\n",
      "learn_multisplits(): returning loss:  74.71559509634972\n",
      "================================\n",
      "learn_multisplits(): initial loss:    2083.9726744472796\n",
      "learn_multisplits(): returning loss:  10.359297278323293\n",
      "================================\n",
      "learn_multisplits(): initial loss:    19958.855976952327\n",
      "learn_multisplits(): returning loss:  151.31561666168272\n",
      "================================\n",
      "learn_multisplits(): initial loss:    4945.064439540434\n",
      "learn_multisplits(): returning loss:  33.26238254457712\n",
      "================================\n",
      "learn_multisplits(): initial loss:    2577.993830991909\n",
      "learn_multisplits(): returning loss:  16.793864184059203\n",
      "================================\n",
      "learn_multisplits(): initial loss:    433.57312855338563\n",
      "learn_multisplits(): returning loss:  1.7937795160357328\n",
      "================================\n",
      "learn_multisplits(): initial loss:    10668.781302821339\n",
      "learn_multisplits(): returning loss:  33.28650465284083\n",
      "================================\n",
      "learn_multisplits(): initial loss:    8956.235177743145\n",
      "learn_multisplits(): returning loss:  79.5667793750763\n",
      "================================\n",
      "learn_multisplits(): initial loss:    13295.388439636232\n",
      "learn_multisplits(): returning loss:  39.20593659076055\n",
      "================================\n",
      "learn_multisplits(): initial loss:    1467.5657910710383\n",
      "learn_multisplits(): returning loss:  14.004342561587691\n",
      "================================\n",
      "learn_multisplits(): initial loss:    4248.920338159725\n",
      "learn_multisplits(): returning loss:  25.705534130334854\n",
      "================================\n",
      "learn_multisplits(): initial loss:    5341.460269312855\n",
      "learn_multisplits(): returning loss:  55.358227372169495\n",
      "================================\n",
      "learn_multisplits(): initial loss:    400.8997851863084\n",
      "learn_multisplits(): returning loss:  1.4534518516413564\n",
      "================================\n",
      "learn_multisplits(): initial loss:    8283.20386120677\n",
      "learn_multisplits(): returning loss:  37.20882172882557\n",
      "================================\n",
      "learn_multisplits(): initial loss:    5606.759095334709\n",
      "learn_multisplits(): returning loss:  38.157354928553104\n",
      "================================\n",
      "learn_multisplits(): initial loss:    5603.029456270931\n",
      "learn_multisplits(): returning loss:  31.014120295643806\n",
      "================================\n",
      "learn_multisplits(): initial loss:    2263.0587249323726\n",
      "learn_multisplits(): returning loss:  11.68085017427802\n",
      "================================\n",
      "learn_multisplits(): initial loss:    24284.463103264578\n",
      "learn_multisplits(): returning loss:  140.33485765079968\n",
      "================================\n",
      "learn_multisplits(): initial loss:    6998.96237682037\n",
      "learn_multisplits(): returning loss:  38.13874616473913\n",
      "================================\n",
      "learn_multisplits(): initial loss:    28971.082581477138\n",
      "learn_multisplits(): returning loss:  154.21818716824055\n",
      "================================\n",
      "learn_multisplits(): initial loss:    6212.415158604384\n",
      "learn_multisplits(): returning loss:  34.552489378489554\n",
      "================================\n",
      "learn_multisplits(): initial loss:    6094.042783921286\n",
      "learn_multisplits(): returning loss:  32.402635369449854\n",
      "================================\n",
      "learn_multisplits(): initial loss:    3320.9891803402406\n",
      "learn_multisplits(): returning loss:  17.88849806843854\n",
      "================================\n",
      "learn_multisplits(): initial loss:    952.6782836698741\n",
      "learn_multisplits(): returning loss:  3.93551372820273\n",
      "================================\n",
      "learn_multisplits(): initial loss:    7938.536495738026\n",
      "learn_multisplits(): returning loss:  42.38001108914614\n",
      "================================\n",
      "learn_multisplits(): initial loss:    2418.53995411843\n",
      "learn_multisplits(): returning loss:  12.07312500260931\n",
      "================================\n",
      "learn_multisplits(): initial loss:    20049.372480578422\n",
      "learn_multisplits(): returning loss:  77.59947038081843\n",
      "================================\n",
      "learn_multisplits(): initial loss:    21703.986536593446\n",
      "learn_multisplits(): returning loss:  111.7594480868429\n",
      "================================\n",
      "learn_multisplits(): initial loss:    4114.4086297875465\n",
      "learn_multisplits(): returning loss:  17.03826342271378\n",
      "================================\n",
      "learn_multisplits(): initial loss:    1963.714136504829\n",
      "learn_multisplits(): returning loss:  10.344875090641064\n",
      "================================\n",
      "learn_multisplits(): initial loss:    22294.336453990945\n",
      "learn_multisplits(): returning loss:  119.50956609845161\n",
      "================================\n",
      "learn_multisplits(): initial loss:    10565.13979653947\n",
      "learn_multisplits(): returning loss:  53.07669676840305\n",
      "================================\n",
      "learn_multisplits(): initial loss:    19551.361713867183\n",
      "learn_multisplits(): returning loss:  88.3164397329092\n",
      "================================\n",
      "learn_multisplits(): initial loss:    2458.8328320094897\n",
      "learn_multisplits(): returning loss:  11.848341084918678\n",
      "================================\n",
      "learn_multisplits(): initial loss:    2270.654002603814\n",
      "learn_multisplits(): returning loss:  11.46451080031693\n",
      "================================\n",
      "learn_multisplits(): initial loss:    3988.169707014486\n",
      "learn_multisplits(): returning loss:  14.431488802182155\n",
      "================================\n",
      "learn_multisplits(): initial loss:    6115.120281077456\n",
      "learn_multisplits(): returning loss:  28.043349599346318\n",
      "================================\n",
      "learn_multisplits(): initial loss:    1956.8791038971383\n",
      "learn_multisplits(): returning loss:  21.43429324030876\n",
      "================================\n",
      "learn_multisplits(): initial loss:    5568.324774911926\n",
      "learn_multisplits(): returning loss:  29.234215804375708\n",
      "================================\n",
      "learn_multisplits(): initial loss:    5783.311366483156\n",
      "learn_multisplits(): returning loss:  16.083784914429717\n",
      "================================\n",
      "learn_multisplits(): initial loss:    4880.295829920097\n",
      "learn_multisplits(): returning loss:  21.353374430909753\n",
      "================================\n",
      "learn_multisplits(): initial loss:    3815.014328369797\n",
      "learn_multisplits(): returning loss:  22.13256809860468\n",
      "================================\n",
      "learn_multisplits(): initial loss:    4854.349938726126\n",
      "learn_multisplits(): returning loss:  19.790644363600038\n",
      "================================\n",
      "learn_multisplits(): initial loss:    5118.059283671081\n",
      "learn_multisplits(): returning loss:  24.017203472554684\n",
      "================================\n",
      "learn_multisplits(): initial loss:    6085.659608578607\n",
      "learn_multisplits(): returning loss:  40.14671199768782\n",
      "================================\n",
      "learn_multisplits(): initial loss:    4293.43679819934\n",
      "learn_multisplits(): returning loss:  18.17748933308758\n",
      "================================\n",
      "learn_multisplits(): initial loss:    4181.36880985789\n",
      "learn_multisplits(): returning loss:  25.6106509976089\n",
      "================================\n",
      "learn_multisplits(): initial loss:    16.955514469892464\n",
      "learn_multisplits(): returning loss:  0.030371372659600222\n",
      "================================\n",
      "learn_multisplits(): initial loss:    3391.131666687056\n",
      "learn_multisplits(): returning loss:  22.256976038217545\n",
      "================================\n",
      "learn_multisplits(): initial loss:    26635.092206763034\n",
      "learn_multisplits(): returning loss:  213.69233351619914\n",
      "================================\n",
      "learn_multisplits(): initial loss:    1494.4633813737148\n",
      "learn_multisplits(): returning loss:  5.943160288843058\n",
      "================================\n",
      "learn_multisplits(): initial loss:    285918.1635622978\n",
      "learn_multisplits(): returning loss:  119.29590272903442\n",
      "================================\n",
      "learn_multisplits(): initial loss:    842.8280269996903\n",
      "learn_multisplits(): returning loss:  3.336042612686324\n",
      "================================\n",
      "learn_multisplits(): initial loss:    5132.63934212178\n",
      "learn_multisplits(): returning loss:  41.87378600239754\n",
      "================================\n",
      "learn_multisplits(): initial loss:    4623.168838156464\n",
      "learn_multisplits(): returning loss:  22.38004524121061\n",
      "================================\n",
      "learn_multisplits(): initial loss:    23007.07295078155\n",
      "learn_multisplits(): returning loss:  172.58653654437512\n",
      "================================\n",
      "learn_multisplits(): initial loss:    156.71960393212436\n",
      "learn_multisplits(): returning loss:  1.1017851113832242\n",
      "================================\n",
      "learn_multisplits(): initial loss:    12358.50927363865\n",
      "learn_multisplits(): returning loss:  68.29285478591919\n",
      "================================\n",
      "learn_multisplits(): initial loss:    3013.212148162647\n",
      "learn_multisplits(): returning loss:  23.504678428173065\n",
      "================================\n",
      "learn_multisplits(): initial loss:    9498.461526414676\n",
      "learn_multisplits(): returning loss:  42.28299717605114\n",
      "================================\n",
      "learn_multisplits(): initial loss:    7002.148468899423\n",
      "learn_multisplits(): returning loss:  68.70915186498314\n",
      "================================\n",
      "learn_multisplits(): initial loss:    14853.891567934761\n",
      "learn_multisplits(): returning loss:  194.86155899986625\n",
      "================================\n",
      "learn_multisplits(): initial loss:    6810.729176324531\n",
      "learn_multisplits(): returning loss:  17.41640695757949\n",
      "================================\n",
      "learn_multisplits(): initial loss:    1686.5746016298936\n",
      "learn_multisplits(): returning loss:  8.001420335908303\n",
      "================================\n",
      "learn_multisplits(): initial loss:    5616.660777468681\n",
      "learn_multisplits(): returning loss:  62.812325918115675\n",
      "================================\n",
      "learn_multisplits(): initial loss:    11388.106285094022\n",
      "learn_multisplits(): returning loss:  64.55450941249728\n",
      "================================\n",
      "learn_multisplits(): initial loss:    113.15658428211388\n",
      "learn_multisplits(): returning loss:  0.41029517079426886\n",
      "================================\n",
      "learn_multisplits(): initial loss:    1289.3976865924708\n",
      "learn_multisplits(): returning loss:  4.808909587737526\n",
      "================================\n",
      "learn_multisplits(): initial loss:    8025.368798863216\n",
      "learn_multisplits(): returning loss:  38.51726921647787\n",
      "================================\n",
      "learn_multisplits(): initial loss:    6580.731295761765\n",
      "learn_multisplits(): returning loss:  37.751378430984914\n",
      "================================\n",
      "learn_multisplits(): initial loss:    1333.3816762863844\n",
      "learn_multisplits(): returning loss:  10.76361947217097\n",
      "================================\n",
      "learn_multisplits(): initial loss:    894.6994527491916\n",
      "learn_multisplits(): returning loss:  3.460442155438181\n",
      "================================\n",
      "learn_multisplits(): initial loss:    26143.16766872289\n",
      "learn_multisplits(): returning loss:  141.9425529788714\n",
      "X_res mse / X mse:  0.0010430557\n",
      "fitting dense lstsq to X_res\n",
      "  with X_enc:(204800, 128) Y:(204800, 128)\n",
      "fitted dense lstsq with W:(2048, 128)\n",
      "X_res mse / X mse after lstsq:  0.000823202\n"
     ]
    }
   ],
   "source": [
    "est3 = mm.estFactory(X_path=data_to_fcpath_train, W_path=weightpath, Y_path=y_train, dir= dir_train, ncodebooks=ncodebooks, ncentroids=ncentroids, methods=[method])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(est3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.load(dir_test+'/'+data_to_fcpath_test)\n",
    "w_test = np.load(dir_train+'/'+weightpath)\n",
    "bias = np.load(dir_train+'/'+biaspath)\n",
    "# print(type(est3))\n",
    "y_out_matmul = mm.eval_matmul(est3, x_test, w_test) # MADDNESS乘法的结果\n",
    "# y_out_last = mu.softmax(y_out_matmul + bias.T) # MADDNESS替换后当前层输出，即+bias并激活函数后的结果\n",
    "y_out_last = y_out_matmul + bias.T # MADDNESS替换后当前层输出，即+bias并不需要激活函数后的结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-2.8218367  -0.9621016  -0.8115635  ... -0.73980373  1.0360615\n",
      "  -0.6223679 ]\n",
      " [-2.8218367   1.0418123  -0.8115635  ... -2.7437177   1.0360615\n",
      "   1.381546  ]\n",
      " [-0.8179226  -2.9660156   1.1923504  ... -0.73980373 -2.9717665\n",
      "   3.38546   ]\n",
      " ...\n",
      " [-2.8218367  -0.9621016  -0.8115635  ... -2.7437177   3.0399754\n",
      "   1.381546  ]\n",
      " [-2.8218367  -0.9621016   1.1923504  ... -2.7437177   1.0360615\n",
      "   1.381546  ]\n",
      " [-2.8218367  -0.9621016  -0.8115635  ... -2.7437177   1.0360615\n",
      "   1.381546  ]]\n",
      "y_out_last.shape:  (1024000, 64)\n",
      "y_out_last_re.shape:  (1000, 32, 32, 64)\n"
     ]
    }
   ],
   "source": [
    "print(y_out_last)\n",
    "print(\"y_out_last.shape: \", y_out_last.shape)\n",
    "y_out_last_re = y_out_last.reshape(test_sam_num, batch_size, -1, y_out_last.shape[-1]) #AMM字典模式需要复原y大小\n",
    "print(\"y_out_last_re.shape: \", y_out_last_re.shape)\n",
    "# np.save(\"LDPC_decoder_NET_testdata/\" + snr + \"nomul_matmul_yout_matmul\", y_out_matmul)\n",
    "# np.save(dir_result+'/'+method+'fc1_fb256_cb%i_ct%i.npy' % (ncodebooks, ncentroids), y_out_matmul)\n",
    "np.save(os.path.join(dir_result, '%s%s_trsam%i_tesam%i_fb%i_cb%i_ct%i.npy' % (method, linear_name, train_sam_num, test_sam_num, feedback_bits, ncodebooks, ncentroids)), y_out_last_re)\n",
    "# io.savemat(dir_result+'\\\\fc1_256.mat', {\"NN_output_buffer\": y_out_last})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('pqhdr')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ec04f7dc2b3ae4a422de9aaf96e8c62fe190a2869a08d14112cb2d7713497448"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
