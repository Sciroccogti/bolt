{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "encoder transformer层的linear1层（etl1）替换为近似矩阵乘法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matmul as mm\n",
    "import math_util as mu\n",
    "from NNutils import *\n",
    "import scipy.io as io\n",
    "from amm_methods import *\n",
    "import socket # Obtain the current host name, which can be used to select different data directories and result saving directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = METHOD_MITHRAL\n",
    "# method = METHOD_PQ\n",
    "# method = METHOD_EXACT\n",
    "# method = METHOD_SCALAR_QUANTIZE\n",
    "nbits = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_name = \"etl1\"\n",
    "linear_name_full = \"ex_linear1\"\n",
    "feedback_bits = 256\n",
    "ncodebooks = 64 # max:64\n",
    "ncentroids = 128\n",
    "# if method == METHOD_MITHRAL:\n",
    "#     ncentroids = 16\n",
    "train_sam_num = 125 # 训练集样本数\n",
    "test_sam_num = 1000 # 测试集样本数\n",
    "batch_size = 32\n",
    "if method == METHOD_EXACT:\n",
    "    ncodebooks = 0\n",
    "    ncentroids = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "host_name = socket.gethostname()\n",
    "if host_name == 'DESKTOP-PLRL7TK':\n",
    "    dir_train = 'E:\\\\hdr\\\\研一\\\\华为-深度学习\\\\intermediate\\\\intermediate8dbfc1'\n",
    "    dir_result = ''\n",
    "elif host_name == 'DESKTOP-6FOH47P':\n",
    "    dir_train = 'F:\\\\Projects\\\\python\\\\PQ\\\\intermediate8dbfc1'\n",
    "    dir_result = 'F:\\\\Projects\\\\python\\\\PQ\\\\res'\n",
    "    linearin_path_train= ''\n",
    "    linearout_path_train= ''\n",
    "    linearin_path_test = ''\n",
    "    linearout_path_test = ''\n",
    "elif host_name == 'jm-System-Product-Name':\n",
    "    dir_joined = '/data/hdr/transformer_data/joined'\n",
    "    dir_train = os.path.join(dir_joined, 'train', 'f'+str(feedback_bits))\n",
    "    dir_test = os.path.join(dir_joined, 'test', 'f'+str(feedback_bits))\n",
    "    dir_result = '/data/hdr/pq/res'\n",
    "    linearin_path_train= 'ex_linear1in_train_f%i_sam%i.npy' % (feedback_bits, train_sam_num)\n",
    "    y_train = 'ex_linear1_y_train_f%i_sam%i.npy' % (feedback_bits, train_sam_num)\n",
    "    linearout_path_train= 'ex_linear1out_train_f%i_sam%i.npy' % (feedback_bits, train_sam_num)\n",
    "    linearin_path_test = 'ex_linear1in_test_f%i_sam%i.npy' % (feedback_bits, test_sam_num)\n",
    "    linearout_path_test = 'ex_linear1out_test_f%i_sam%i.npy' % (feedback_bits, test_sam_num)\n",
    "else:\n",
    "    raise NameError(\"You are running the script in a new computer %s, please define dirs\" % host_name)\n",
    "\n",
    "\n",
    "weightpath = 'ex_linear1_w_f256.npy'\n",
    "biaspath = 'ex_linear1_b_f256.npy'\n",
    "dir_result = os.path.join(dir_result, method, \"f%i\" % feedback_bits, linear_name)\n",
    "try:\n",
    "    os.mkdir(dir_result)\n",
    "except FileNotFoundError:\n",
    "    os.makedirs(dir_result)\n",
    "except FileExistsError:\n",
    "    pass \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_prepare(dir_joined, linear_name_full, feedback_bits, [train_sam_num, test_sam_num], batch_size, S1 = S1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "running method:  Mithral\n",
      "_learn_mithral_initialization heuristic pq\n",
      "================================\n",
      "learn_multisplits(): initial loss:    1065.870246439427\n",
      "learn_multisplits(): returning loss:  0.2679029136779718\n",
      "================================\n",
      "learn_multisplits(): initial loss:    651.5780927184801\n",
      "learn_multisplits(): returning loss:  0.1894425149075687\n",
      "================================\n",
      "learn_multisplits(): initial loss:    649.2333590561892\n",
      "learn_multisplits(): returning loss:  0.16227918659569696\n",
      "================================\n",
      "learn_multisplits(): initial loss:    936.8366025805473\n",
      "learn_multisplits(): returning loss:  0.2119341142824851\n",
      "================================\n",
      "learn_multisplits(): initial loss:    959.7519711827034\n",
      "learn_multisplits(): returning loss:  0.2610050281509757\n",
      "================================\n",
      "learn_multisplits(): initial loss:    712.6405246181769\n",
      "learn_multisplits(): returning loss:  0.32374924002215266\n",
      "================================\n",
      "learn_multisplits(): initial loss:    1245.1493607120306\n",
      "learn_multisplits(): returning loss:  0.5568850063718855\n",
      "================================\n",
      "learn_multisplits(): initial loss:    2115.3592320266293\n",
      "learn_multisplits(): returning loss:  1.427807778120041\n",
      "================================\n",
      "learn_multisplits(): initial loss:    3097.3349869796402\n",
      "learn_multisplits(): returning loss:  1.5636643897742033\n",
      "================================\n",
      "learn_multisplits(): initial loss:    4842.745624022931\n",
      "learn_multisplits(): returning loss:  1.931125110015273\n",
      "================================\n",
      "learn_multisplits(): initial loss:    4859.415546227089\n",
      "learn_multisplits(): returning loss:  1.6318919621407986\n",
      "================================\n",
      "learn_multisplits(): initial loss:    5026.513405540956\n",
      "learn_multisplits(): returning loss:  1.5084499567747116\n",
      "================================\n",
      "learn_multisplits(): initial loss:    5313.520892236864\n",
      "learn_multisplits(): returning loss:  1.5009172046557069\n",
      "================================\n",
      "learn_multisplits(): initial loss:    5549.960691568933\n",
      "learn_multisplits(): returning loss:  1.4855628674849868\n",
      "================================\n",
      "learn_multisplits(): initial loss:    5047.9166605003\n",
      "learn_multisplits(): returning loss:  1.3722220985218883\n",
      "================================\n",
      "learn_multisplits(): initial loss:    4131.094898756473\n",
      "learn_multisplits(): returning loss:  1.1626855933573097\n",
      "================================\n",
      "learn_multisplits(): initial loss:    1943.5008713833986\n",
      "learn_multisplits(): returning loss:  0.5409988302271813\n",
      "================================\n",
      "learn_multisplits(): initial loss:    1857.3849099814815\n",
      "learn_multisplits(): returning loss:  0.6103957444429398\n",
      "================================\n",
      "learn_multisplits(): initial loss:    1455.0763871567528\n",
      "learn_multisplits(): returning loss:  0.5302771495189518\n",
      "================================\n",
      "learn_multisplits(): initial loss:    818.1672235562652\n",
      "learn_multisplits(): returning loss:  0.29823281907010823\n",
      "================================\n",
      "learn_multisplits(): initial loss:    655.1017180907131\n",
      "learn_multisplits(): returning loss:  0.21855168306501582\n",
      "================================\n",
      "learn_multisplits(): initial loss:    642.0956049899565\n",
      "learn_multisplits(): returning loss:  0.19705892610363662\n",
      "================================\n",
      "learn_multisplits(): initial loss:    541.4362331252405\n",
      "learn_multisplits(): returning loss:  0.17032596928765997\n",
      "================================\n",
      "learn_multisplits(): initial loss:    614.4670374325495\n",
      "learn_multisplits(): returning loss:  0.16479688385152258\n",
      "================================\n",
      "learn_multisplits(): initial loss:    393.55484484940024\n",
      "learn_multisplits(): returning loss:  0.132761462504277\n",
      "================================\n",
      "learn_multisplits(): initial loss:    446.08803309965464\n",
      "learn_multisplits(): returning loss:  0.15486866992432624\n",
      "================================\n",
      "learn_multisplits(): initial loss:    419.30097958134354\n",
      "learn_multisplits(): returning loss:  0.14645709548494779\n",
      "================================\n",
      "learn_multisplits(): initial loss:    376.2939115458065\n",
      "learn_multisplits(): returning loss:  0.1172583329025656\n",
      "================================\n",
      "learn_multisplits(): initial loss:    573.5411883532399\n",
      "learn_multisplits(): returning loss:  0.16712847113376483\n",
      "================================\n",
      "learn_multisplits(): initial loss:    422.6718562095891\n",
      "learn_multisplits(): returning loss:  0.12678664944542106\n",
      "================================\n",
      "learn_multisplits(): initial loss:    406.41277798884363\n",
      "learn_multisplits(): returning loss:  0.13282180865644477\n",
      "================================\n",
      "learn_multisplits(): initial loss:    544.323289773665\n",
      "learn_multisplits(): returning loss:  0.15355487307533622\n",
      "================================\n",
      "learn_multisplits(): initial loss:    746.1657301206026\n",
      "learn_multisplits(): returning loss:  0.19163210553233512\n",
      "================================\n",
      "learn_multisplits(): initial loss:    659.445898676843\n",
      "learn_multisplits(): returning loss:  0.10983543581096455\n",
      "================================\n",
      "learn_multisplits(): initial loss:    1111.8739982889886\n",
      "learn_multisplits(): returning loss:  0.17826202849391848\n",
      "================================\n",
      "learn_multisplits(): initial loss:    747.4271227245334\n",
      "learn_multisplits(): returning loss:  0.20084408091497608\n",
      "================================\n",
      "learn_multisplits(): initial loss:    676.3298984467739\n",
      "learn_multisplits(): returning loss:  0.24973397786379792\n",
      "================================\n",
      "learn_multisplits(): initial loss:    520.3554074452536\n",
      "learn_multisplits(): returning loss:  0.23067319014808163\n",
      "================================\n",
      "learn_multisplits(): initial loss:    764.0460507799954\n",
      "learn_multisplits(): returning loss:  0.33191946521401405\n",
      "================================\n",
      "learn_multisplits(): initial loss:    1166.115181980679\n",
      "learn_multisplits(): returning loss:  0.9367686295881867\n",
      "================================\n",
      "learn_multisplits(): initial loss:    2038.3352792453002\n",
      "learn_multisplits(): returning loss:  1.1836994104087353\n",
      "================================\n",
      "learn_multisplits(): initial loss:    2722.7687705010007\n",
      "learn_multisplits(): returning loss:  1.2416954273357987\n",
      "================================\n",
      "learn_multisplits(): initial loss:    3353.6368846872406\n",
      "learn_multisplits(): returning loss:  1.2898162538185716\n",
      "================================\n",
      "learn_multisplits(): initial loss:    3435.168564679913\n",
      "learn_multisplits(): returning loss:  1.1396680837497115\n",
      "================================\n",
      "learn_multisplits(): initial loss:    4132.015997082873\n",
      "learn_multisplits(): returning loss:  1.2664674585685134\n",
      "================================\n",
      "learn_multisplits(): initial loss:    5437.784099563353\n",
      "learn_multisplits(): returning loss:  1.556476527824998\n",
      "================================\n",
      "learn_multisplits(): initial loss:    6216.758629119047\n",
      "learn_multisplits(): returning loss:  1.8486980572342873\n",
      "================================\n",
      "learn_multisplits(): initial loss:    5093.727623147319\n",
      "learn_multisplits(): returning loss:  1.7279286179691553\n",
      "================================\n",
      "learn_multisplits(): initial loss:    3708.81777757808\n",
      "learn_multisplits(): returning loss:  1.4615322733297944\n",
      "================================\n",
      "learn_multisplits(): initial loss:    2510.3364729019327\n",
      "learn_multisplits(): returning loss:  1.065444327890873\n",
      "================================\n",
      "learn_multisplits(): initial loss:    1697.710612878899\n",
      "learn_multisplits(): returning loss:  0.7284005405381322\n",
      "================================\n",
      "learn_multisplits(): initial loss:    1484.1626936244668\n",
      "learn_multisplits(): returning loss:  0.5665645238477737\n",
      "================================\n",
      "learn_multisplits(): initial loss:    2168.603909223554\n",
      "learn_multisplits(): returning loss:  0.6864311048993841\n",
      "================================\n",
      "learn_multisplits(): initial loss:    4695.79046058464\n",
      "learn_multisplits(): returning loss:  1.1170982904732227\n",
      "================================\n",
      "learn_multisplits(): initial loss:    7820.043567350396\n",
      "learn_multisplits(): returning loss:  1.4566983245313168\n",
      "================================\n",
      "learn_multisplits(): initial loss:    8235.929406690588\n",
      "learn_multisplits(): returning loss:  1.468326149508357\n",
      "================================\n",
      "learn_multisplits(): initial loss:    5525.600638213639\n",
      "learn_multisplits(): returning loss:  1.0490226745605469\n",
      "================================\n",
      "learn_multisplits(): initial loss:    1668.7864889286743\n",
      "learn_multisplits(): returning loss:  0.32396383909508586\n",
      "================================\n",
      "learn_multisplits(): initial loss:    428.18844931632236\n",
      "learn_multisplits(): returning loss:  0.15198758910992183\n",
      "================================\n",
      "learn_multisplits(): initial loss:    1928.5179175395974\n",
      "learn_multisplits(): returning loss:  0.49281394202262163\n",
      "================================\n",
      "learn_multisplits(): initial loss:    3498.710882566449\n",
      "learn_multisplits(): returning loss:  0.6352879069745541\n",
      "================================\n",
      "learn_multisplits(): initial loss:    1698.2187028333851\n",
      "learn_multisplits(): returning loss:  0.4052103173453361\n",
      "================================\n",
      "learn_multisplits(): initial loss:    497.6660228895844\n",
      "learn_multisplits(): returning loss:  0.16011151671409607\n",
      "================================\n",
      "learn_multisplits(): initial loss:    484.4126622714038\n",
      "learn_multisplits(): returning loss:  0.1877199065638706\n",
      "X_res mse / X mse:  9.370479e-05\n",
      "fitting dense lstsq to X_res\n",
      "  with X_enc:(128000, 64) Y:(128000, 64)\n",
      "fitted dense lstsq with W:(8192, 64)\n",
      "X_res mse / X mse after lstsq:  0.00025204883\n"
     ]
    }
   ],
   "source": [
    "est3 = mm.estFactory(X_path=linearin_path_train, W_path=weightpath, Y_path=y_train, dir= dir_train, ncodebooks=ncodebooks, ncentroids=ncentroids, methods=[method], nbits=nbits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.load(dir_test+'/'+linearin_path_test)\n",
    "w_test = np.load(dir_train+'/'+weightpath)\n",
    "bias = np.load(dir_train+'/'+biaspath)\n",
    "# print(type(est3))\n",
    "y_out_matmul = mm.eval_matmul(est3, x_test, w_test) # MADDNESS乘法的结果\n",
    "# y_out_last = mu.softmax(y_out_matmul + bias.T) # MADDNESS替换后当前层输出，即+bias并激活函数后的结果\n",
    "y_out_last = y_out_matmul + bias.T # MADDNESS替换后当前层输出，即+bias并不需要激活函数后的结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.48835498 -0.25156578 -0.47112092 ... -0.24716164  1.256324\n",
      "  -0.17062312]\n",
      " [-0.36311036 -0.25156578 -0.22063169 ... -0.12191702  1.256324\n",
      "  -0.17062312]\n",
      " [-0.23786576 -0.3768104  -0.47112092 ... -0.37240624  1.256324\n",
      "  -0.29586774]\n",
      " ...\n",
      " [-0.11262114 -0.12632117 -0.47112092 ... -0.12191702  0.63010097\n",
      "  -0.17062312]\n",
      " [-0.36311036 -0.25156578 -0.47112092 ... -0.12191702  0.8805902\n",
      "  -0.42111236]\n",
      " [-0.11262114 -0.25156578 -0.09538707 ... -0.12191702  0.63010097\n",
      "  -0.17062312]]\n",
      "y_out_last.shape:  (1024000, 512)\n",
      "y_out_last_re.shape:  (1000, 32, 32, 512)\n"
     ]
    }
   ],
   "source": [
    "print(y_out_last)\n",
    "print(\"y_out_last.shape: \", y_out_last.shape)\n",
    "y_out_last_re = y_out_last.reshape(test_sam_num, batch_size, -1, y_out_last.shape[-1]) #AMM字典模式需要复原y大小\n",
    "print(\"y_out_last_re.shape: \", y_out_last_re.shape)\n",
    "if method == METHOD_EXACT:\n",
    "    train_sam_num = 0 # 训练集样本数\n",
    "if method == METHOD_SCALAR_QUANTIZE:\n",
    "    np.save(os.path.join(dir_result, '%s%s_trsam%i_tesam%i_fb%i_nbits%i.npy' % (method, linear_name, train_sam_num, test_sam_num, feedback_bits, nbits)), y_out_last_re.astype(np.float32))\n",
    "else:\n",
    "    np.save(os.path.join(dir_result, '%s%s_trsam%i_tesam%i_fb%i_cb%i_ct%i.npy' % (method, linear_name, train_sam_num, test_sam_num, feedback_bits, ncodebooks, ncentroids)), y_out_last_re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('pqhdr')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ec04f7dc2b3ae4a422de9aaf96e8c62fe190a2869a08d14112cb2d7713497448"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
