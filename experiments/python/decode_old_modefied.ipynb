{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matmul as mm\n",
    "import math_util as mu\n",
    "import scipy.io as io\n",
    "from amm_methods import *\n",
    "import socket # Obtain the current host name, which can be used to select different data directories and result saving directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirnow = os.getcwd()\n",
    "\n",
    "host_name = socket.gethostname()\n",
    "if host_name == 'DESKTOP-6FOH47P':\n",
    "    _dir = 'F:\\\\Projects\\\\python\\\\PQ\\\\tutorialdjy\\\\bolt-master\\\\bolt-master\\\\experiments\\\\python'\n",
    "    traindir = 'F:\\\\Projects\\\\python\\PQ\\\\tutorialdjy\\\\bolt-master\\\\bolt-master\\\\experiments\\\\assets\\\\ldpc\\\\'\n",
    "elif host_name == 'DESKTOP-PLRL7TK':\n",
    "    _dir = 'E:\\\\hdr\\\\研一\\\\华为-深度学习\\\\tutorialDJY\\\\bolt-master\\\\bolt-master\\\\experiments\\\\python'\n",
    "    traindir = 'E:\\\\hdr\\\\研一\\\\华为-深度学习\\\\tutorialDJY\\\\bolt-master\\\\bolt-master\\\\experiments\\\\assets\\\\ldpc\\\\'\n",
    "elif host_name == 'jm-System-Product-Name':\n",
    "    _dir = ''\n",
    "    traindir = ''\n",
    "else:\n",
    "    raise NameError(\"You are running the script in a new computer, please define _dir\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "snrs_ = [\"8db/\", \"8.5db/\", \"9db/\", \"9.5db/\", \"10db/\", \"10.5db/\", \"11db/\"] #, \"12db/\", \"14db/\"]\n",
    "\n",
    "method = METHOD_MITHRAL\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8db/\n",
      "F:\\Projects\\python\\PQ\\tutorialdjy\\bolt-master\\bolt-master\\experiments\\python\n",
      "==============================\n",
      "running method:  Mithral\n",
      "================================\n",
      "learn_multisplits(): initial loss:    82423.9921875\n",
      "learn_multisplits(): returning loss:  281.50109738111496\n",
      "================================\n",
      "learn_multisplits(): initial loss:    144615.84375\n",
      "learn_multisplits(): returning loss:  1096.0723991394043\n",
      "================================\n",
      "learn_multisplits(): initial loss:    922638.4375\n",
      "learn_multisplits(): returning loss:  5705.015243530273\n",
      "================================\n",
      "learn_multisplits(): initial loss:    344851.0\n",
      "learn_multisplits(): returning loss:  1365.602243900299\n",
      "================================\n",
      "learn_multisplits(): initial loss:    507911.4375\n",
      "learn_multisplits(): returning loss:  2271.440305709839\n",
      "================================\n",
      "learn_multisplits(): initial loss:    0\n",
      "learn_multisplits(): returning loss:  0\n",
      "================================\n",
      "learn_multisplits(): initial loss:    908700.375\n",
      "learn_multisplits(): returning loss:  3875.839635848999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Projects\\python\\bolt\\experiments\\python\\clusterize.py:764: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  scale = 254. / upper_val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\n",
      "learn_multisplits(): initial loss:    591155.0625\n",
      "learn_multisplits(): returning loss:  3540.801071166992\n",
      "================================\n",
      "learn_multisplits(): initial loss:    750819.25\n",
      "learn_multisplits(): returning loss:  3294.4543027877808\n",
      "================================\n",
      "learn_multisplits(): initial loss:    766829.3125\n",
      "learn_multisplits(): returning loss:  3234.2160501480103\n",
      "================================\n",
      "learn_multisplits(): initial loss:    522153.65625\n",
      "learn_multisplits(): returning loss:  2004.3577437400818\n",
      "================================\n",
      "learn_multisplits(): initial loss:    802439.6875\n",
      "learn_multisplits(): returning loss:  4593.384841918945\n",
      "================================\n",
      "learn_multisplits(): initial loss:    1115201.125\n",
      "learn_multisplits(): returning loss:  5070.0440311431885\n",
      "================================\n",
      "learn_multisplits(): initial loss:    964600.5625\n",
      "learn_multisplits(): returning loss:  4089.691813468933\n",
      "================================\n",
      "learn_multisplits(): initial loss:    1222022.125\n",
      "learn_multisplits(): returning loss:  6500.264587402344\n",
      "================================\n",
      "learn_multisplits(): initial loss:    785300.0625\n",
      "learn_multisplits(): returning loss:  3302.8309421539307\n",
      "================================\n",
      "learn_multisplits(): initial loss:    483942.96875\n",
      "learn_multisplits(): returning loss:  1657.9687747955322\n",
      "================================\n",
      "learn_multisplits(): initial loss:    442805.09375\n",
      "learn_multisplits(): returning loss:  2238.8195037841797\n",
      "================================\n",
      "learn_multisplits(): initial loss:    197333.015625\n",
      "learn_multisplits(): returning loss:  700.1702567338943\n",
      "================================\n",
      "learn_multisplits(): initial loss:    247189.21875\n",
      "learn_multisplits(): returning loss:  1975.1584701538086\n",
      "================================\n",
      "learn_multisplits(): initial loss:    1212039.25\n",
      "learn_multisplits(): returning loss:  7095.656623840332\n",
      "================================\n",
      "learn_multisplits(): initial loss:    1226987.25\n",
      "learn_multisplits(): returning loss:  5844.096870422363\n",
      "================================\n",
      "learn_multisplits(): initial loss:    774161.875\n",
      "learn_multisplits(): returning loss:  2989.3607997894287\n",
      "================================\n",
      "learn_multisplits(): initial loss:    595695.0625\n",
      "learn_multisplits(): returning loss:  3227.5001525878906\n",
      "================================\n",
      "learn_multisplits(): initial loss:    747319.9375\n",
      "learn_multisplits(): returning loss:  4567.895568847656\n",
      "================================\n",
      "learn_multisplits(): initial loss:    507898.625\n",
      "learn_multisplits(): returning loss:  2317.313097000122\n",
      "================================\n",
      "learn_multisplits(): initial loss:    356089.90625\n",
      "learn_multisplits(): returning loss:  1349.0132541656494\n",
      "================================\n",
      "learn_multisplits(): initial loss:    525550.0\n",
      "learn_multisplits(): returning loss:  2053.491707801819\n",
      "X_res mse / X mse:  0.0017576164\n",
      "fitting dense lstsq to X_res\n",
      "X_res mse / X mse after lstsq:  0.0008402875\n",
      "8.5db/\n",
      "F:\\Projects\\python\\PQ\\tutorialdjy\\bolt-master\\bolt-master\\experiments\\python\n",
      "==============================\n",
      "running method:  Mithral\n",
      "================================\n",
      "learn_multisplits(): initial loss:    80588.9296875\n",
      "learn_multisplits(): returning loss:  271.42341274023056\n",
      "================================\n",
      "learn_multisplits(): initial loss:    141708.078125\n",
      "learn_multisplits(): returning loss:  1059.6019439697266\n",
      "================================\n",
      "learn_multisplits(): initial loss:    898825.5\n",
      "learn_multisplits(): returning loss:  5473.720260620117\n",
      "================================\n",
      "learn_multisplits(): initial loss:    334132.21875\n",
      "learn_multisplits(): returning loss:  1337.1933093070984\n",
      "================================\n",
      "learn_multisplits(): initial loss:    498307.3125\n",
      "learn_multisplits(): returning loss:  2123.642746925354\n",
      "================================\n",
      "learn_multisplits(): initial loss:    893823.9375\n",
      "learn_multisplits(): returning loss:  3584.104070663452\n",
      "================================\n",
      "learn_multisplits(): initial loss:    580167.4375\n",
      "learn_multisplits(): returning loss:  3436.246124267578\n",
      "================================\n",
      "learn_multisplits(): initial loss:    739212.8125\n",
      "learn_multisplits(): returning loss:  3161.5584506988525\n",
      "================================\n",
      "learn_multisplits(): initial loss:    755370.1875\n",
      "learn_multisplits(): returning loss:  3120.911725997925\n",
      "================================\n",
      "learn_multisplits(): initial loss:    513170.9375\n",
      "learn_multisplits(): returning loss:  1973.6519346237183\n",
      "================================\n",
      "learn_multisplits(): initial loss:    782127.375\n",
      "learn_multisplits(): returning loss:  4440.367385864258\n",
      "================================\n",
      "learn_multisplits(): initial loss:    1091855.625\n",
      "learn_multisplits(): returning loss:  4900.855812072754\n",
      "================================\n",
      "learn_multisplits(): initial loss:    944527.9375\n",
      "learn_multisplits(): returning loss:  3932.991720199585\n",
      "================================\n",
      "learn_multisplits(): initial loss:    1204599.75\n",
      "learn_multisplits(): returning loss:  6182.642303466797\n",
      "================================\n",
      "learn_multisplits(): initial loss:    765657.75\n",
      "learn_multisplits(): returning loss:  3162.088152885437\n",
      "================================\n",
      "learn_multisplits(): initial loss:    473878.34375\n",
      "learn_multisplits(): returning loss:  1626.3571009635925\n",
      "================================\n",
      "learn_multisplits(): initial loss:    431662.875\n",
      "learn_multisplits(): returning loss:  2160.934471130371\n",
      "================================\n",
      "learn_multisplits(): initial loss:    193960.875\n",
      "learn_multisplits(): returning loss:  673.4635217189789\n",
      "================================\n",
      "learn_multisplits(): initial loss:    243600.78125\n",
      "learn_multisplits(): returning loss:  1918.4600105285645\n",
      "================================\n",
      "learn_multisplits(): initial loss:    1185284.125\n",
      "learn_multisplits(): returning loss:  6747.043014526367\n",
      "================================\n",
      "learn_multisplits(): initial loss:    1198924.375\n",
      "learn_multisplits(): returning loss:  5621.574806213379\n",
      "================================\n",
      "learn_multisplits(): initial loss:    757734.4375\n",
      "learn_multisplits(): returning loss:  2913.5104360580444\n",
      "================================\n",
      "learn_multisplits(): initial loss:    580208.6875\n",
      "learn_multisplits(): returning loss:  3199.4721450805664\n",
      "================================\n",
      "learn_multisplits(): initial loss:    726834.8125\n",
      "learn_multisplits(): returning loss:  4459.741149902344\n",
      "================================\n",
      "learn_multisplits(): initial loss:    497636.0\n",
      "learn_multisplits(): returning loss:  2293.638313293457\n",
      "================================\n",
      "learn_multisplits(): initial loss:    348281.0\n",
      "learn_multisplits(): returning loss:  1286.273768901825\n",
      "================================\n",
      "learn_multisplits(): initial loss:    515139.125\n",
      "learn_multisplits(): returning loss:  1952.8901135921478\n",
      "X_res mse / X mse:  0.0017346505\n",
      "fitting dense lstsq to X_res\n",
      "X_res mse / X mse after lstsq:  0.00083826337\n",
      "9db/\n",
      "F:\\Projects\\python\\PQ\\tutorialdjy\\bolt-master\\bolt-master\\experiments\\python\n",
      "==============================\n",
      "running method:  Mithral\n",
      "================================\n",
      "learn_multisplits(): initial loss:    80394.328125\n",
      "learn_multisplits(): returning loss:  271.7809472680092\n",
      "================================\n",
      "learn_multisplits(): initial loss:    138855.765625\n",
      "learn_multisplits(): returning loss:  1027.900520324707\n",
      "================================\n",
      "learn_multisplits(): initial loss:    885479.5\n",
      "learn_multisplits(): returning loss:  5375.522109985352\n",
      "================================\n",
      "learn_multisplits(): initial loss:    330450.59375\n",
      "learn_multisplits(): returning loss:  1321.2664413452148\n",
      "================================\n",
      "learn_multisplits(): initial loss:    490388.46875\n",
      "learn_multisplits(): returning loss:  2071.3817443847656\n",
      "================================\n",
      "learn_multisplits(): initial loss:    869600.625\n",
      "learn_multisplits(): returning loss:  3548.8153009414673\n",
      "================================\n",
      "learn_multisplits(): initial loss:    572993.4375\n",
      "learn_multisplits(): returning loss:  3351.0658264160156\n",
      "================================\n",
      "learn_multisplits(): initial loss:    713855.25\n",
      "learn_multisplits(): returning loss:  3058.09072971344\n",
      "================================\n",
      "learn_multisplits(): initial loss:    736650.625\n",
      "learn_multisplits(): returning loss:  2987.389183998108\n",
      "================================\n",
      "learn_multisplits(): initial loss:    498983.25\n",
      "learn_multisplits(): returning loss:  1920.2095561027527\n",
      "================================\n",
      "learn_multisplits(): initial loss:    771916.375\n",
      "learn_multisplits(): returning loss:  4415.518142700195\n",
      "================================\n",
      "learn_multisplits(): initial loss:    1069978.5\n",
      "learn_multisplits(): returning loss:  4784.92391204834\n",
      "================================\n",
      "learn_multisplits(): initial loss:    926471.9375\n",
      "learn_multisplits(): returning loss:  3811.5876092910767\n",
      "================================\n",
      "learn_multisplits(): initial loss:    1168782.875\n",
      "learn_multisplits(): returning loss:  5996.266983032227\n",
      "================================\n",
      "learn_multisplits(): initial loss:    754242.0625\n",
      "learn_multisplits(): returning loss:  3078.275942802429\n",
      "================================\n",
      "learn_multisplits(): initial loss:    464859.28125\n",
      "learn_multisplits(): returning loss:  1579.292233467102\n",
      "================================\n",
      "learn_multisplits(): initial loss:    425833.0625\n",
      "learn_multisplits(): returning loss:  2114.715908050537\n",
      "================================\n",
      "learn_multisplits(): initial loss:    191617.90625\n",
      "learn_multisplits(): returning loss:  682.7657913565636\n",
      "================================\n",
      "learn_multisplits(): initial loss:    238969.375\n",
      "learn_multisplits(): returning loss:  1851.535026550293\n",
      "================================\n",
      "learn_multisplits(): initial loss:    1167066.375\n",
      "learn_multisplits(): returning loss:  6611.098571777344\n",
      "================================\n",
      "learn_multisplits(): initial loss:    1181196.75\n",
      "learn_multisplits(): returning loss:  5517.64688873291\n",
      "================================\n",
      "learn_multisplits(): initial loss:    745296.6875\n",
      "learn_multisplits(): returning loss:  2843.585171699524\n",
      "================================\n",
      "learn_multisplits(): initial loss:    567976.0\n",
      "learn_multisplits(): returning loss:  3093.0240898132324\n",
      "================================\n",
      "learn_multisplits(): initial loss:    716150.375\n",
      "learn_multisplits(): returning loss:  4359.2437744140625\n",
      "================================\n",
      "learn_multisplits(): initial loss:    490928.5625\n",
      "learn_multisplits(): returning loss:  2209.2880687713623\n",
      "================================\n",
      "learn_multisplits(): initial loss:    343763.75\n",
      "learn_multisplits(): returning loss:  1277.5359830856323\n",
      "================================\n",
      "learn_multisplits(): initial loss:    499706.8125\n",
      "learn_multisplits(): returning loss:  1872.7062001228333\n",
      "X_res mse / X mse:  0.0017318823\n",
      "fitting dense lstsq to X_res\n",
      "X_res mse / X mse after lstsq:  0.0008286676\n",
      "9.5db/\n",
      "F:\\Projects\\python\\PQ\\tutorialdjy\\bolt-master\\bolt-master\\experiments\\python\n",
      "==============================\n",
      "running method:  Mithral\n",
      "================================\n",
      "learn_multisplits(): initial loss:    78813.03125\n",
      "learn_multisplits(): returning loss:  265.2003234922886\n",
      "================================\n",
      "learn_multisplits(): initial loss:    136900.484375\n",
      "learn_multisplits(): returning loss:  978.6499519348145\n",
      "================================\n",
      "learn_multisplits(): initial loss:    869357.25\n",
      "learn_multisplits(): returning loss:  5077.2525634765625\n",
      "================================\n",
      "learn_multisplits(): initial loss:    322371.6875\n",
      "learn_multisplits(): returning loss:  1205.2921540737152\n",
      "================================\n",
      "learn_multisplits(): initial loss:    481105.5\n",
      "learn_multisplits(): returning loss:  2007.6936197280884\n",
      "================================\n",
      "learn_multisplits(): initial loss:    860721.125\n",
      "learn_multisplits(): returning loss:  3465.0847759246826\n",
      "================================\n",
      "learn_multisplits(): initial loss:    563205.375\n",
      "learn_multisplits(): returning loss:  3250.5398864746094\n",
      "================================\n",
      "learn_multisplits(): initial loss:    706728.1875\n",
      "learn_multisplits(): returning loss:  3006.788106918335\n",
      "================================\n",
      "learn_multisplits(): initial loss:    725647.1875\n",
      "learn_multisplits(): returning loss:  2917.9722328186035\n",
      "================================\n",
      "learn_multisplits(): initial loss:    489882.8125\n",
      "learn_multisplits(): returning loss:  1803.4740266799927\n",
      "================================\n",
      "learn_multisplits(): initial loss:    756482.625\n",
      "learn_multisplits(): returning loss:  4110.36328125\n",
      "================================\n",
      "learn_multisplits(): initial loss:    1044620.25\n",
      "learn_multisplits(): returning loss:  4576.267152786255\n",
      "================================\n",
      "learn_multisplits(): initial loss:    907764.375\n",
      "learn_multisplits(): returning loss:  3635.9145555496216\n",
      "================================\n",
      "learn_multisplits(): initial loss:    1161686.375\n",
      "learn_multisplits(): returning loss:  5868.757537841797\n",
      "================================\n",
      "learn_multisplits(): initial loss:    738175.125\n",
      "learn_multisplits(): returning loss:  2930.734652519226\n",
      "================================\n",
      "learn_multisplits(): initial loss:    455313.59375\n",
      "learn_multisplits(): returning loss:  1519.7798829078674\n",
      "================================\n",
      "learn_multisplits(): initial loss:    415394.625\n",
      "learn_multisplits(): returning loss:  2006.4371185302734\n",
      "================================\n",
      "learn_multisplits(): initial loss:    188824.296875\n",
      "learn_multisplits(): returning loss:  624.1233977079391\n",
      "================================\n",
      "learn_multisplits(): initial loss:    234684.75\n",
      "learn_multisplits(): returning loss:  1834.2850189208984\n",
      "================================\n",
      "learn_multisplits(): initial loss:    1138018.125\n",
      "learn_multisplits(): returning loss:  6359.184188842773\n",
      "================================\n",
      "learn_multisplits(): initial loss:    1155883.5\n",
      "learn_multisplits(): returning loss:  5277.611167907715\n",
      "================================\n",
      "learn_multisplits(): initial loss:    730091.125\n",
      "learn_multisplits(): returning loss:  2674.6945428848267\n",
      "================================\n",
      "learn_multisplits(): initial loss:    557565.25\n",
      "learn_multisplits(): returning loss:  2917.8507347106934\n",
      "================================\n",
      "learn_multisplits(): initial loss:    701823.5\n",
      "learn_multisplits(): returning loss:  4130.323501586914\n",
      "================================\n",
      "learn_multisplits(): initial loss:    479772.28125\n",
      "learn_multisplits(): returning loss:  2125.9243879318237\n",
      "================================\n",
      "learn_multisplits(): initial loss:    334235.125\n",
      "learn_multisplits(): returning loss:  1216.5387403964996\n",
      "================================\n",
      "learn_multisplits(): initial loss:    490900.03125\n",
      "learn_multisplits(): returning loss:  1842.5139656066895\n",
      "X_res mse / X mse:  0.0016941235\n",
      "fitting dense lstsq to X_res\n",
      "X_res mse / X mse after lstsq:  0.0008014574\n",
      "10db/\n",
      "F:\\Projects\\python\\PQ\\tutorialdjy\\bolt-master\\bolt-master\\experiments\\python\n",
      "==============================\n",
      "running method:  Mithral\n",
      "================================\n",
      "learn_multisplits(): initial loss:    76042.1953125\n",
      "learn_multisplits(): returning loss:  241.031391620636\n",
      "================================\n",
      "learn_multisplits(): initial loss:    133051.40625\n",
      "learn_multisplits(): returning loss:  957.7792358398438\n",
      "================================\n",
      "learn_multisplits(): initial loss:    854365.6875\n",
      "learn_multisplits(): returning loss:  5072.268020629883\n",
      "================================\n",
      "learn_multisplits(): initial loss:    317345.90625\n",
      "learn_multisplits(): returning loss:  1199.2813222408295\n",
      "================================\n",
      "learn_multisplits(): initial loss:    473721.84375\n",
      "learn_multisplits(): returning loss:  1936.1868362426758\n",
      "================================\n",
      "learn_multisplits(): initial loss:    846710.3125\n",
      "learn_multisplits(): returning loss:  3378.5666580200195\n",
      "================================\n",
      "learn_multisplits(): initial loss:    550843.3125\n",
      "learn_multisplits(): returning loss:  3157.7481689453125\n",
      "================================\n",
      "learn_multisplits(): initial loss:    698555.5\n",
      "learn_multisplits(): returning loss:  2917.400393486023\n",
      "================================\n",
      "learn_multisplits(): initial loss:    713194.4375\n",
      "learn_multisplits(): returning loss:  2815.271848678589\n",
      "================================\n",
      "learn_multisplits(): initial loss:    476395.5\n",
      "learn_multisplits(): returning loss:  1743.931740283966\n",
      "================================\n",
      "learn_multisplits(): initial loss:    744855.125\n",
      "learn_multisplits(): returning loss:  4028.475830078125\n",
      "================================\n",
      "learn_multisplits(): initial loss:    1029962.875\n",
      "learn_multisplits(): returning loss:  4507.828840255737\n",
      "================================\n",
      "learn_multisplits(): initial loss:    893574.1875\n",
      "learn_multisplits(): returning loss:  3532.9170684814453\n",
      "================================\n",
      "learn_multisplits(): initial loss:    1142732.375\n",
      "learn_multisplits(): returning loss:  5761.517349243164\n",
      "================================\n",
      "learn_multisplits(): initial loss:    719823.5\n",
      "learn_multisplits(): returning loss:  2854.977767944336\n",
      "================================\n",
      "learn_multisplits(): initial loss:    448453.46875\n",
      "learn_multisplits(): returning loss:  1425.8827257156372\n",
      "================================\n",
      "learn_multisplits(): initial loss:    408116.8125\n",
      "learn_multisplits(): returning loss:  1952.9564590454102\n",
      "================================\n",
      "learn_multisplits(): initial loss:    181761.796875\n",
      "learn_multisplits(): returning loss:  612.8839589953423\n",
      "================================\n",
      "learn_multisplits(): initial loss:    229079.90625\n",
      "learn_multisplits(): returning loss:  1737.638687133789\n",
      "================================\n",
      "learn_multisplits(): initial loss:    1124528.75\n",
      "learn_multisplits(): returning loss:  6191.130294799805\n",
      "================================\n",
      "learn_multisplits(): initial loss:    1141538.625\n",
      "learn_multisplits(): returning loss:  5194.804046630859\n",
      "================================\n",
      "learn_multisplits(): initial loss:    711767.0625\n",
      "learn_multisplits(): returning loss:  2599.29838848114\n",
      "================================\n",
      "learn_multisplits(): initial loss:    547859.8125\n",
      "learn_multisplits(): returning loss:  2897.1051483154297\n",
      "================================\n",
      "learn_multisplits(): initial loss:    690937.5\n",
      "learn_multisplits(): returning loss:  4079.781494140625\n",
      "================================\n",
      "learn_multisplits(): initial loss:    470844.25\n",
      "learn_multisplits(): returning loss:  2027.075553894043\n",
      "================================\n",
      "learn_multisplits(): initial loss:    327291.0625\n",
      "learn_multisplits(): returning loss:  1169.3653149604797\n",
      "================================\n",
      "learn_multisplits(): initial loss:    485831.90625\n",
      "learn_multisplits(): returning loss:  1808.4113624095917\n",
      "X_res mse / X mse:  0.0016859454\n",
      "fitting dense lstsq to X_res\n",
      "X_res mse / X mse after lstsq:  0.000775823\n",
      "10.5db/\n",
      "F:\\Projects\\python\\PQ\\tutorialdjy\\bolt-master\\bolt-master\\experiments\\python\n",
      "==============================\n",
      "running method:  Mithral\n",
      "================================\n",
      "learn_multisplits(): initial loss:    76250.0703125\n",
      "learn_multisplits(): returning loss:  245.1357922554016\n",
      "================================\n",
      "learn_multisplits(): initial loss:    131433.875\n",
      "learn_multisplits(): returning loss:  940.4730911254883\n",
      "================================\n",
      "learn_multisplits(): initial loss:    837735.75\n",
      "learn_multisplits(): returning loss:  4881.248229980469\n",
      "================================\n",
      "learn_multisplits(): initial loss:    309795.84375\n",
      "learn_multisplits(): returning loss:  1154.4706115722656\n",
      "================================\n",
      "learn_multisplits(): initial loss:    467416.5625\n",
      "learn_multisplits(): returning loss:  1883.459882736206\n",
      "================================\n",
      "learn_multisplits(): initial loss:    832004.375\n",
      "learn_multisplits(): returning loss:  3267.432915687561\n",
      "================================\n",
      "learn_multisplits(): initial loss:    545943.1875\n",
      "learn_multisplits(): returning loss:  3092.4471130371094\n",
      "================================\n",
      "learn_multisplits(): initial loss:    688305.0625\n",
      "learn_multisplits(): returning loss:  2777.302674293518\n",
      "================================\n",
      "learn_multisplits(): initial loss:    703452.1875\n",
      "learn_multisplits(): returning loss:  2792.4809284210205\n",
      "================================\n",
      "learn_multisplits(): initial loss:    473493.4375\n",
      "learn_multisplits(): returning loss:  1673.362621307373\n",
      "================================\n",
      "learn_multisplits(): initial loss:    731921.8125\n",
      "learn_multisplits(): returning loss:  3948.7423248291016\n",
      "================================\n",
      "learn_multisplits(): initial loss:    1015955.9375\n",
      "learn_multisplits(): returning loss:  4438.036794662476\n",
      "================================\n",
      "learn_multisplits(): initial loss:    884176.1875\n",
      "learn_multisplits(): returning loss:  3487.03249835968\n",
      "================================\n",
      "learn_multisplits(): initial loss:    1127048.625\n",
      "learn_multisplits(): returning loss:  5541.932754516602\n",
      "================================\n",
      "learn_multisplits(): initial loss:    710287.25\n",
      "learn_multisplits(): returning loss:  2770.414475440979\n",
      "================================\n",
      "learn_multisplits(): initial loss:    442692.0\n",
      "learn_multisplits(): returning loss:  1419.9335842132568\n",
      "================================\n",
      "learn_multisplits(): initial loss:    402323.78125\n",
      "learn_multisplits(): returning loss:  1890.6145324707031\n",
      "================================\n",
      "learn_multisplits(): initial loss:    181875.71875\n",
      "learn_multisplits(): returning loss:  594.4126721024513\n",
      "================================\n",
      "learn_multisplits(): initial loss:    228157.96875\n",
      "learn_multisplits(): returning loss:  1709.9717750549316\n",
      "================================\n",
      "learn_multisplits(): initial loss:    1109291.0\n",
      "learn_multisplits(): returning loss:  6050.907005310059\n",
      "================================\n",
      "learn_multisplits(): initial loss:    1123123.375\n",
      "learn_multisplits(): returning loss:  5097.83479309082\n",
      "================================\n",
      "learn_multisplits(): initial loss:    704947.875\n",
      "learn_multisplits(): returning loss:  2460.9887771606445\n",
      "================================\n",
      "learn_multisplits(): initial loss:    537654.625\n",
      "learn_multisplits(): returning loss:  2778.0541763305664\n",
      "================================\n",
      "learn_multisplits(): initial loss:    678356.8125\n",
      "learn_multisplits(): returning loss:  3964.3333740234375\n",
      "================================\n",
      "learn_multisplits(): initial loss:    468133.9375\n",
      "learn_multisplits(): returning loss:  2005.3774156570435\n",
      "================================\n",
      "learn_multisplits(): initial loss:    325556.53125\n",
      "learn_multisplits(): returning loss:  1129.4045143127441\n",
      "================================\n",
      "learn_multisplits(): initial loss:    477536.125\n",
      "learn_multisplits(): returning loss:  1688.0747754573822\n",
      "X_res mse / X mse:  0.0016659342\n",
      "fitting dense lstsq to X_res\n",
      "X_res mse / X mse after lstsq:  0.00075291964\n",
      "11db/\n",
      "F:\\Projects\\python\\PQ\\tutorialdjy\\bolt-master\\bolt-master\\experiments\\python\n",
      "==============================\n",
      "running method:  Mithral\n",
      "================================\n",
      "learn_multisplits(): initial loss:    74660.1015625\n",
      "learn_multisplits(): returning loss:  242.20856547355652\n",
      "================================\n",
      "learn_multisplits(): initial loss:    128206.4296875\n",
      "learn_multisplits(): returning loss:  916.7155799865723\n",
      "================================\n",
      "learn_multisplits(): initial loss:    827345.0\n",
      "learn_multisplits(): returning loss:  4828.067047119141\n",
      "================================\n",
      "learn_multisplits(): initial loss:    304841.0625\n",
      "learn_multisplits(): returning loss:  1160.6349897384644\n",
      "================================\n",
      "learn_multisplits(): initial loss:    460040.9375\n",
      "learn_multisplits(): returning loss:  1836.5612831115723\n",
      "================================\n",
      "learn_multisplits(): initial loss:    826289.8125\n",
      "learn_multisplits(): returning loss:  3200.2531299591064\n",
      "================================\n",
      "learn_multisplits(): initial loss:    539040.0\n",
      "learn_multisplits(): returning loss:  3002.430130004883\n",
      "================================\n",
      "learn_multisplits(): initial loss:    681552.6875\n",
      "learn_multisplits(): returning loss:  2760.9561977386475\n",
      "================================\n",
      "learn_multisplits(): initial loss:    694208.4375\n",
      "learn_multisplits(): returning loss:  2723.407783508301\n",
      "================================\n",
      "learn_multisplits(): initial loss:    463006.25\n",
      "learn_multisplits(): returning loss:  1657.1304264068604\n",
      "================================\n",
      "learn_multisplits(): initial loss:    718932.375\n",
      "learn_multisplits(): returning loss:  3921.5496826171875\n",
      "================================\n",
      "learn_multisplits(): initial loss:    995484.25\n",
      "learn_multisplits(): returning loss:  4356.098678588867\n",
      "================================\n",
      "learn_multisplits(): initial loss:    869272.5\n",
      "learn_multisplits(): returning loss:  3448.5977506637573\n",
      "================================\n",
      "learn_multisplits(): initial loss:    1122379.625\n",
      "learn_multisplits(): returning loss:  5410.061859130859\n",
      "================================\n",
      "learn_multisplits(): initial loss:    695391.0625\n",
      "learn_multisplits(): returning loss:  2690.9845581054688\n",
      "================================\n",
      "learn_multisplits(): initial loss:    435234.78125\n",
      "learn_multisplits(): returning loss:  1385.6641640663147\n",
      "================================\n",
      "learn_multisplits(): initial loss:    395234.125\n",
      "learn_multisplits(): returning loss:  1878.5487747192383\n",
      "================================\n",
      "learn_multisplits(): initial loss:    177783.8125\n",
      "learn_multisplits(): returning loss:  579.7479737997055\n",
      "================================\n",
      "learn_multisplits(): initial loss:    222917.296875\n",
      "learn_multisplits(): returning loss:  1676.7288513183594\n",
      "================================\n",
      "learn_multisplits(): initial loss:    1091128.75\n",
      "learn_multisplits(): returning loss:  5980.577949523926\n",
      "================================\n",
      "learn_multisplits(): initial loss:    1107821.875\n",
      "learn_multisplits(): returning loss:  5009.586364746094\n",
      "================================\n",
      "learn_multisplits(): initial loss:    695058.875\n",
      "learn_multisplits(): returning loss:  2418.582619667053\n",
      "================================\n",
      "learn_multisplits(): initial loss:    526186.375\n",
      "learn_multisplits(): returning loss:  2779.1051292419434\n",
      "================================\n",
      "learn_multisplits(): initial loss:    667016.8125\n",
      "learn_multisplits(): returning loss:  3917.48641204834\n",
      "================================\n",
      "learn_multisplits(): initial loss:    459773.53125\n",
      "learn_multisplits(): returning loss:  1957.9557456970215\n",
      "================================\n",
      "learn_multisplits(): initial loss:    318886.15625\n",
      "learn_multisplits(): returning loss:  1116.5959084033966\n",
      "================================\n",
      "learn_multisplits(): initial loss:    469535.5\n",
      "learn_multisplits(): returning loss:  1702.2800993919373\n",
      "X_res mse / X mse:  0.0016662575\n",
      "fitting dense lstsq to X_res\n",
      "X_res mse / X mse after lstsq:  0.00078481785\n"
     ]
    }
   ],
   "source": [
    "for snr in snrs_:\n",
    "    print(snr)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    print(_dir)\n",
    "    est3 = mm.estFactory(X_path=\"x.npy\", W_path=\"w.npy\", Y_path=\"y.npy\", dir=traindir+snr, methods=[method])\n",
    "    # est3 = mm.estFactory(X_path=\"x.npy\", W_path=\"w.npy\", Y_path=\"y.npy\", dir= os.path.join(\"..\\\\python\\\\data\\\\train\\\\\", snr), methods=[method])\n",
    "    x_test = np.load(_dir + \"/LDPC_decoder_NET_testdata/\" + snr + \"input.npy\")\n",
    "    w_test = np.load(_dir + \"/LDPC_decoder_NET_testdata/\"  + snr + \"weight.npy\")\n",
    "    bias = np.load(_dir + \"/LDPC_decoder_NET_testdata/\"+ snr + \"bias.npy\")\n",
    "    y_out_matmul = mm.eval_matmul(est3, x_test, w_test) # MADDNESS乘法的结果\n",
    "    y_out_last = mu.softmax(y_out_matmul + bias.T) # MADDNESS替换后当前层输出，即+bias并激活函数后的结果\n",
    "\n",
    "    # np.save(\"LDPC_decoder_NET_testdata/\" + snr + \"nomul_matmul_yout_matmul\", y_out_matmul)\n",
    "    # np.save(\"LDPC_decoder_NET_testdata/\" + snr + \"nomul_matmul_yout_last\", y_out_last)\n",
    "\n",
    "    io.savemat(dirnow + \"/data/\" + method + \"nc16@1_output1_threshold0.3_Tr15_SNR%s_ot.mat\" % (snr[:-3]), {\"NN_output_buffer\": y_out_last})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('PQ')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c58ec5320688f90a968f6b915ced038d1b61d036794cbc96752cb7f08b73ac5a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
